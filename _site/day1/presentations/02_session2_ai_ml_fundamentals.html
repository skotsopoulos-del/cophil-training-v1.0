<!DOCTYPE html>
<html lang="en"><head>
<link href="../../images/favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="author" content="Stylianos Kotsopoulos">
  <title>CoPhil EO AI/ML Training – Core Concepts of AI/ML for Earth Observation</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-534cd8e3a96973385dffff3f4709048d.css">
  <link rel="stylesheet" href="custom.scss">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Core Concepts of AI/ML for Earth Observation</h1>
  <p class="subtitle">CoPhil EO AI/ML Training - Day 1, Session 2</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Stylianos Kotsopoulos 
</div>
        <p class="quarto-title-affiliation">
            EU-Philippines CoPhil Programme
          </p>
    </div>
</div>

</section>
<section>
<section id="welcome-to-session-2" class="title-slide slide level1 center" data-background-color="#1e3a8a">
<h1>Welcome to Session 2</h1>

</section>
<section id="session-objectives" class="slide level2 center">
<h2>Session Objectives</h2>
<ul>
<li class="fragment">Understand <strong>what AI/ML means</strong> in Earth Observation context</li>
<li class="fragment">Learn the <strong>end-to-end workflow</strong> for ML projects</li>
<li class="fragment">Distinguish <strong>supervised</strong> vs <strong>unsupervised</strong> learning</li>
<li class="fragment">Grasp <strong>deep learning</strong> and neural network basics</li>
<li class="fragment">Explore <strong>2025 AI innovations</strong> (foundation models, data-centric AI)</li>
</ul>
<div class="fragment">
<p><strong>Duration:</strong> 2 hours</p>
</div>
<aside class="notes">
<p>This session covers fundamental AI/ML concepts tailored to EO applications. Mostly conceptual, but essential foundation for hands-on work in Sessions 3-4 and throughout Day 2-4.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="session-roadmap" class="slide level2 center">
<h2>Session Roadmap</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Time</th>
<th>Topic</th>
<th>Duration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>00-10 min</td>
<td>What is AI/ML?</td>
<td>10 min</td>
</tr>
<tr class="even">
<td>10-35 min</td>
<td>EO Workflow &amp; Data Pipeline</td>
<td>25 min</td>
</tr>
<tr class="odd">
<td>35-60 min</td>
<td>Supervised vs Unsupervised Learning</td>
<td>25 min</td>
</tr>
<tr class="even">
<td><strong>60-65 min</strong></td>
<td><strong>☕ Break</strong></td>
<td><strong>5 min</strong></td>
</tr>
<tr class="odd">
<td>65-90 min</td>
<td>Deep Learning &amp; Neural Networks</td>
<td>25 min</td>
</tr>
<tr class="even">
<td>90-110 min</td>
<td>Data-Centric AI &amp; 2025 Updates</td>
<td>20 min</td>
</tr>
<tr class="odd">
<td>110-120 min</td>
<td>Q&amp;A &amp; Summary</td>
<td>10 min</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p><strong>Timing:</strong> 2 minutes</p>
<p>This session is more conceptual than Session 1. Focus on building intuition and mental models. Hands-on practice comes in Sessions 3-4 and Days 2-4.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="why-aiml-for-earth-observation" class="slide level2 center">
<h2>Why AI/ML for Earth Observation?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Traditional Approach</strong></p>
<ul>
<li>Manual interpretation</li>
<li>Rule-based classification</li>
<li>Simple thresholds</li>
<li>Time-consuming</li>
<li>Hard to scale</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>AI/ML Approach</strong></p>
<ul>
<li>Automated pattern recognition</li>
<li>Learn from examples</li>
<li>Complex decision boundaries</li>
<li>Fast processing</li>
<li>Scalable to large areas</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>ML can process years of satellite data in hours!</strong></p>
</div>
<aside class="notes">
<p>Machine learning allows us to automatically recognize patterns in satellite imagery without hard-coding rules for every scenario. This is transformative for large-area, time-series analysis.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="what-is-aiml" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>What is AI/ML?</h1>

</section>
<section id="defining-the-terms" class="slide level2 center">
<h2>Defining the Terms</h2>

<img data-src="images/ai_ml_dl_venn.png" class="quarto-figure quarto-figure-center r-stretch" style="width:60.0%"><ul>
<li class="fragment"><strong>Artificial Intelligence (AI):</strong> Broad field of making machines “smart”</li>
<li class="fragment"><strong>Machine Learning (ML):</strong> Subset of AI where algorithms learn from data</li>
<li class="fragment"><strong>Deep Learning (DL):</strong> Subset of ML using neural networks with many layers</li>
</ul>
<aside class="notes">
<p>AI is the broadest term. Machine Learning is a subset where computer algorithms learn patterns from data without being explicitly programmed. Deep Learning uses neural networks.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="machine-learning-in-simple-terms" class="slide level2 center">
<h2>Machine Learning in Simple Terms</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Traditional Programming</strong></p>
<pre><code>Rules + Data → Results</code></pre>
<ul>
<li>Programmer writes explicit rules</li>
<li>Fixed logic</li>
<li>Hard to handle complexity</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Machine Learning</strong></p>
<pre><code>Data + Results → Rules</code></pre>
<ul>
<li>Algorithm learns rules from examples</li>
<li>Adaptive</li>
<li>Handles complex patterns</li>
</ul>
</div></div>
<aside class="notes">
<p>In traditional programming, we tell computers what to do step-by-step. In ML, we show examples and the algorithm figures out the pattern.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ml-in-earth-observation-context" class="slide level2 center">
<h2>ML in Earth Observation Context</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Example: Forest vs Non-Forest</strong></p>
<p><strong>Traditional:</strong></p>
<pre><code>IF NDVI &gt; 0.6 THEN Forest
ELSE Non-Forest</code></pre>
<p>Simple, but breaks easily</p>
</div><div class="column" style="width:50%;">
<p><strong>Machine Learning:</strong></p>
<ul>
<li>Show 1000 examples of forest pixels</li>
<li>Show 1000 examples of non-forest</li>
<li>Algorithm learns complex patterns</li>
<li>Works in diverse conditions</li>
</ul>
</div></div>

<img data-src="images/ml_classification_example.jpg" class="quarto-figure quarto-figure-center r-stretch" style="width:60.0%"><aside class="notes">
<p>A simple NDVI threshold might work in one region but fail in another. ML can learn the nuanced patterns that distinguish forest from non-forest across different conditions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="the-aiml-workflow-for-eo" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>The AI/ML Workflow for EO</h1>

</section>
<section id="end-to-end-ml-workflow" class="slide level2 center">
<h2>End-to-End ML Workflow</h2>

<img data-src="images/ml_workflow.png" class="quarto-figure quarto-figure-center r-stretch" style="width:90.0%"><aside class="notes">
<p>This is the typical workflow for any ML project in Earth Observation. Understanding these steps is crucial for successful implementation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="step-1-problem-definition" class="slide level2 center">
<h2>Step 1: Problem Definition</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Key Questions</strong></p>
<ul>
<li>What exactly are we trying to achieve?</li>
<li>What decisions will this support?</li>
<li>What level of accuracy is needed?</li>
<li>What resources are available?</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>EO Examples</strong></p>
<ul>
<li>Map rice paddy extent</li>
<li>Detect flooded areas after typhoon</li>
<li>Classify land cover types</li>
<li>Estimate crop yield</li>
<li>Monitor deforestation</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>Clear problem definition = 50% of success</strong></p>
</div>
<aside class="notes">
<p>Being clear on the question helps design the solution. “We want to classify land cover in Palawan” is much more actionable than “We want to use AI.”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="step-2-data-acquisition" class="slide level2 center">
<h2>Step 2: Data Acquisition</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Satellite Imagery</strong></p>
<ul>
<li>Sentinel-1/2 (covered in Session 1!)</li>
<li>Landsat</li>
<li>Planet</li>
<li>High-resolution commercial</li>
<li>Multiple dates/seasons</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Ground Truth / Labels</strong></p>
<ul>
<li>Field surveys</li>
<li>GPS points</li>
<li>Existing maps</li>
<li>Photo interpretation</li>
<li>Expert knowledge</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>Challenge:</strong> Getting quality labels is often hardest part</p>
</div>
<aside class="notes">
<p>Data acquisition includes both satellite images and the ground truth labels needed to train supervised models. The quality and quantity of labels directly impact model performance.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="step-3-data-preprocessing" class="slide level2 center">
<h2>Step 3: Data Preprocessing</h2>
<p><strong>For Satellite Imagery:</strong></p>
<ul>
<li class="fragment">Atmospheric correction (use Level-2A!)</li>
<li class="fragment">Cloud masking</li>
<li class="fragment">Geometric correction</li>
<li class="fragment">Radiometric calibration</li>
<li class="fragment">Co-registration (multiple sensors)</li>
<li class="fragment">Temporal compositing</li>
</ul>
<div class="fragment">
<p><strong>“Garbage In, Garbage Out”</strong> - preprocessing matters!</p>
</div>
<aside class="notes">
<p>Well-prepared input data is crucial. Even the best model will fail if fed cloudy, misaligned, or uncorrected images.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="preprocessing-example" class="slide level2 center">
<h2>Preprocessing Example</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Before Preprocessing</strong></p>
<p><img data-src="images/before_preprocessing.jpg" style="width:100.0%"></p>
<ul>
<li>Clouds present</li>
<li>Atmospheric haze</li>
<li>Different dates</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>After Preprocessing</strong></p>
<p><img data-src="images/after_preprocessing.jpg" style="width:100.0%"></p>
<ul>
<li>Clouds masked</li>
<li>Atmospherically corrected</li>
<li>Temporal composite</li>
</ul>
</div></div>
<aside class="notes">
<p>Preprocessing transforms raw satellite data into analysis-ready products. This often involves cloud masking and creating composites.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="step-4-feature-engineering" class="slide level2 center">
<h2>Step 4: Feature Engineering</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>What are Features?</strong></p>
<ul>
<li>Input variables for the model</li>
<li>Derived from raw data</li>
<li>Informative for the task</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>EO Features</strong></p>
<ul>
<li>Spectral bands (Blue, Red, NIR, etc.)</li>
<li>Spectral indices (NDVI, NDWI)</li>
<li>Texture measures</li>
<li>Temporal statistics</li>
<li>Topography (elevation, slope)</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>Deep Learning:</strong> Often learns features automatically!</p>
</div>
<aside class="notes">
<p>For traditional ML like Random Forest, we engineer features. For deep learning, the network learns features automatically from raw pixels.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="common-eo-features" class="slide level2 center">
<h2>Common EO Features</h2>
<table class="caption-top">
<colgroup>
<col style="width: 32%">
<col style="width: 25%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Feature Type</strong></th>
<th><strong>Examples</strong></th>
<th><strong>What They Capture</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Spectral Bands</strong></td>
<td>B2, B3, B4, B8</td>
<td>Reflectance at different wavelengths</td>
</tr>
<tr class="even">
<td><strong>Vegetation Indices</strong></td>
<td>NDVI, EVI, SAVI</td>
<td>Vegetation health, density</td>
</tr>
<tr class="odd">
<td><strong>Water Indices</strong></td>
<td>NDWI, MNDWI</td>
<td>Water presence, moisture</td>
</tr>
<tr class="even">
<td><strong>Texture</strong></td>
<td>GLCM variance, entropy</td>
<td>Spatial patterns</td>
</tr>
<tr class="odd">
<td><strong>Temporal</strong></td>
<td>Mean, std over time</td>
<td>Phenology, seasonality</td>
</tr>
<tr class="even">
<td><strong>Topographic</strong></td>
<td>Elevation, slope, aspect</td>
<td>Terrain characteristics</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>Different features highlight different aspects of the landscape. Vegetation indices emphasize green biomass, water indices highlight water bodies, etc.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="step-5-model-selection-training" class="slide level2 center">
<h2>Step 5: Model Selection &amp; Training</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Model Selection</strong></p>
<p>Choose based on:</p>
<ul>
<li>Problem type (classification vs regression)</li>
<li>Data size</li>
<li>Interpretability needs</li>
<li>Computational resources</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Common EO Models</strong></p>
<ul>
<li>Random Forest</li>
<li>Support Vector Machines</li>
<li>Convolutional Neural Networks</li>
<li>U-Net (segmentation)</li>
<li>Recurrent networks (time series)</li>
</ul>
</div></div>
<aside class="notes">
<p>Model choice depends on your specific problem, available data, and resources. We’ll cover Random Forest on Day 2 and CNNs on Day 3.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="training-process" class="slide level2 center">
<h2>Training Process</h2>

<img data-src="images/training_process.png" class="quarto-figure quarto-figure-center r-stretch" style="width:75.0%"><ol type="1">
<li class="fragment"><strong>Split data:</strong> Training set (70-80%) &amp; Validation set (20-30%)</li>
<li class="fragment"><strong>Feed training data</strong> to model</li>
<li class="fragment"><strong>Model learns patterns</strong> by adjusting internal parameters</li>
<li class="fragment"><strong>Validate</strong> on unseen validation data</li>
<li class="fragment"><strong>Iterate:</strong> Adjust model or data if needed</li>
</ol>
<aside class="notes">
<p>Training involves feeding labeled examples to the model. The model adjusts its internal parameters to minimize errors on the training data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="step-6-validation-evaluation" class="slide level2 center">
<h2>Step 6: Validation &amp; Evaluation</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Why Validate?</strong></p>
<ul>
<li>Ensure model generalizes</li>
<li>Detect overfitting</li>
<li>Compare different models</li>
<li>Build confidence</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Evaluation Metrics</strong></p>
<ul>
<li>Overall Accuracy</li>
<li>Confusion Matrix</li>
<li>Precision &amp; Recall</li>
<li>F1-Score</li>
<li>Kappa coefficient</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>Use independent test data - never validate on training data!</strong></p>
</div>
<aside class="notes">
<p>Rigorous validation using held-out data ensures the model works on new, unseen examples - not just memorizing training data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="confusion-matrix-example" class="slide level2 center">
<h2>Confusion Matrix Example</h2>

<img data-src="images/confusion_matrix.png" class="quarto-figure quarto-figure-center r-stretch" style="width:60.0%"><div class="columns">
<div class="column" style="width:50%;">
<p><strong>What it shows:</strong></p>
<ul>
<li>True Positives (correct predictions)</li>
<li>False Positives (type I error)</li>
<li>False Negatives (type II error)</li>
<li>True Negatives</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Derived Metrics:</strong></p>
<ul>
<li>Precision = TP / (TP + FP)</li>
<li>Recall = TP / (TP + FN)</li>
<li>Accuracy = (TP + TN) / Total</li>
</ul>
</div></div>
<aside class="notes">
<p>The confusion matrix shows where your model is making mistakes. This helps identify which classes are being confused.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="step-7-deployment" class="slide level2 center">
<h2>Step 7: Deployment</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Deployment Options</strong></p>
<ul>
<li>Generate full maps</li>
<li>Near real-time monitoring</li>
<li>Operational pipelines</li>
<li>Decision support systems</li>
<li>Web applications</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Considerations</strong></p>
<ul>
<li>Model retraining schedule</li>
<li>Computational requirements</li>
<li>User interface</li>
<li>Data updates</li>
<li>Maintenance plan</li>
</ul>
</div></div>
<aside class="notes">
<p>If the model is satisfactory, deploy it for operational use. This might mean generating maps for entire regions or setting up automatic processing of new satellite images.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="workflow-is-iterative" class="slide level2 center">
<h2>Workflow is Iterative</h2>

<img data-src="images/iterative_workflow.png" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"><ul>
<li class="fragment"><strong>Poor validation?</strong> → Go back to data acquisition or model selection</li>
<li class="fragment"><strong>New data available?</strong> → Retrain model</li>
<li class="fragment"><strong>Requirements change?</strong> → Redefine problem</li>
<li class="fragment"><strong>Continuous improvement</strong> is key</li>
</ul>
<aside class="notes">
<p>Real projects are iterative. You often loop back: if validation is poor, you might need more data, different features, or a different model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="types-of-machine-learning" class="title-slide slide level1 center" data-background-color="#1e3a8a">
<h1>Types of Machine Learning</h1>

</section>
<section id="main-ml-paradigms" class="slide level2 center">
<h2>Main ML Paradigms</h2>

<img data-src="images/ml_types.png" class="quarto-figure quarto-figure-center r-stretch" style="width:75.0%"><ol type="1">
<li class="fragment"><strong>Supervised Learning</strong> (most common in EO)</li>
<li class="fragment"><strong>Unsupervised Learning</strong> (exploratory analysis)</li>
<li class="fragment"><strong>Semi-supervised Learning</strong> (combines both)</li>
<li class="fragment"><strong>Reinforcement Learning</strong> (less common in EO)</li>
</ol>
<aside class="notes">
<p>We’ll focus on supervised and unsupervised learning as these are most relevant for Earth Observation applications.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="supervised-learning" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>Supervised Learning</h1>

</section>
<section id="what-is-supervised-learning" class="slide level2 center">
<h2>What is Supervised Learning?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Definition</strong></p>
<ul>
<li>Learning from <strong>labeled data</strong></li>
<li>Known input-output pairs</li>
<li>Model learns mapping from inputs to outputs</li>
<li>Like learning with an answer key</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/supervised_learning.png" style="width:100.0%"></p>
</div></div>
<div class="fragment">
<p><strong>Requires ground truth labels for training</strong></p>
</div>
<aside class="notes">
<p>Supervised learning is the most common in EO. The algorithm is given examples with known outcomes (labels) and learns to predict labels for new, unseen data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="two-types-of-supervised-learning" class="slide level2 center">
<h2>Two Types of Supervised Learning</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Classification</strong></p>
<ul>
<li>Predict <strong>categorical</strong> labels</li>
<li>Discrete classes</li>
<li>Example outputs: “Forest”, “Water”, “Urban”</li>
</ul>
<p><img data-src="images/classification.jpg" style="width:100.0%"></p>
</div><div class="column" style="width:50%;">
<p><strong>Regression</strong></p>
<ul>
<li>Predict <strong>continuous</strong> values</li>
<li>Numeric outputs</li>
<li>Example outputs: 25.3 tons/hectare, 15.2°C</li>
</ul>
<p><img data-src="images/regression.jpg" style="width:100.0%"></p>
</div></div>
<aside class="notes">
<p>Classification assigns data to categories. Regression predicts numeric values. Both require labeled training data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classification-examples-in-eo" class="slide level2 center">
<h2>Classification Examples in EO</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Land Cover Classification</strong></p>
<p><img data-src="images/land_cover_classification.jpg" style="width:100.0%"></p>
<ul>
<li>Forest, agriculture, urban, water</li>
<li>Pixel-wise or object-based</li>
<li>Multi-class problem</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Crop Type Mapping</strong></p>
<p><img data-src="images/crop_type_map.jpg" style="width:100.0%"></p>
<ul>
<li>Rice, corn, sugarcane</li>
<li>Seasonal patterns important</li>
<li>Supports agricultural planning</li>
</ul>
</div></div>
<aside class="notes">
<p>Land cover classification is the classic EO supervised learning task. Each pixel or region is assigned to a class like forest, water, or urban.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="regression-examples-in-eo" class="slide level2 center">
<h2>Regression Examples in EO</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Biomass Estimation</strong></p>
<p><img data-src="images/biomass_estimation.jpg" style="width:100.0%"></p>
<ul>
<li>Predict tons of biomass per hectare</li>
<li>Important for carbon accounting</li>
<li>Uses SAR and optical data</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Crop Yield Prediction</strong></p>
<p><img data-src="images/yield_prediction.jpg" style="width:100.0%"></p>
<ul>
<li>Predict tons per hectare</li>
<li>Seasonal NDVI time series</li>
<li>Supports food security planning</li>
</ul>
</div></div>
<aside class="notes">
<p>Regression tasks predict continuous values like biomass density, crop yield, soil moisture, or sea surface temperature from satellite data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="common-supervised-algorithms" class="slide level2 center">
<h2>Common Supervised Algorithms</h2>
<table class="caption-top">
<colgroup>
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Algorithm</strong></th>
<th><strong>Strengths</strong></th>
<th><strong>EO Applications</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Random Forest</strong></td>
<td>Handles high dimensions, robust</td>
<td>Land cover, crop classification</td>
</tr>
<tr class="even">
<td><strong>SVM</strong></td>
<td>Effective in high dimensions</td>
<td>Binary classification, change detection</td>
</tr>
<tr class="odd">
<td><strong>Neural Networks</strong></td>
<td>Learns complex patterns</td>
<td>Image classification, segmentation</td>
</tr>
<tr class="even">
<td><strong>Decision Trees</strong></td>
<td>Interpretable</td>
<td>Quick classifications</td>
</tr>
<tr class="odd">
<td><strong>k-NN</strong></td>
<td>Simple, non-parametric</td>
<td>Local classifications</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>Different algorithms have different strengths. Random Forest is popular in EO for its robustness and ability to handle many features.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="supervised-learning-requirements" class="slide level2 center">
<h2>Supervised Learning Requirements</h2>
<p><strong>Essential:</strong></p>
<ol type="1">
<li class="fragment"><strong>Training data</strong> with known labels</li>
<li class="fragment"><strong>Representative samples</strong> covering all classes</li>
<li class="fragment"><strong>Sufficient quantity</strong> (varies by algorithm)</li>
<li class="fragment"><strong>Quality labels</strong> (accurate, consistent)</li>
<li class="fragment"><strong>Independent validation</strong> data</li>
</ol>
<div class="fragment">
<p><strong>Challenge:</strong> Getting quality labels is often the bottleneck!</p>
</div>
<aside class="notes">
<p>Supervised learning needs ground truth. For land cover, this might be field surveys, GPS points, or careful photo interpretation. Quality matters more than quantity!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="unsupervised-learning" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>Unsupervised Learning</h1>

</section>
<section id="what-is-unsupervised-learning" class="slide level2 center">
<h2>What is Unsupervised Learning?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Definition</strong></p>
<ul>
<li>Learning from <strong>unlabeled data</strong></li>
<li>No known outputs</li>
<li>Discover hidden patterns</li>
<li>Like sorting without instructions</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/unsupervised_learning.png" style="width:100.0%"></p>
</div></div>
<div class="fragment">
<p><strong>Useful for exploratory analysis and finding structure</strong></p>
</div>
<aside class="notes">
<p>Unsupervised learning finds patterns or groupings inherent in the data without being told what to look for.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="clustering-main-unsupervised-technique" class="slide level2 center">
<h2>Clustering: Main Unsupervised Technique</h2>

<img data-src="images/clustering_example.png" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"><ul>
<li class="fragment"><strong>Group similar pixels</strong> based on spectral characteristics</li>
<li class="fragment">Algorithm decides number of clusters (or you specify)</li>
<li class="fragment"><strong>Analyst interprets</strong> what each cluster means</li>
<li class="fragment">Example: “Cluster 3 looks like water, Cluster 7 looks like forest”</li>
</ul>
<aside class="notes">
<p>K-means clustering is a common unsupervised method. It groups pixels with similar reflectance, but you have to interpret what those groups mean.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="unsupervised-eo-applications" class="slide level2 center">
<h2>Unsupervised EO Applications</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Change Detection</strong></p>
<ul>
<li>Cluster “before” and “after” images</li>
<li>Identify changed areas</li>
<li>No labels needed</li>
</ul>
<p><strong>Anomaly Detection</strong></p>
<ul>
<li>Find unusual pixels</li>
<li>Potential forest disturbance</li>
<li>Data quality issues</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Initial Exploration</strong></p>
<ul>
<li>Quick overview of spectral classes</li>
<li>Inform supervised approach</li>
<li>Generate training samples</li>
</ul>
<p><strong>Dimensionality Reduction</strong></p>
<ul>
<li>PCA, t-SNE</li>
<li>Visualize high-dimensional data</li>
<li>Feature extraction</li>
</ul>
</div></div>
<aside class="notes">
<p>Unsupervised methods are useful for quick initial analysis or when you don’t have ground truth labels. Results need interpretation though.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="supervised-vs-unsupervised" class="slide level2 center">
<h2>Supervised vs Unsupervised</h2>
<table class="caption-top">
<colgroup>
<col style="width: 26%">
<col style="width: 34%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Aspect</strong></th>
<th><strong>Supervised</strong></th>
<th><strong>Unsupervised</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Labels</strong></td>
<td>Required</td>
<td>Not needed</td>
</tr>
<tr class="even">
<td><strong>Accuracy</strong></td>
<td>Generally higher</td>
<td>Lower, needs interpretation</td>
</tr>
<tr class="odd">
<td><strong>Use Case</strong></td>
<td>Precise classification</td>
<td>Exploration, pattern discovery</td>
</tr>
<tr class="even">
<td><strong>Effort</strong></td>
<td>High (collecting labels)</td>
<td>Low (no labels)</td>
</tr>
<tr class="odd">
<td><strong>Output</strong></td>
<td>Predefined classes</td>
<td>Discovered clusters</td>
</tr>
<tr class="even">
<td><strong>Control</strong></td>
<td>High (you define classes)</td>
<td>Low (algorithm decides groups)</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>Supervised methods generally yield more accurate results when good training data is available. Unsupervised is useful when labels are unavailable or for exploratory work.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="which-to-choose" class="slide level2 center">
<h2>Which to Choose?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Use Supervised When:</strong></p>
<ul>
<li>You have ground truth labels</li>
<li>Need specific classes</li>
<li>Accuracy is critical</li>
<li>Operational application</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Use Unsupervised When:</strong></p>
<ul>
<li>No labels available</li>
<li>Exploratory analysis</li>
<li>Discovering unknown patterns</li>
<li>Quick initial assessment</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>In practice:</strong> Often combine both approaches!</p>
</div>
<aside class="notes">
<p>Most operational EO applications use supervised learning because accuracy and specific class definitions are important. Unsupervised helps with initial exploration.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="minute-break" class="slide level2 center" data-background-color="#7c3aed">
<h2>☕ 5-Minute Break</h2>
<div class="r-fit-text">
<p><strong>Stretch Break</strong></p>
<p>Stand up • Grab water • Back in 5 minutes</p>
</div>
<aside class="notes">
<p><strong>Timing:</strong> 5 minutes</p>
<p><strong>Instructor Actions:</strong> - Announce break - Mention we’ll dive into deep learning next - Be available for quick questions</p>
<p><strong>When Resuming:</strong> - Quick recap: “We’ve covered ML basics, workflow, supervised/unsupervised. Now: deep learning!”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2 center">

</section></section>
<section>
<section id="introduction-to-deep-learning" class="title-slide slide level1 center" data-background-color="#1e3a8a">
<h1>Introduction to Deep Learning</h1>

</section>
<section id="what-is-deep-learning" class="slide level2 center">
<h2>What is Deep Learning?</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><strong>Deep Learning = Neural Networks with Many Layers</strong></p>
<ul>
<li>Subset of machine learning</li>
<li>“Deep” refers to multiple layers</li>
<li>Automatically learns features</li>
<li>Excels at image analysis</li>
<li>Data-hungry</li>
</ul>
</div><div class="column" style="width:40%;">
<p><img data-src="images/deep_learning_layers.png" style="width:100.0%"></p>
</div></div>
<aside class="notes">
<p>Deep learning is essentially about neural networks with many layers (dozens or even hundreds). These “deep” networks can capture very complex relationships.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="neural-networks-building-blocks" class="slide level2 center">
<h2>Neural Networks: Building Blocks</h2>

<img data-src="images/neuron_diagram.png" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"><p><strong>Artificial Neuron:</strong></p>
<ol type="1">
<li class="fragment">Takes multiple inputs</li>
<li class="fragment">Multiplies each by a <strong>weight</strong></li>
<li class="fragment">Adds a <strong>bias</strong></li>
<li class="fragment">Applies <strong>activation function</strong></li>
<li class="fragment">Produces output</li>
</ol>
<aside class="notes">
<p>A single neuron is like a logistic regression unit. It takes inputs, applies weights, and uses an activation function to produce an output.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="neural-network-architecture" class="slide level2 center">
<h2>Neural Network Architecture</h2>

<img data-src="images/neural_network_architecture.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><div class="columns">
<div class="column" style="width:50%;">
<p><strong>Layers:</strong></p>
<ul>
<li><strong>Input Layer:</strong> Receives data (e.g., pixel values)</li>
<li><strong>Hidden Layers:</strong> Process and transform</li>
<li><strong>Output Layer:</strong> Final prediction</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Connections:</strong></p>
<ul>
<li>Each neuron connects to next layer</li>
<li>Weights on connections</li>
<li>Information flows forward</li>
</ul>
</div></div>
<aside class="notes">
<p>Neurons are organized into layers. The input layer receives data (pixel values), hidden layers progressively extract features, and the output layer makes predictions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="key-concepts" class="slide level2 center">
<h2>Key Concepts</h2>
<p><strong>Activation Functions</strong></p>
<ul>
<li class="fragment">Introduce non-linearity</li>
<li class="fragment">Common: ReLU, Sigmoid, Tanh</li>
<li class="fragment">Allow network to learn complex patterns</li>
</ul>
<p><strong>Weights and Biases</strong></p>
<ul>
<li class="fragment">Parameters the network learns</li>
<li class="fragment">Millions of parameters in deep networks</li>
<li class="fragment">Adjusted during training</li>
</ul>
<p><strong>Forward Propagation</strong></p>
<ul>
<li class="fragment">Data flows input → output</li>
<li class="fragment">Generate prediction</li>
</ul>
<aside class="notes">
<p>Activation functions are crucial - they allow neural networks to learn non-linear relationships. Without them, the network would just be linear regression!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-neural-networks-learn" class="slide level2 center">
<h2>How Neural Networks Learn</h2>

<img data-src="images/training_loop.png" class="quarto-figure quarto-figure-center r-stretch" style="width:75.0%"><ol type="1">
<li class="fragment"><strong>Forward pass:</strong> Input data, get prediction</li>
<li class="fragment"><strong>Calculate loss:</strong> How wrong is the prediction?</li>
<li class="fragment"><strong>Backpropagation:</strong> Calculate gradients</li>
<li class="fragment"><strong>Update weights:</strong> Adjust to reduce error</li>
<li class="fragment"><strong>Repeat:</strong> Thousands of times (epochs)</li>
</ol>
<aside class="notes">
<p>Training adjusts weights to minimize error. This happens through backpropagation - computing gradients and updating weights in the direction that reduces loss.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="loss-functions" class="slide level2 center">
<h2>Loss Functions</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Classification</strong></p>
<p><strong>Cross-Entropy Loss</strong></p>
<ul>
<li>Measures classification error</li>
<li>Higher penalty for confident wrong predictions</li>
<li>Standard for multi-class problems</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Regression</strong></p>
<p><strong>Mean Squared Error</strong></p>
<p><span class="math display">\[MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2\]</span></p>
<ul>
<li>Measures prediction error</li>
<li>Squared difference from true value</li>
</ul>
</div></div>
<aside class="notes">
<p>Loss functions quantify “how bad” predictions are. The training process tries to minimize this loss by adjusting weights.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="optimizers" class="slide level2 center">
<h2>Optimizers</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Stochastic Gradient Descent (SGD)</strong></p>
<ul>
<li>Basic optimizer</li>
<li>Updates weights based on gradients</li>
<li>Learning rate controls step size</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Adam Optimizer</strong></p>
<ul>
<li>Adaptive learning rates</li>
<li>Faster convergence</li>
<li>Most popular for deep learning</li>
<li>Generally works well</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>You don’t need to implement these - frameworks do it for you!</strong></p>
</div>
<aside class="notes">
<p>Optimizers determine how weights are updated. Adam is the most popular because it adapts learning rates automatically and generally converges faster than SGD.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="convolutional-neural-networks-cnns" class="slide level2 center">
<h2>Convolutional Neural Networks (CNNs)</h2>

<img data-src="images/cnn_architecture.png" class="quarto-figure quarto-figure-center r-stretch" style="width:85.0%"><p><strong>Specialized for images:</strong></p>
<ul>
<li class="fragment"><strong>Convolutional layers:</strong> Detect spatial patterns</li>
<li class="fragment"><strong>Pooling layers:</strong> Reduce dimensionality</li>
<li class="fragment"><strong>Fully connected layers:</strong> Final classification</li>
<li class="fragment">Automatically learn features (edges, textures, objects)</li>
</ul>
<aside class="notes">
<p>CNNs are neural networks specialized for grid data like images. They use convolutional layers to automatically extract spatial features.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-cnns-process-images" class="slide level2 center">
<h2>How CNNs Process Images</h2>

<img data-src="images/cnn_feature_extraction.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p><strong>Hierarchical Feature Learning:</strong></p>
<ul>
<li class="fragment"><strong>Early layers:</strong> Detect edges, simple patterns</li>
<li class="fragment"><strong>Middle layers:</strong> Detect textures, parts</li>
<li class="fragment"><strong>Later layers:</strong> Detect objects, scenes</li>
<li class="fragment"><strong>No manual feature engineering needed!</strong></li>
</ul>
<aside class="notes">
<p>CNNs learn increasingly complex features at each layer. Early layers detect edges, later layers detect whole objects. This happens automatically during training!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="cnns-in-earth-observation" class="slide level2 center">
<h2>CNNs in Earth Observation</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Applications:</strong></p>
<ul>
<li>Image classification</li>
<li>Object detection (ships, buildings)</li>
<li>Semantic segmentation (pixel-wise)</li>
<li>Change detection</li>
<li>Super-resolution</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Advantages:</strong></p>
<ul>
<li>Learn features automatically</li>
<li>Handle spatial context</li>
<li>State-of-the-art performance</li>
<li>Transfer learning possible</li>
</ul>
</div></div>

<img data-src="images/cnn_eo_examples.jpg" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"><aside class="notes">
<p>CNNs have achieved state-of-the-art results in many EO tasks. They can learn to recognize complex patterns without manual feature engineering.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="popular-cnn-architectures-for-eo" class="slide level2 center">
<h2>Popular CNN Architectures for EO</h2>
<table class="caption-top">
<colgroup>
<col style="width: 27%">
<col style="width: 15%">
<col style="width: 29%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Architecture</strong></th>
<th><strong>Year</strong></th>
<th><strong>Key Innovation</strong></th>
<th><strong>EO Use Cases</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>ResNet</strong></td>
<td>2015</td>
<td>Residual connections</td>
<td>Classification, backbone for detection</td>
</tr>
<tr class="even">
<td><strong>U-Net</strong></td>
<td>2015</td>
<td>Skip connections</td>
<td>Semantic segmentation, flood mapping</td>
</tr>
<tr class="odd">
<td><strong>EfficientNet</strong></td>
<td>2019</td>
<td>Compound scaling</td>
<td>Efficient classification, mobile deployment</td>
</tr>
<tr class="even">
<td><strong>DeepLabv3+</strong></td>
<td>2018</td>
<td>Atrous convolution</td>
<td>Land cover segmentation</td>
</tr>
<tr class="odd">
<td><strong>YOLOv8</strong></td>
<td>2023</td>
<td>Real-time detection</td>
<td>Object detection, ship/vehicle counting</td>
</tr>
</tbody>
</table>
<div class="fragment">
<p><strong>ResNet and EfficientNet are most popular backbones for EO</strong></p>
</div>
<aside class="notes">
<p>These are proven architectures widely used in EO. ResNet-50 is often the starting point for transfer learning. U-Net dominates semantic segmentation tasks.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="resnet-residual-networks" class="slide level2 center">
<h2>ResNet: Residual Networks</h2>

<img data-src="images/resnet_residual_block.png" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"><div class="columns">
<div class="column" style="width:60%;">
<p><strong>Key Innovation: Skip Connections</strong></p>
<ul>
<li>Allows training very deep networks (50, 101, 152 layers)</li>
<li>Solves vanishing gradient problem</li>
<li>Identity mapping preserves information</li>
</ul>
<p><strong>Common Variants:</strong> - ResNet-50 (25M parameters) - ResNet-101 (44M parameters) - ResNet-152 (60M parameters)</p>
</div><div class="column" style="width:40%;">
<p><strong>EO Applications:</strong></p>
<ul>
<li>Pre-trained on ImageNet</li>
<li>Fine-tune for EO tasks</li>
<li>Backbone for object detection</li>
<li>Transfer learning baseline</li>
</ul>
<p><strong>Performance:</strong> - Top-5 error: 3.57% (ImageNet) - Works well with 10k+ images</p>
</div></div>
<aside class="notes">
<p>ResNet revolutionized deep learning by enabling training of very deep networks. Skip connections allow gradients to flow directly through the network.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="u-net-for-semantic-segmentation" class="slide level2 center">
<h2>U-Net for Semantic Segmentation</h2>

<img data-src="images/unet_architecture.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p><strong>Architecture:</strong> - <strong>Encoder (contracting path):</strong> Captures context - <strong>Decoder (expanding path):</strong> Enables precise localization - <strong>Skip connections:</strong> Combine low &amp; high-level features</p>
<p><strong>Why Dominant in EO:</strong> - Works with small datasets (hundreds of images) - Precise pixel-wise predictions - Perfect for segmentation tasks</p>
<div class="fragment">
<p><strong>EO Applications:</strong> Flood mapping, land cover, building footprints, crop fields</p>
</div>
<aside class="notes">
<p>U-Net is THE architecture for semantic segmentation in EO. Originally designed for biomedical image segmentation, it’s now standard for pixel-wise classification tasks.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-frameworks" class="slide level2 center">
<h2>Deep Learning Frameworks</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>TensorFlow / Keras</strong></p>
<p><img data-src="images/tensorflow_logo.png" width="150"></p>
<ul>
<li>Google’s framework</li>
<li>High-level Keras API</li>
<li>Production-ready</li>
<li>Large ecosystem</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>PyTorch</strong></p>
<p><img data-src="images/pytorch_logo.png" width="150"></p>
<ul>
<li>Facebook’s framework</li>
<li>Pythonic and intuitive</li>
<li>Popular in research</li>
<li>Flexible</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>We’ll use TensorFlow/Keras in this training</strong></p>
</div>
<aside class="notes">
<p>You don’t implement backpropagation yourself - frameworks like TensorFlow and PyTorch handle the math. You just define the architecture and provide data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-considerations" class="slide level2 center">
<h2>Deep Learning Considerations</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Advantages:</strong></p>
<ul>
<li>Automatic feature learning</li>
<li>State-of-the-art accuracy</li>
<li>Handles complex patterns</li>
<li>Scales to big data</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Challenges:</strong></p>
<ul>
<li>Requires lots of training data</li>
<li>Computationally intensive (need GPUs)</li>
<li>Less interpretable (“black box”)</li>
<li>Harder to debug</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>Start simple (Random Forest), move to DL when you have data and compute</strong></p>
</div>
<aside class="notes">
<p>Deep learning is powerful but data-hungry and computationally expensive. For many EO tasks, simpler models like Random Forest work well with less data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="benchmark-datasets-for-eo" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>Benchmark Datasets for EO</h1>

</section>
<section id="why-benchmark-datasets-matter" class="slide level2 center">
<h2>Why Benchmark Datasets Matter</h2>
<ol type="1">
<li class="fragment"><strong>Standardized Evaluation</strong> - Compare algorithms objectively</li>
<li class="fragment"><strong>Training Resources</strong> - Pre-labeled data for model training</li>
<li class="fragment"><strong>Transfer Learning</strong> - Pre-train on large datasets, fine-tune locally</li>
<li class="fragment"><strong>Research Reproducibility</strong> - Enable comparison across studies</li>
<li class="fragment"><strong>Community Building</strong> - Shared resources accelerate progress</li>
</ol>
<div class="fragment">
<p><strong>You don’t need to label everything from scratch!</strong></p>
</div>
<aside class="notes">
<p>Benchmark datasets are crucial for EO ML. They provide labeled training data and enable fair comparison of methods across research groups worldwide.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="eurosat-land-cover-classification" class="slide level2 center">
<h2>EuroSAT: Land Cover Classification</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><strong>Specifications:</strong> - <strong>Images:</strong> 27,000 labeled patches - <strong>Classes:</strong> 10 land cover types - <strong>Size:</strong> 64×64 pixels - <strong>Bands:</strong> All 13 Sentinel-2 bands - <strong>Source:</strong> European cities</p>
<p><strong>10 Classes:</strong> Annual Crop • Forest • Herbaceous Vegetation • Highway • Industrial • Pasture • Permanent Crop • Residential • River • Sea/Lake</p>
</div><div class="column" style="width:40%;">
<p><img data-src="images/eurosat_classes.png" style="width:100.0%"></p>
<p><strong>Achievement:</strong> <strong>98.57% accuracy</strong> with CNNs</p>
<p><strong>Why Popular:</strong> - Sentinel-2 based - Balanced classes - Easy to use</p>
</div></div>
<aside class="notes">
<p>EuroSAT is one of the most popular benchmarks for EO classification. Based on Sentinel-2, making it highly relevant for operational applications. Great starting point for CNN experiments.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="bigearthnet-large-scale-multi-label" class="slide level2 center">
<h2>BigEarthNet: Large-Scale Multi-Label</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Massive Scale:</strong> - <strong>Images:</strong> 590,326 Sentinel-2 patches - <strong>Coverage:</strong> 10 European countries - <strong>Labels:</strong> 43 land cover classes - <strong>Multi-label:</strong> Multiple classes per image - <strong>Multi-modal:</strong> Optical + SAR version</p>
<p><strong>Real-World Complexity:</strong> - Forest + Water - Urban + Agricultural - Reflects actual landscapes</p>
</div><div class="column" style="width:50%;">
<p><img data-src="images/bigearth_multilabel.jpg" style="width:100.0%"></p>
<p><strong>Why Different:</strong></p>
<p>Unlike EuroSAT (single label), BigEarthNet has multiple overlapping classes - more realistic!</p>
<p><strong>Access:</strong> - bigearth.net - TensorFlow Datasets - Papers With Code</p>
</div></div>
<aside class="notes">
<p>BigEarthNet’s multi-label nature makes it more challenging but also more realistic. Essential for semantic segmentation research and testing advanced architectures.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="xview-object-detection-benchmark" class="slide level2 center">
<h2>xView: Object Detection Benchmark</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Specifications:</strong> - <strong>Objects:</strong> &gt;1 million annotated - <strong>Classes:</strong> 60 object types - <strong>Resolution:</strong> 0.3m (WorldView-3) - <strong>Area:</strong> &gt;1,400 km² - <strong>Annotations:</strong> Bounding boxes</p>
<p><strong>Object Categories:</strong> - Buildings &amp; infrastructure - Vehicles (cars, trucks, aircraft) - Ships &amp; maritime - Storage tanks - Construction equipment</p>
</div><div class="column" style="width:50%;">
<p><img data-src="images/xview_samples.jpg" style="width:100.0%"></p>
<p><strong>Created for disaster response</strong></p>
<p><strong>Applications:</strong> - YOLO training - Faster R-CNN - Small object detection - Infrastructure mapping</p>
</div></div>
<aside class="notes">
<p>xView is THE benchmark for object detection in satellite imagery. Created for disaster response applications, now widely used for testing detection algorithms like YOLO and Faster R-CNN.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="philippine-data-resources" class="slide level2 center">
<h2>Philippine Data Resources</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>PRiSM (PhilRice)</strong> - Rice area maps (wet/dry season) - Planting dates &amp; growth stages - Yield estimates - Since 2014 - https://prism.philrice.gov.ph/</p>
<p><strong>PhilSA Products</strong> - Flood extent maps (DATOS) - Mangrove extent mapping - Land cover classifications - Disaster damage assessments</p>
</div><div class="column" style="width:50%;">
<p><strong>DOST-ASTI Outputs</strong> - DATOS rapid flood mapping - Hazard susceptibility maps - AI-powered damage assessment - hazardhunter.georisk.gov.ph</p>
<p><strong>NAMRIA Geoportal</strong> - National land cover (2020) - Topographic basemaps - Administrative boundaries - Digital Elevation Models - www.geoportal.gov.ph</p>
</div></div>
<div class="fragment">
<p><strong>Use these as training/validation data - don’t start from scratch!</strong></p>
</div>
<aside class="notes">
<p>Philippine agencies have produced operational EO products that can serve as training or validation data for your ML models. Leverage existing work!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="data-centric-ai-2025-innovations" class="title-slide slide level1 center" data-background-color="#1e3a8a">
<h1>Data-Centric AI &amp; 2025 Innovations</h1>

</section>
<section id="paradigm-shift-model-centric-vs-data-centric" class="slide level2 center">
<h2>Paradigm Shift: Model-Centric vs Data-Centric</h2>

<img data-src="images/model_vs_data_centric.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><div class="columns">
<div class="column" style="width:50%;">
<p><strong>Model-Centric (Traditional)</strong></p>
<ul>
<li>Focus on improving algorithms</li>
<li>Keep data fixed</li>
<li>Try different models</li>
<li>Tune hyperparameters</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Data-Centric (Modern)</strong></p>
<ul>
<li>Focus on improving data</li>
<li>Keep model fixed</li>
<li>Clean and augment data</li>
<li>Better annotations</li>
</ul>
</div></div>
<aside class="notes">
<p>A lot of early ML progress focused on model algorithms. Data-Centric AI, popularized by Andrew Ng, advocates that improving your data often yields bigger gains.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="why-data-centric-matters-for-eo" class="slide level2 center">
<h2>Why Data-Centric Matters for EO</h2>
<p><strong>EO-Specific Data Challenges:</strong></p>
<ul>
<li class="fragment">Cloud contamination</li>
<li class="fragment">Atmospheric effects</li>
<li class="fragment">Sensor artifacts and noise</li>
<li class="fragment">Label uncertainty</li>
<li class="fragment">Geographic variability</li>
<li class="fragment">Temporal dynamics</li>
<li class="fragment">Class imbalance</li>
</ul>
<div class="fragment">
<p><strong>“Better data beats a cleverer model” in most cases</strong></p>
</div>
<aside class="notes">
<p>In EO, the “food” you feed your AI matters more than fancy model tweaks. Cloudy images, mislabeled points, or biased samples can derail any model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="research-data-efficiency" class="slide level2 center">
<h2>2025 Research: Data Efficiency</h2>

<img data-src="images/data_efficiency_research.png" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"><p><strong>Key Finding (ArXiv 2025):</strong></p>
<ul>
<li class="fragment">Some EO datasets reach <strong>optimal accuracy with &lt;20% of temporal instances</strong></li>
<li class="fragment"><strong>Single band</strong> from single modality can be sufficient</li>
<li class="fragment">Data efficiency crucial for operational systems</li>
<li class="fragment">Quality over quantity</li>
</ul>
<aside class="notes">
<p>Recent research shows you don’t always need all available data. Smart selection of temporal instances and bands can achieve similar accuracy with much less data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="four-pillars-of-data-centric-ai" class="slide level2 center">
<h2>Four Pillars of Data-Centric AI</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>1. Data Quality</strong></p>
<p><img data-src="images/data_quality.jpg" style="width:100.0%"></p>
<ul>
<li>Cloud/shadow removal</li>
<li>Atmospheric correction</li>
<li>Sensor calibration</li>
<li>Geometric accuracy</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>2. Data Quantity</strong></p>
<p><img data-src="images/data_quantity.jpg" style="width:100.0%"></p>
<ul>
<li>Sufficient training samples</li>
<li>Balanced classes</li>
<li>Data augmentation</li>
<li>Transfer learning</li>
</ul>
</div></div>
</section>
<section id="four-pillars-continued" class="slide level2 center">
<h2>Four Pillars (Continued)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>3. Data Diversity</strong></p>
<p><img data-src="images/data_diversity.jpg" style="width:100.0%"></p>
<ul>
<li>Multiple seasons</li>
<li>Different regions</li>
<li>Various conditions</li>
<li>Class variations</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>4. Label Quality</strong></p>
<p><img data-src="images/label_quality.jpg" style="width:100.0%"></p>
<ul>
<li>Clear definitions</li>
<li>Consistent protocols</li>
<li>Expert validation</li>
<li>Accurate geolocation</li>
</ul>
</div></div>
<aside class="notes">
<p>These four aspects - quality, quantity, diversity, and labels - determine model success more than architectural choices.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="data-quality" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>Data Quality</h1>

</section>
<section id="data-quality-in-eo" class="slide level2 center">
<h2>Data Quality in EO</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Common Issues:</strong></p>
<ul>
<li>Clouds and shadows</li>
<li>Haze and aerosols</li>
<li>Sensor artifacts (striping, banding)</li>
<li>Geometric misalignment</li>
<li>Radiometric inconsistencies</li>
<li>Mixed pixels at boundaries</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Solutions:</strong></p>
<ul>
<li>Use Level-2A products</li>
<li>Rigorous cloud masking</li>
<li>Quality flag filtering</li>
<li>Multi-temporal compositing</li>
<li>Validation checks</li>
<li>Document preprocessing</li>
</ul>
</div></div>
<aside class="notes">
<p>Satellite data can be noisy. Cloud masking, using atmospherically corrected products, and careful preprocessing are essential.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="quality-example-cloud-masking" class="slide level2 center">
<h2>Quality Example: Cloud Masking</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Without Cloud Masking</strong></p>
<p><img data-src="images/with_clouds.jpg" style="width:100.0%"></p>
<ul>
<li>Clouds misclassified</li>
<li>Shadows cause errors</li>
<li>Poor model performance</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>With Proper Masking</strong></p>
<p><img data-src="images/clouds_masked.jpg" style="width:100.0%"></p>
<ul>
<li>Clean training data</li>
<li>Accurate classifications</li>
<li>Better generalization</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>One cloudy image can ruin your training data!</strong></p>
</div>
<aside class="notes">
<p>Even a few cloudy training samples can teach the model wrong patterns. Rigorous cloud masking is non-negotiable.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="data-quantity" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>Data Quantity</h1>

</section>
<section id="how-much-data-do-you-need" class="slide level2 center">
<h2>How Much Data Do You Need?</h2>
<p><strong>Depends on:</strong></p>
<ul>
<li class="fragment">Model complexity (DL needs more)</li>
<li class="fragment">Problem difficulty</li>
<li class="fragment">Class separability</li>
<li class="fragment">Available features</li>
</ul>
<p><strong>General Guidelines:</strong></p>
<ul>
<li class="fragment"><strong>Traditional ML:</strong> 100s to 1000s of samples per class</li>
<li class="fragment"><strong>Deep Learning:</strong> 1000s to 10,000s per class</li>
<li class="fragment"><strong>Transfer Learning:</strong> Can work with 100s per class</li>
</ul>
<aside class="notes">
<p>Deep learning is data-hungry. Random Forest can work with smaller datasets. Transfer learning (starting from pre-trained models) reduces data requirements.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-augmentation" class="slide level2 center">
<h2>Data Augmentation</h2>

<img data-src="images/data_augmentation.jpg" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p><strong>Techniques:</strong></p>
<ul>
<li class="fragment">Rotation (90°, 180°, 270°)</li>
<li class="fragment">Flipping (horizontal, vertical)</li>
<li class="fragment">Brightness/contrast adjustment</li>
<li class="fragment">Adding noise</li>
<li class="fragment">Elastic deformations</li>
</ul>
<div class="fragment">
<p><strong>Result:</strong> 10x more training samples from existing data!</p>
</div>
<aside class="notes">
<p>Data augmentation synthetically increases dataset size by creating modified versions of existing samples. This helps models generalize better.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="transfer-learning" class="slide level2 center">
<h2>Transfer Learning</h2>

<img data-src="images/transfer_learning.png" class="quarto-figure quarto-figure-center r-stretch" style="width:75.0%"><div class="columns">
<div class="column" style="width:50%;">
<p><strong>Concept:</strong></p>
<ul>
<li>Start with model pre-trained on large dataset</li>
<li>Fine-tune on your specific task</li>
<li>Requires much less data</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>EO Applications:</strong></p>
<ul>
<li>Use ImageNet pre-trained models</li>
<li>NASA-IBM Geospatial Foundation Model</li>
<li>Domain-specific pre-training</li>
</ul>
</div></div>
<aside class="notes">
<p>Transfer learning leverages knowledge learned on large datasets and adapts it to your specific problem with much less data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="data-diversity" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>Data Diversity</h1>

</section>
<section id="why-diversity-matters" class="slide level2 center">
<h2>Why Diversity Matters</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Problem: Biased Training</strong></p>
<p><img data-src="images/biased_training.jpg" style="width:100.0%"></p>
<ul>
<li>All samples from one season</li>
<li>One geographic region only</li>
<li>Similar conditions</li>
<li><strong>Result:</strong> Model fails elsewhere</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Solution: Diverse Training</strong></p>
<p><img data-src="images/diverse_training.jpg" style="width:100.0%"></p>
<ul>
<li>Multiple seasons</li>
<li>Different regions</li>
<li>Various conditions</li>
<li><strong>Result:</strong> Model generalizes</li>
</ul>
</div></div>
<aside class="notes">
<p>Models trained on narrow datasets often fail when deployed in different conditions. Diversity in training data leads to better generalization.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="sources-of-diversity-needed" class="slide level2 center">
<h2>Sources of Diversity Needed</h2>
<p><strong>Temporal Diversity:</strong></p>
<ul>
<li class="fragment">Different seasons (wet/dry)</li>
<li class="fragment">Multiple years</li>
<li class="fragment">Phenological stages</li>
</ul>
<p><strong>Geographic Diversity:</strong></p>
<ul>
<li class="fragment">Different regions</li>
<li class="fragment">Various elevations</li>
<li class="fragment">Coastal vs inland</li>
</ul>
<p><strong>Atmospheric Diversity:</strong></p>
<ul>
<li class="fragment">Clear vs hazy days</li>
<li class="fragment">Different solar angles</li>
<li class="fragment">Seasonal lighting</li>
</ul>
<p><strong>Class Diversity:</strong></p>
<ul>
<li class="fragment">Variations within classes</li>
<li class="fragment">Edge cases</li>
<li class="fragment">Transitional zones</li>
</ul>
<aside class="notes">
<p>For robust models, ensure your training data covers the range of conditions the model will encounter in operational use.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="example-urban-classification" class="slide level2 center">
<h2>Example: Urban Classification</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Poor Diversity</strong></p>
<ul>
<li>Only Metro Manila samples</li>
<li>Only concrete roofs</li>
<li>Only high-density areas</li>
<li><strong>Fails</strong> in other cities</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Good Diversity</strong></p>
<ul>
<li>Large cities, small towns</li>
<li>Various roof materials (concrete, metal, nipa)</li>
<li>Different architectural styles</li>
<li>Different densities</li>
<li><strong>Works</strong> across Philippines</li>
</ul>
</div></div>
<aside class="notes">
<p>If training only on Metro Manila, the model might not recognize small towns or rural settlements with different characteristics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="label-quality" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>Label Quality</h1>

</section>
<section id="label-quality-is-critical" class="slide level2 center">
<h2>Label Quality is Critical</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Common Label Issues:</strong></p>
<ul>
<li>Mislabeled samples</li>
<li>Positional errors (GPS drift)</li>
<li>Temporal mismatch (old labels, new image)</li>
<li>Ambiguous classes</li>
<li>Inconsistent definitions</li>
<li>Mixed pixels</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Impact:</strong></p>
<ul>
<li>Model learns wrong patterns</li>
<li>Contradictory signals</li>
<li>Poor generalization</li>
<li>Low confidence predictions</li>
<li>Wasted compute</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>One bad label can corrupt model learning!</strong></p>
</div>
<aside class="notes">
<p>Ground truth labels might have errors - GPS inaccuracy, outdated information, or human mistakes. These errors propagate to model predictions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="label-quality-best-practices" class="slide level2 center">
<h2>Label Quality Best Practices</h2>
<p><strong>1. Clear Class Definitions</strong></p>
<ul>
<li class="fragment">Write explicit criteria</li>
<li class="fragment">Provide examples</li>
<li class="fragment">Define edge cases</li>
<li class="fragment">Document ambiguities</li>
</ul>
<p><strong>2. Consistent Protocols</strong></p>
<ul>
<li class="fragment">Standard operating procedures</li>
<li class="fragment">Same interpretation rules</li>
<li class="fragment">Calibration sessions</li>
<li class="fragment">Regular training for labelers</li>
</ul>
<p><strong>3. Multiple Annotators</strong></p>
<ul>
<li class="fragment">Independent labeling</li>
<li class="fragment">Compare for consistency</li>
<li class="fragment">Resolve disagreements</li>
<li class="fragment">Build consensus labels</li>
</ul>
<p><strong>4. Expert Validation</strong></p>
<ul>
<li class="fragment">Domain experts review samples</li>
<li class="fragment">Random quality checks</li>
<li class="fragment">Iterative improvement</li>
</ul>
<aside class="notes">
<p>Invest time in defining classes clearly and training labelers. Consistency matters more than speed.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="label-quality-example" class="slide level2 center">
<h2>Label Quality Example</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Poor Labels</strong></p>
<p><img data-src="images/poor_labels.jpg" style="width:100.0%"></p>
<ul>
<li>“Forest” defined inconsistently</li>
<li>Mixed with shrubland</li>
<li>Temporal mismatch</li>
<li>Positional errors</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>High-Quality Labels</strong></p>
<p><img data-src="images/good_labels.jpg" style="width:100.0%"></p>
<ul>
<li>Clear forest definition</li>
<li>Careful boundary delineation</li>
<li>Image-label temporal match</li>
<li>Validated position</li>
</ul>
</div></div>
<aside class="notes">
<p>High-quality labels are worth the effort. A smaller dataset with accurate labels often outperforms a larger dataset with noisy labels.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="alam-project-addressing-labels" class="slide level2 center">
<h2>ALaM Project: Addressing Labels</h2>

<img data-src="images/alam_project.jpg" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"><p><strong>DOST-ASTI’s Automated Labeling Machine</strong></p>
<ul>
<li class="fragment">Automates labeling process</li>
<li class="fragment">Crowdsourcing capabilities</li>
<li class="fragment">Expert validation workflow</li>
<li class="fragment"><strong>Addresses EO’s biggest bottleneck</strong></li>
</ul>
<aside class="notes">
<p>Remember from Session 1: DOST-ASTI’s ALaM project specifically addresses the label quality and quantity challenge through automation and crowdsourcing.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="practical-data-centric-tips" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>Practical Data-Centric Tips</h1>

</section>
<section id="data-centric-workflow" class="slide level2 center">
<h2>Data-Centric Workflow</h2>
<p><strong>Before Training:</strong></p>
<ol type="1">
<li class="fragment"><strong>Audit your data:</strong> Visualize samples, check distributions</li>
<li class="fragment"><strong>Clean aggressively:</strong> Remove clouds, fix labels, filter outliers</li>
<li class="fragment"><strong>Balance classes:</strong> Address imbalances through sampling or augmentation</li>
<li class="fragment"><strong>Document everything:</strong> Track data sources, preprocessing, versions</li>
</ol>
<p><strong>During Training:</strong></p>
<ol start="5" type="1">
<li class="fragment"><strong>Analyze errors:</strong> Which samples does model get wrong?</li>
<li class="fragment"><strong>Identify patterns:</strong> Are errors systematic? (e.g., all in one region)</li>
<li class="fragment"><strong>Fix data:</strong> Add more diverse samples, improve labels</li>
<li class="fragment"><strong>Iterate:</strong> Retrain with better data</li>
</ol>
<aside class="notes">
<p>Data-centric approach means continuously improving data quality based on model feedback. Look at errors to understand what data you’re missing.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-quality-checklist" class="slide level2 center">
<h2>Data Quality Checklist</h2>
<ul class="task-list">
<li class="fragment"><label><input type="checkbox">Atmospherically corrected (Level-2A)?</label></li>
<li class="fragment"><label><input type="checkbox">Clouds and shadows masked?</label></li>
<li class="fragment"><label><input type="checkbox">Geometric alignment verified?</label></li>
<li class="fragment"><label><input type="checkbox">Temporal consistency checked?</label></li>
<li class="fragment"><label><input type="checkbox">Label accuracy validated?</label></li>
<li class="fragment"><label><input type="checkbox">Classes clearly defined?</label></li>
<li class="fragment"><label><input type="checkbox">Training data balanced?</label></li>
<li class="fragment"><label><input type="checkbox">Geographic diversity ensured?</label></li>
<li class="fragment"><label><input type="checkbox">Seasonal coverage adequate?</label></li>
<li class="fragment"><label><input type="checkbox">Edge cases included?</label></li>
<li class="fragment"><label><input type="checkbox">Quality flags documented?</label></li>
</ul>
<aside class="notes">
<p>Use this checklist before training any model. Addressing data issues upfront saves time and improves results.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="case-study-better-data-better-results" class="slide level2 center">
<h2>Case Study: Better Data = Better Results</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Scenario:</strong></p>
<p>Coral reef mapping project</p>
<p><strong>Initial Results:</strong></p>
<ul>
<li>70% accuracy</li>
<li>Fails in turbid water</li>
<li>Confuses reef with sand</li>
</ul>
<p><strong>Problem Identified:</strong></p>
<p>All training data from clear water</p>
</div><div class="column" style="width:50%;">
<p><strong>Data-Centric Solution:</strong></p>
<ol type="1">
<li>Add turbid water samples</li>
<li>Include reef-sand transition zones</li>
<li>More diverse depths</li>
<li>Improve label precision</li>
</ol>
<p><strong>New Results:</strong></p>
<ul>
<li><strong>90% accuracy</strong></li>
<li>Works in turbid water</li>
<li>Better boundary detection</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>10x improvement from better data, same model!</strong></p>
</div>
<aside class="notes">
<p>Real example of how data improvements had bigger impact than model tuning. The data was the key, not the algorithm.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="developments" class="title-slide slide level1 center" data-background-color="#1e3a8a">
<h1>2025 Developments</h1>

</section>
<section id="foundation-models-for-eo" class="slide level2 center">
<h2>Foundation Models for EO</h2>

<img data-src="images/foundation_models.png" class="quarto-figure quarto-figure-center r-stretch" style="width:75.0%"><p><strong>What are Foundation Models?</strong></p>
<ul>
<li class="fragment">Large models pre-trained on massive EO datasets</li>
<li class="fragment">Learn general representations</li>
<li class="fragment">Fine-tune for specific tasks</li>
<li class="fragment"><strong>Dramatically reduce labeled data needs</strong></li>
</ul>
<p><strong>Examples (2025):</strong></p>
<ul>
<li class="fragment"><strong>NASA-IBM Geospatial Foundation Model</strong> (open-source, Aug 2024)</li>
<li class="fragment"><strong>Prithvi</strong> (IBM/NASA/ESA collaboration)</li>
<li class="fragment"><strong>Clay Foundation Model</strong> (open-source)</li>
<li class="fragment">Planet Labs + Anthropic Claude integration</li>
</ul>
<aside class="notes">
<p><strong>Timing:</strong> 4 minutes</p>
<p><strong>Key Points:</strong> - <strong>2025 Update:</strong> Foundation models are THE major innovation in EO AI - NASA-IBM model released August 2024 as open-source - Trained on massive Sentinel-2 datasets (1 billion parameters) - Can be fine-tuned with just hundreds of labeled samples (vs thousands before) - <strong>Philippine Application:</strong> Use foundation models to jumpstart projects with limited labeled data</p>
<p><strong>Example:</strong> “Instead of manually labeling 10,000 images for rice mapping, fine-tune Prithvi with just 500 samples and achieve similar accuracy”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="on-board-ai-processing" class="slide level2 center">
<h2>On-Board AI Processing</h2>

<img data-src="images/onboard_ai.jpg" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"><div class="columns">
<div class="column" style="width:50%;">
<p><strong>ESA Φsat-2 (Launched 2024)</strong></p>
<ul>
<li>22×10×33 cm CubeSat</li>
<li>Onboard AI computer (Intel Myriad X VPU)</li>
<li>Real-time cloud detection</li>
<li>Process before downlink</li>
<li><strong>Saves bandwidth</strong></li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Satellogic Edge Computing</strong></p>
<ul>
<li>“AI First” satellites</li>
<li>Onboard GPUs</li>
<li>Real-time processing</li>
<li>Immediate insights</li>
<li>Ship/object detection</li>
</ul>
</div></div>
<aside class="notes">
<p><strong>Timing:</strong> 3 minutes</p>
<p><strong>Key Points:</strong> - <strong>2025 Update:</strong> On-board AI is operational on multiple satellites - ESA’s Φsat-2 launched 2024 with Intel AI chip - Processes images on-orbit before transmitting - Use case: Only download cloud-free portions, save 90% bandwidth - Future: Real-time disaster detection from space</p>
<p><strong>Philippine Relevance:</strong> “Imagine typhoon damage detected and reported automatically from orbit within minutes, not hours”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="self-supervised-learning" class="slide level2 center">
<h2>Self-Supervised Learning</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><strong>Concept:</strong></p>
<ul>
<li>Learn from <strong>unlabeled data</strong></li>
<li>Define pretext tasks (e.g., predict missing patches)</li>
<li>Model learns useful representations</li>
<li>Fine-tune with small labeled dataset</li>
</ul>
<p><strong>Why Important for EO:</strong></p>
<ul>
<li>Abundance of unlabeled satellite imagery</li>
<li>High cost of labeling</li>
<li>Improves transferability</li>
</ul>
</div><div class="column" style="width:40%;">
<p><img data-src="images/self_supervised.png" style="width:100.0%"></p>
</div></div>
<aside class="notes">
<p>Self-supervised learning is particularly relevant for EO due to abundance of unlabeled imagery. Models learn useful features without expensive labeling.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="explainable-ai-xai" class="slide level2 center">
<h2>Explainable AI (XAI)</h2>

<img data-src="images/xai_methods.png" class="quarto-figure quarto-figure-center r-stretch" style="width:75.0%"><p><strong>Why XAI Matters:</strong></p>
<ul>
<li class="fragment">Understand model decisions</li>
<li class="fragment">Build trust in AI systems</li>
<li class="fragment">Debug and improve models</li>
<li class="fragment">Regulatory compliance</li>
</ul>
<p><strong>Methods:</strong></p>
<ul>
<li class="fragment"><strong>SHAP:</strong> Feature importance</li>
<li class="fragment"><strong>LIME:</strong> Local explanations</li>
<li class="fragment"><strong>Grad-CAM:</strong> Visual attention maps</li>
<li class="fragment"><strong>Saliency Maps:</strong> What pixels matter?</li>
</ul>
<aside class="notes">
<p>As AI systems make important decisions (disaster response, resource allocation), understanding why they make those decisions becomes crucial.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="summary-key-takeaways" class="title-slide slide level1 center" data-background-color="#1e3a8a">
<h1>Summary &amp; Key Takeaways</h1>

</section>
<section id="what-we-covered" class="slide level2 center">
<h2>What We Covered</h2>
<ol type="1">
<li class="fragment"><strong>AI/ML Basics:</strong> What it is and why it’s powerful for EO</li>
<li class="fragment"><strong>ML Workflow:</strong> 7-step process from problem to deployment</li>
<li class="fragment"><strong>Supervised Learning:</strong> Classification and regression with labeled data</li>
<li class="fragment"><strong>Unsupervised Learning:</strong> Clustering and pattern discovery</li>
<li class="fragment"><strong>Deep Learning:</strong> Neural networks and CNNs for images</li>
<li class="fragment"><strong>Data-Centric AI:</strong> Quality, quantity, diversity, labels</li>
<li class="fragment"><strong>2025 Trends:</strong> Foundation models, on-board AI, XAI</li>
</ol>
<aside class="notes">
<p>We’ve covered the fundamental concepts you need to understand before diving into hands-on implementation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="key-takeaways" class="slide level2 center">
<h2>Key Takeaways</h2>
<p><strong>1. Focus on Data First</strong></p>
<ul>
<li class="fragment">Quality beats quantity</li>
<li class="fragment">Diversity enables generalization</li>
<li class="fragment">Good labels are gold</li>
</ul>
<p><strong>2. Start Simple</strong></p>
<ul>
<li class="fragment">Try traditional ML before deep learning</li>
<li class="fragment">Random Forest is often enough</li>
<li class="fragment">Add complexity only when needed</li>
</ul>
<p><strong>3. Iterate Continuously</strong></p>
<ul>
<li class="fragment">Analyze errors</li>
<li class="fragment">Improve data</li>
<li class="fragment">Retrain models</li>
<li class="fragment">Deployment is not the end</li>
</ul>
<aside class="notes">
<p>These principles will serve you well throughout your AI/ML journey. Data quality and iterative improvement are more important than fancy algorithms.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="practical-advice" class="slide level2 center">
<h2>Practical Advice</h2>
<p><strong>For Your Projects:</strong></p>
<ul>
<li class="fragment"><strong>Define the problem clearly</strong> before collecting data</li>
<li class="fragment"><strong>Invest in high-quality training data</strong> - it’s worth it</li>
<li class="fragment"><strong>Validate rigorously</strong> on independent data</li>
<li class="fragment"><strong>Document everything</strong> (data sources, preprocessing, model versions)</li>
<li class="fragment"><strong>Start with baselines</strong> (simple models, existing methods)</li>
<li class="fragment"><strong>Iterate based on errors</strong> - let failures guide improvements</li>
<li class="fragment"><strong>Consider operational constraints</strong> early</li>
</ul>
<aside class="notes">
<p>These practical tips come from real-world experience. Following them will save you time and frustration.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-data-centric-mindset" class="slide level2 center">
<h2>The Data-Centric Mindset</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>When model performs poorly, ask:</strong></p>
<ol type="1">
<li>Is my data clean?</li>
<li>Are labels accurate?</li>
<li>Is training data representative?</li>
<li>Do I have enough diversity?</li>
<li>Are there systematic biases?</li>
</ol>
</div><div class="column" style="width:50%;">
<p><strong>Before trying:</strong></p>
<ul>
<li>More complex model</li>
<li>More epochs</li>
<li>Different hyperparameters</li>
<li>New architecture</li>
</ul>
<p><strong>Check your data first!</strong></p>
</div></div>
<div class="fragment">
<p><strong>“Better data beats a cleverer model” - Andrew Ng</strong></p>
</div>
<aside class="notes">
<p>Adopt a data-centric mindset. When models underperform, investigate data issues before blaming the algorithm.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="connection-to-sessions-3-4" class="slide level2 center">
<h2>Connection to Sessions 3 &amp; 4</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Session 3: Python Basics</strong></p>
<ul>
<li>Load and explore data</li>
<li>GeoPandas (vector)</li>
<li>Rasterio (raster)</li>
<li><strong>Foundation for all ML work</strong></li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Session 4: Google Earth Engine</strong></p>
<ul>
<li>Access Sentinel data at scale</li>
<li>Cloud masking (data quality!)</li>
<li>Temporal compositing</li>
<li>Export for ML workflows</li>
</ul>
</div></div>
<div class="fragment">
<p><strong>Everything builds on these concepts!</strong></p>
</div>
<aside class="notes">
<p>The hands-on sessions this afternoon put these concepts into practice. You’ll actually work with data and see these principles in action.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="looking-ahead-days-2-4" class="slide level2 center">
<h2>Looking Ahead: Days 2-4</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Day 2:</strong></p>
<ul>
<li>Random Forest classification</li>
<li>Land cover mapping</li>
<li>CNN basics</li>
<li>TensorFlow/Keras intro</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Days 3-4:</strong></p>
<ul>
<li>U-Net for segmentation</li>
<li>Flood mapping (DRR focus)</li>
<li>Time series with LSTMs</li>
<li>Foundation models</li>
<li>Explainable AI</li>
</ul>
</div></div>
<aside class="notes">
<p>Over the next three days, we’ll implement these concepts in real EO applications for DRR, CCA, and NRM.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="resources-for-continued-learning" class="slide level2 center">
<h2>Resources for Continued Learning</h2>
<p><strong>Online Courses:</strong></p>
<ul>
<li class="fragment">NASA ARSET: ML for Earth Science</li>
<li class="fragment">EO College: Introduction to ML for EO</li>
<li class="fragment">Coursera: Machine Learning (Andrew Ng)</li>
<li class="fragment">Fast.ai: Practical Deep Learning</li>
</ul>
<p><strong>Papers &amp; Tutorials:</strong></p>
<ul>
<li class="fragment">“Data-Centric ML for Earth Observation” (ArXiv 2025)</li>
<li class="fragment">Google Earth Engine tutorials</li>
<li class="fragment">TensorFlow Earth Observation tutorials</li>
</ul>
<p><strong>Communities:</strong></p>
<ul>
<li class="fragment">SkAI-Pinas network</li>
<li class="fragment">Digital Space Campus (CoPhil)</li>
<li class="fragment">DIMER model repository</li>
</ul>
<aside class="notes">
<p>These resources will support your continued learning after the training. The Digital Space Campus will have all our materials for reference.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="session-summary" class="slide level2 center">
<h2>Session Summary</h2>
<p><strong>What We Covered:</strong></p>
<p>✅ AI/ML/DL definitions and relationships<br>
✅ End-to-end ML workflow for EO<br>
✅ Supervised learning (classification, regression)<br>
✅ Unsupervised learning (clustering)<br>
✅ Deep learning &amp; CNNs for satellite imagery<br>
✅ Data-centric AI philosophy<br>
✅ <strong>2025 innovations:</strong> Foundation models, on-board AI</p>
<aside class="notes">
<p><strong>Timing:</strong> 2 minutes</p>
<p>You now have conceptual foundation for all ML work in this course. Sessions 3-4 today and Days 2-4 will implement these concepts.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="qa" class="slide level2 center">
<h2>Q&amp;A</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>AI/ML Concepts</strong></p>
<ul>
<li>Supervised vs unsupervised?</li>
<li>When to use deep learning?</li>
<li>Foundation models for my use case?</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Practical Questions</strong></p>
<ul>
<li>Data quality challenges?</li>
<li>Label collection strategies?</li>
<li>Computing requirements?</li>
</ul>
</div></div>
<aside class="notes">
<p><strong>Timing:</strong> 5-8 minutes for Q&amp;A</p>
<p><strong>Common Questions:</strong> - “Do I need a GPU?” → Not for Random Forest, yes for deep learning - “How many labels do I need?” → Depends: 100s with foundation models, 1000s for CNN from scratch - “Which algorithm should I use?” → Start simple (RF), then deep learning if needed - “Can I use foundation models for Philippines?” → Yes! They’re global and open-source</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="next-session-3" class="title-slide slide level1 center" data-background-color="#0f766e">
<h1>Next: Session 3</h1>

</section>
<section id="hands-on-python-for-geospatial-data" class="slide level2 center">
<h2>Hands-on Python for Geospatial Data</h2>
<p><strong>Coming up after 15-minute break:</strong></p>
<ul>
<li>Google Colab environment setup</li>
<li>GeoPandas for vector data</li>
<li>Rasterio for raster data</li>
<li>Work with Philippine boundaries</li>
<li>Load and visualize Sentinel-2 imagery</li>
<li>Calculate NDVI</li>
</ul>
<div class="fragment">
<p><strong>Get ready to code! 💻</strong></p>
</div>
</section></section>
<section>
<section id="thank-you" class="title-slide slide level1 center" data-background-color="#1e3a8a">
<h1>Thank You!</h1>

</section>
<section id="resources" class="slide level2 center">
<h2>Resources</h2>
<p><strong>Foundation Models:</strong><br>
NASA-IBM Geospatial: <a href="https://huggingface.co/ibm-nasa-geospatial" class="uri">https://huggingface.co/ibm-nasa-geospatial</a><br>
Prithvi: <a href="https://github.com/NASA-IMPACT/Prithvi" class="uri">https://github.com/NASA-IMPACT/Prithvi</a><br>
Clay: <a href="https://clay-foundation.github.io" class="uri">https://clay-foundation.github.io</a></p>
<p><strong>Learning:</strong><br>
NASA ARSET: <a href="https://appliedsciences.nasa.gov/arset" class="uri">https://appliedsciences.nasa.gov/arset</a><br>
EO College: <a href="https://eo-college.org" class="uri">https://eo-college.org</a><br>
SkAI-Pinas: <a href="https://asti.dost.gov.ph/skai-pinas" class="uri">https://asti.dost.gov.ph/skai-pinas</a></p>
<aside class="notes">
<p><strong>Session 2 Complete!</strong></p>
<p>15-minute break before Session 3. Make sure participants have: - Google Colab access working - GEE account registration started (will finalize in Session 4)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>Day 1 Session 2 | AI/ML Fundamentals | 20-23 October 2025</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'h.v',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/DimitrisKasabalis\.github\.io\/cophil-training-v1\.0");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script src="https://utteranc.es/client.js" repo="cophil-training-v1.0" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
    </script>
    

</body></html>