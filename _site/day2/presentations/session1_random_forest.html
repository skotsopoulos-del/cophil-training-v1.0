<!DOCTYPE html>
<html lang="en"><head>
<link href="../../images/favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="author" content="Stylianos Kotsopoulos">
  <title>CoPhil EO AI/ML Training ‚Äì Session 1: Supervised Classification with Random Forest</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-a52660f024e6f9788c15754c389b1b96.css">
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-509191933"></script>

  <script type="text/javascript">

  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-509191933', { 'anonymize_ip': true});
  </script>
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
  <script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
  <link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Session 1: Supervised Classification with Random Forest</h1>
  <p class="subtitle">Theory and Practice for Earth Observation</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Stylianos Kotsopoulos 
</div>
        <p class="quarto-title-affiliation">
            EU-Philippines CoPhil Programme
          </p>
    </div>
</div>

</section>
<section id="session-overview" class="slide level2 smaller">
<h2>Session Overview</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Part A: Theory (1.5 hours)</strong></p>
<ul>
<li>Introduction to Supervised Classification</li>
<li>Decision Trees Fundamentals</li>
<li>Random Forest Ensemble Method</li>
<li>Feature Importance</li>
<li>Accuracy Assessment</li>
<li>Google Earth Engine Platform</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Part B: Hands-on Lab (1.5 hours)</strong></p>
<ul>
<li>Sentinel-2 Data Acquisition</li>
<li>Feature Engineering (Spectral Indices)</li>
<li>Training Data Preparation</li>
<li>Model Training &amp; Optimization</li>
<li>Classification &amp; Validation</li>
<li>Philippine NRM Applications</li>
</ul>
</div></div>
<p><strong>Learning Objectives:</strong></p>
<ul>
<li>Understand supervised classification workflow for EO data</li>
<li>Implement Random Forest using Google Earth Engine</li>
<li>Perform accuracy assessment and interpret results</li>
<li>Apply classification to Palawan land cover mapping</li>
</ul>
</section>
<section class="slide level2">

</section>
<section>
<section id="part-a-theory" class="title-slide slide level1 center" data-background-color="#2C5F77">
<h1>Part A: Theory</h1>

</section>
<section id="what-is-supervised-classification" class="slide level2">
<h2>What is Supervised Classification?</h2>
<ul>
<li class="fragment"><strong>Goal:</strong> Assign labels to pixels/objects based on their characteristics</li>
<li class="fragment"><strong>‚ÄúSupervised‚Äù:</strong> We provide labeled training examples to the algorithm</li>
<li class="fragment"><strong>Learning Process:</strong> Algorithm learns patterns from training data</li>
<li class="fragment"><strong>Application:</strong> Classify entire image based on learned patterns</li>
</ul>
<div class="fragment">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Key Concept</strong></p>
</div>
<div class="callout-content">
<p>Supervised classification requires <strong>labeled training data</strong> (ground truth) to learn the relationship between spectral signatures and land cover classes.</p>
</div>
</div>
</div>
</div>
</section>
<section id="supervised-classification-workflow" class="slide level2">
<h2>Supervised Classification Workflow</h2>
<div class="cell" data-reveal="true" data-fig-width="10" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    A[Satellite Imagery] --&gt; B[Preprocessing]
    B --&gt; C[Feature Extraction]
    C --&gt; D[Training Data Collection]
    D --&gt; E[Model Training]
    E --&gt; F[Classification]
    F --&gt; G[Accuracy Assessment]
    G --&gt; H{Acceptable?}
    H --&gt;|No| D
    H --&gt;|Yes| I[Final Map]
    style E fill:#4A90E2
    style F fill:#4A90E2
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><strong>Key Steps:</strong></p>
<ol type="1">
<li><strong>Preprocessing:</strong> Cloud masking, atmospheric correction</li>
<li><strong>Feature Extraction:</strong> Spectral bands, indices (NDVI, NDWI)</li>
<li><strong>Training Data:</strong> Collect representative samples for each class</li>
<li><strong>Model Training:</strong> Train classifier on training data</li>
<li><strong>Classification:</strong> Apply model to entire scene</li>
<li><strong>Validation:</strong> Assess accuracy with independent test data</li>
</ol>
</section>
<section id="common-land-cover-classes-in-philippines" class="slide level2">
<h2>Common Land Cover Classes in Philippines</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Natural Ecosystems:</strong></p>
<ul>
<li>Primary Forest (dipterocarp)</li>
<li>Secondary Forest</li>
<li>Mangroves</li>
<li>Grasslands</li>
<li>Water Bodies (rivers, lakes, coastal)</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Human-Modified:</strong></p>
<ul>
<li>Agricultural Land (rice paddies, coconut)</li>
<li>Urban/Built-up Areas</li>
<li>Bare Soil</li>
<li>Mining Areas</li>
<li>Roads and Infrastructure</li>
</ul>
</div></div>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Philippine Context</strong></p>
</div>
<div class="callout-content">
<p>Accurate land cover classification supports monitoring of <strong>Protected Areas</strong>, <strong>REDD+ programs</strong>, <strong>agricultural expansion</strong>, and <strong>disaster response</strong> (typhoons, floods).</p>
</div>
</div>
</div>
</div>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="decision-trees" class="title-slide slide level1 center" data-background-color="#2C5F77">
<h1>Decision Trees</h1>

</section>
<section id="what-is-a-decision-tree" class="slide level2">
<h2>What is a Decision Tree?</h2>
<p>A tree-like structure that makes decisions by asking a series of questions about features.</p>
<div class="columns">
<div class="column" style="width:60%;">
<div class="cell" data-reveal="true" data-fig-width="8" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[NDVI &gt; 0.4?] --&gt;|Yes| B[NIR &gt; 3000?]
    A --&gt;|No| C[NDWI &gt; 0?]
    B --&gt;|Yes| D[Forest]
    B --&gt;|No| E[Agriculture]
    C --&gt;|Yes| F[Water]
    C --&gt;|No| G[Urban/Bare]
    style D fill:#2E7D32
    style E fill:#FBC02D
    style F fill:#1976D2
    style G fill:#757575
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div><div class="column" style="width:40%;">
<p><strong>How it Works:</strong></p>
<ol type="1">
<li>Start at root node</li>
<li>Test condition (e.g., NDVI &gt; 0.4?)</li>
<li>Branch based on answer</li>
<li>Repeat until reaching leaf node</li>
<li>Leaf node = predicted class</li>
</ol>
</div></div>
</section>
<section id="decision-tree-splitting" class="slide level2">
<h2>Decision Tree Splitting</h2>
<p><strong>How does a tree decide where to split?</strong></p>
<ul>
<li class="fragment"><strong>Goal:</strong> Create pure nodes (all samples belong to one class)</li>
<li class="fragment"><strong>Metric:</strong> Information Gain or Gini Impurity</li>
<li class="fragment"><strong>Process:</strong> Test all possible splits, choose the best one</li>
<li class="fragment"><strong>Recursion:</strong> Repeat for each branch until stopping criteria</li>
</ul>
<div class="fragment">
<p><strong>Gini Impurity Formula:</strong></p>
<p><span class="math display">\[
Gini = 1 - \sum_{i=1}^{n} (p_i)^2
\]</span></p>
<p>Where <span class="math inline">\(p_i\)</span> is the probability of class <span class="math inline">\(i\)</span> in the node.</p>
<ul>
<li><strong>Gini = 0:</strong> Pure node (all samples same class) ‚úì</li>
<li><strong>Gini = 0.5:</strong> Maximum impurity (50/50 split) ‚úó</li>
</ul>
</div>
</section>
<section id="decision-tree-example-spectral-splitting" class="slide level2">
<h2>Decision Tree Example: Spectral Splitting</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Split 1</a></li><li><a href="#tabset-1-2">Split 2</a></li><li><a href="#tabset-1-3">Split 3</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<p><strong>Root Node: All 1000 samples</strong></p>
<p>Test: <strong>NDVI &gt; 0.4?</strong></p>
<ul>
<li><strong>Left branch (NDVI ‚â§ 0.4):</strong> 400 samples ‚Üí Mostly Water, Urban, Bare</li>
<li><strong>Right branch (NDVI &gt; 0.4):</strong> 600 samples ‚Üí Mostly Forest, Agriculture</li>
</ul>
<p><strong>Information Gain:</strong> High ‚úì (classes becoming more separated)</p>
</div>
<div id="tabset-1-2">
<p><strong>Right Branch: 600 samples with NDVI &gt; 0.4</strong></p>
<p>Test: <strong>NIR Reflectance &gt; 3000?</strong></p>
<ul>
<li><strong>Left branch (NIR ‚â§ 3000):</strong> 250 samples ‚Üí Agriculture (less canopy density)</li>
<li><strong>Right branch (NIR &gt; 3000):</strong> 350 samples ‚Üí Forest (dense canopy)</li>
</ul>
<p><strong>Information Gain:</strong> High ‚úì</p>
</div>
<div id="tabset-1-3">
<p><strong>Left Branch: 400 samples with NDVI ‚â§ 0.4</strong></p>
<p>Test: <strong>NDWI &gt; 0?</strong></p>
<ul>
<li><strong>Left branch (NDWI ‚â§ 0):</strong> 200 samples ‚Üí Urban/Bare</li>
<li><strong>Right branch (NDWI &gt; 0):</strong> 200 samples ‚Üí Water</li>
</ul>
<p><strong>Information Gain:</strong> High ‚úì</p>
</div>
</div>
</div>
</section>
<section id="decision-tree-advantages-limitations" class="slide level2">
<h2>Decision Tree Advantages &amp; Limitations</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Advantages:</strong></p>
<ul>
<li>‚úì Easy to understand and visualize</li>
<li>‚úì No data normalization needed</li>
<li>‚úì Handles non-linear relationships</li>
<li>‚úì Feature importance easily extracted</li>
<li>‚úì Fast prediction</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Limitations:</strong></p>
<ul>
<li>‚úó <strong>Overfitting:</strong> Can memorize training data</li>
<li>‚úó <strong>High variance:</strong> Small data changes ‚Üí big tree changes</li>
<li>‚úó <strong>Instability:</strong> Greedy algorithm (local optima)</li>
<li>‚úó <strong>Bias:</strong> Favor features with many levels</li>
</ul>
</div></div>
<div class="fragment">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>The Solution</strong></p>
</div>
<div class="callout-content">
<p><strong>Random Forest</strong> addresses these limitations by combining many decision trees!</p>
</div>
</div>
</div>
</div>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="random-forest" class="title-slide slide level1 center" data-background-color="#2C5F77">
<h1>Random Forest</h1>

</section>
<section id="what-is-random-forest" class="slide level2">
<h2>What is Random Forest?</h2>
<p>An <strong>ensemble learning</strong> method that combines many decision trees to improve accuracy and reduce overfitting.</p>
<div class="columns">
<div class="column" style="width:60%;">
<div class="cell" data-reveal="true" data-fig-width="9" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[Training Data&lt;br/&gt;1000 samples] --&gt; B1[Bootstrap&lt;br/&gt;Sample 1]
    A --&gt; B2[Bootstrap&lt;br/&gt;Sample 2]
    A --&gt; B3[Bootstrap&lt;br/&gt;Sample 3]
    A --&gt; B4[...]
    A --&gt; B5[Bootstrap&lt;br/&gt;Sample N]

    B1 --&gt; T1[Tree 1]
    B2 --&gt; T2[Tree 2]
    B3 --&gt; T3[Tree 3]
    B4 --&gt; T4[...]
    B5 --&gt; T5[Tree N]

    T1 --&gt; V[Majority Vote]
    T2 --&gt; V
    T3 --&gt; V
    T4 --&gt; V
    T5 --&gt; V

    V --&gt; F[Final Prediction]

    style F fill:#4CAF50
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div><div class="column" style="width:40%;">
<p><strong>Key Ideas:</strong></p>
<ol type="1">
<li><strong>Bootstrap Aggregating (Bagging)</strong>
<ul>
<li>Random sampling with replacement</li>
<li>Each tree sees different data</li>
</ul></li>
<li><strong>Random Feature Selection</strong>
<ul>
<li>Each split uses random subset of features</li>
<li>Reduces correlation between trees</li>
</ul></li>
<li><strong>Majority Voting</strong>
<ul>
<li>Classification: Most common class</li>
<li>Regression: Average prediction</li>
</ul></li>
</ol>
</div></div>
</section>
<section id="random-forest-the-forest-analogy" class="slide level2">
<h2>Random Forest: The ‚ÄúForest‚Äù Analogy</h2>
<ul>
<li class="fragment"><strong>One tree (Decision Tree):</strong> One expert‚Äôs opinion
<ul>
<li class="fragment">Can be very confident but sometimes wrong</li>
<li class="fragment">Might overfit to specific training examples</li>
</ul></li>
<li class="fragment"><strong>Forest (Random Forest):</strong> Committee of experts
<ul>
<li class="fragment">Each expert sees slightly different data</li>
<li class="fragment">Each expert considers different features</li>
<li class="fragment">Final decision: Majority vote</li>
<li class="fragment"><strong>Wisdom of crowds:</strong> Group decision more reliable than individual</li>
</ul></li>
</ul>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Intuition</strong></p>
</div>
<div class="callout-content">
<p>If you ask 100 independent experts and 75 say ‚ÄúForest‚Äù, you can be more confident than if only 1 expert says ‚ÄúForest‚Äù.</p>
</div>
</div>
</div>
</div>
</section>
<section id="bootstrap-aggregating-bagging" class="slide level2">
<h2>Bootstrap Aggregating (Bagging)</h2>
<p><strong>Bootstrap Sampling:</strong></p>
<ul>
<li>Original training set: 1000 samples</li>
<li>Each tree gets: 1000 samples (with replacement)</li>
<li>Some samples repeated, some never selected (~37% out-of-bag)</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Original Data:</strong></p>
<pre><code>Sample IDs: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10</code></pre>
<p><strong>Tree 1 Bootstrap:</strong></p>
<pre><code>Sample IDs: 1, 3, 3, 5, 7, 7, 7, 9, 9, 10</code></pre>
<p><strong>Tree 2 Bootstrap:</strong></p>
<pre><code>Sample IDs: 2, 2, 4, 5, 5, 6, 8, 8, 9, 10</code></pre>
</div><div class="column" style="width:50%;">
<p><strong>Why Bootstrap?</strong></p>
<ul>
<li>Introduces diversity between trees</li>
<li>Each tree specializes on different samples</li>
<li>Reduces overfitting</li>
<li>Enables Out-of-Bag (OOB) validation</li>
</ul>
<p><strong>Out-of-Bag Samples:</strong> - Samples not used by a tree (~37%) - Used for internal validation - No separate validation set needed</p>
</div></div>
</section>
<section id="random-feature-selection" class="slide level2">
<h2>Random Feature Selection</h2>
<p>At each split, only consider a <strong>random subset</strong> of features.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>All Features (13 for Sentinel-2 + indices):</strong></p>
<ul>
<li>B2 (Blue)</li>
<li>B3 (Green)</li>
<li>B4 (Red)</li>
<li>B8 (NIR)</li>
<li>B11 (SWIR1)</li>
<li>B12 (SWIR2)</li>
<li>NDVI</li>
<li>NDWI</li>
<li>NDBI</li>
<li>EVI</li>
<li>SAVI</li>
<li>Texture features</li>
<li>Elevation</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Random Subset at Each Split:</strong></p>
<p><strong>Typical:</strong> <span class="math inline">\(\sqrt{n}\)</span> features</p>
<p>For 13 features: <span class="math inline">\(\sqrt{13} \approx 4\)</span> features</p>
<p><strong>Tree 1, Split 1:</strong> {NDVI, B4, B11, Elevation}</p>
<p><strong>Tree 1, Split 2:</strong> {B8, NDWI, B3, SAVI}</p>
<p><strong>Tree 2, Split 1:</strong> {NDBI, B12, NDVI, B2}</p>
<p>. . .</p>
<p><strong>Result:</strong> - Trees decorrelated - Prevents strong features from dominating - Better generalization</p>
</div></div>
</section>
<section id="random-forest-prediction-majority-voting" class="slide level2">
<h2>Random Forest Prediction: Majority Voting</h2>
<p><strong>Example Classification:</strong></p>
<p>Classify a pixel with spectral signature: <strong>NDVI=0.65, NIR=4500, SWIR=2000</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>100 Trees Vote:</strong></p>
<ul>
<li>Tree 1 ‚Üí <strong>Forest</strong> üå≤</li>
<li>Tree 2 ‚Üí <strong>Forest</strong> üå≤</li>
<li>Tree 3 ‚Üí <strong>Agriculture</strong> üåæ</li>
<li>Tree 4 ‚Üí <strong>Forest</strong> üå≤</li>
<li>Tree 5 ‚Üí <strong>Forest</strong> üå≤</li>
<li>‚Ä¶</li>
<li>Tree 100 ‚Üí <strong>Forest</strong> üå≤</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Vote Count:</strong></p>
<ul>
<li><strong>Forest:</strong> 78 votes</li>
<li><strong>Agriculture:</strong> 22 votes</li>
</ul>
<p><strong>Final Prediction:</strong> <strong>Forest</strong> (78%)</p>
<p><strong>Confidence:</strong> 78% confidence in prediction</p>
</div></div>
<div class="fragment">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Prediction Confidence</strong></p>
</div>
<div class="callout-content">
<p>The proportion of votes can be interpreted as <strong>confidence</strong>. Higher consensus ‚Üí more confident prediction.</p>
</div>
</div>
</div>
</div>
</section>
<section id="random-forest-hyperparameters" class="slide level2">
<h2>Random Forest Hyperparameters</h2>
<p><strong>Key parameters to tune:</strong></p>
<table class="caption-top" style="width:100%;">
<colgroup>
<col style="width: 22%">
<col style="width: 27%">
<col style="width: 33%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
<th>Typical Values</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>n_trees</strong></td>
<td>Number of trees in forest</td>
<td>50-500</td>
<td>More trees ‚Üí better performance (diminishing returns)</td>
</tr>
<tr class="even">
<td><strong>max_depth</strong></td>
<td>Maximum depth of each tree</td>
<td>10-50 or None</td>
<td>Deeper ‚Üí more complex, risk overfitting</td>
</tr>
<tr class="odd">
<td><strong>min_samples_split</strong></td>
<td>Min samples to split node</td>
<td>2-10</td>
<td>Higher ‚Üí simpler trees, less overfitting</td>
</tr>
<tr class="even">
<td><strong>max_features</strong></td>
<td>Features per split</td>
<td><span class="math inline">\(\sqrt{n}\)</span> or <span class="math inline">\(\log_2(n)\)</span></td>
<td>Balance between accuracy and diversity</td>
</tr>
<tr class="odd">
<td><strong>bootstrap</strong></td>
<td>Use bootstrap sampling</td>
<td>True</td>
<td>Almost always True for RF</td>
</tr>
</tbody>
</table>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Google Earth Engine Default</strong></p>
</div>
<div class="callout-content">
<p>GEE‚Äôs <code>ee.Classifier.smileRandomForest()</code> defaults: - <strong>numberOfTrees:</strong> 100 - <strong>variablesPerSplit:</strong> <span class="math inline">\(\sqrt{n}\)</span> (automatic) - <strong>minLeafPopulation:</strong> 1</p>
</div>
</div>
</div>
</div>
</section>
<section id="random-forest-advantages" class="slide level2">
<h2>Random Forest Advantages</h2>
<ol type="1">
<li class="fragment"><strong>High Accuracy</strong>
<ul>
<li class="fragment">Often achieves excellent performance out-of-the-box</li>
<li class="fragment">Handles complex non-linear relationships</li>
</ul></li>
<li class="fragment"><strong>Robust to Overfitting</strong>
<ul>
<li class="fragment">Ensemble averaging reduces variance</li>
<li class="fragment">Harder to overfit than single decision tree</li>
</ul></li>
<li class="fragment"><strong>Feature Importance</strong>
<ul>
<li class="fragment">Quantifies which features matter most</li>
<li class="fragment">Helps understand classification drivers</li>
</ul></li>
<li class="fragment"><strong>Handles Missing Data</strong>
<ul>
<li class="fragment">Can work with incomplete feature sets</li>
<li class="fragment">Robust to noisy data</li>
</ul></li>
<li class="fragment"><strong>No Normalization Needed</strong>
<ul>
<li class="fragment">Works with features on different scales</li>
<li class="fragment">Simplifies preprocessing</li>
</ul></li>
<li class="fragment"><strong>Efficient</strong>
<ul>
<li class="fragment">Fast training (parallelizable)</li>
<li class="fragment">Fast prediction</li>
</ul></li>
</ol>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="feature-importance" class="title-slide slide level1 center" data-background-color="#2C5F77">
<h1>Feature Importance</h1>

</section>
<section id="understanding-feature-importance" class="slide level2">
<h2>Understanding Feature Importance</h2>
<p><strong>Question:</strong> Which spectral bands/indices contribute most to classification accuracy?</p>
<p><strong>Feature Importance</strong> measures the contribution of each feature to the model‚Äôs predictions.</p>
<div class="columns">
<div class="column" style="width:60%;">
<p><strong>Calculation Methods:</strong></p>
<ol type="1">
<li><strong>Mean Decrease in Impurity (MDI)</strong>
<ul>
<li>How much each feature reduces impurity (Gini)</li>
<li>Averaged across all trees</li>
<li>Default in most implementations</li>
</ul></li>
<li><strong>Permutation Importance</strong>
<ul>
<li>Measure accuracy drop when feature is randomly shuffled</li>
<li>More reliable but slower</li>
</ul></li>
</ol>
</div><div class="column" style="width:40%;">
<p><strong>Interpretation:</strong></p>
<ul>
<li><strong>High importance:</strong> Feature strongly discriminates classes</li>
<li><strong>Low importance:</strong> Feature adds little information</li>
<li><strong>Zero importance:</strong> Feature not used by any tree</li>
</ul>
</div></div>
</section>
<section id="example-feature-importance-for-palawan" class="slide level2">
<h2>Example: Feature Importance for Palawan</h2>
<p><strong>Land Cover Classification (7 classes)</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Top Features:</strong></p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Rank</th>
<th>Feature</th>
<th>Importance</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><strong>NDVI</strong></td>
<td>0.285</td>
<td>Forest vs.&nbsp;non-forest</td>
</tr>
<tr class="even">
<td>2</td>
<td><strong>NIR (B8)</strong></td>
<td>0.192</td>
<td>Vegetation density</td>
</tr>
<tr class="odd">
<td>3</td>
<td><strong>SWIR1 (B11)</strong></td>
<td>0.156</td>
<td>Moisture content</td>
</tr>
<tr class="even">
<td>4</td>
<td><strong>NDWI</strong></td>
<td>0.128</td>
<td>Water detection</td>
</tr>
<tr class="odd">
<td>5</td>
<td><strong>Red (B4)</strong></td>
<td>0.089</td>
<td>Vegetation health</td>
</tr>
<tr class="even">
<td>6</td>
<td><strong>NDBI</strong></td>
<td>0.067</td>
<td>Urban areas</td>
</tr>
<tr class="odd">
<td>7</td>
<td><strong>Elevation</strong></td>
<td>0.045</td>
<td>Topographic context</td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:50%;">
<p><strong>Insights:</strong></p>
<ul>
<li><strong>NDVI dominant:</strong> Vegetation indices most important</li>
<li><strong>NIR crucial:</strong> Distinguishes vegetation types</li>
<li><strong>SWIR useful:</strong> Separates forest from agriculture</li>
<li><strong>NDWI essential:</strong> Water body identification</li>
<li><strong>Elevation helps:</strong> Mountains ‚Üí forest, lowlands ‚Üí agriculture</li>
</ul>
<p><strong>Actionable:</strong> - Focus on acquiring high-quality NIR and SWIR data - Ensure accurate NDVI calculation - Include DEM for improved accuracy</p>
</div></div>
</section>
<section id="feature-importance-visualization" class="slide level2">
<h2>Feature Importance Visualization</h2>
<p><strong>Typical Output:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a><span class="co"># Example feature importance from trained RF</span></span>
<span id="cb4-2"><a></a>Feature Importances:</span>
<span id="cb4-3"><a></a>‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span>
<span id="cb4-4"><a></a>NDVI        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  <span class="fl">0.285</span></span>
<span id="cb4-5"><a></a>NIR         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           <span class="fl">0.192</span></span>
<span id="cb4-6"><a></a>SWIR1       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             <span class="fl">0.156</span></span>
<span id="cb4-7"><a></a>NDWI        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                <span class="fl">0.128</span></span>
<span id="cb4-8"><a></a>Red         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     <span class="fl">0.089</span></span>
<span id="cb4-9"><a></a>NDBI        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       <span class="fl">0.067</span></span>
<span id="cb4-10"><a></a>Elevation   ‚ñà‚ñà‚ñà‚ñà‚ñà                         <span class="fl">0.045</span></span>
<span id="cb4-11"><a></a>Blue        ‚ñà‚ñà‚ñà                           <span class="fl">0.020</span></span>
<span id="cb4-12"><a></a>Green       ‚ñà‚ñà‚ñà                           <span class="fl">0.018</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Applications:</strong></p>
<ul>
<li><strong>Feature selection:</strong> Remove low-importance features</li>
<li><strong>Data collection priorities:</strong> Focus on important bands</li>
<li><strong>Model interpretation:</strong> Understand classification logic</li>
<li><strong>Domain validation:</strong> Does importance match EO theory?</li>
</ul>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="accuracy-assessment" class="title-slide slide level1 center" data-background-color="#2C5F77">
<h1>Accuracy Assessment</h1>

</section>
<section id="trainingtest-data-splitting" class="slide level2">
<h2>Training/Test Data Splitting</h2>
<p><strong>Critical Decision:</strong> How to split data for training vs.&nbsp;validation?</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Common Split Ratios:</strong></p>
<table class="caption-top">
<thead>
<tr class="header">
<th><strong>Split</strong></th>
<th><strong>Training</strong></th>
<th><strong>Testing</strong></th>
<th><strong>Use Case</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>80/20</td>
<td>80%</td>
<td>20%</td>
<td>Standard (sufficient data)</td>
</tr>
<tr class="even">
<td>70/30</td>
<td>70%</td>
<td>30%</td>
<td>More robust validation</td>
</tr>
<tr class="odd">
<td>60/40</td>
<td>60%</td>
<td>40%</td>
<td>Limited training data</td>
</tr>
<tr class="even">
<td>50/50</td>
<td>50%</td>
<td>50%</td>
<td>Very small datasets</td>
</tr>
</tbody>
</table>
<p><strong>Google Earth Engine:</strong> Use <code>.randomColumn()</code> to assign splits</p>
</div><div class="column" style="width:50%;">
<p><strong>Splitting Strategies:</strong></p>
<p><strong>1. Random Split</strong> (most common)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a><span class="co"># Add random column</span></span>
<span id="cb5-2"><a></a>data <span class="op">=</span> data.randomColumn(<span class="st">'random'</span>)</span>
<span id="cb5-3"><a></a></span>
<span id="cb5-4"><a></a><span class="co"># Split 80/20</span></span>
<span id="cb5-5"><a></a>training <span class="op">=</span> data.<span class="bu">filter</span>(ee.Filter.lt(<span class="st">'random'</span>, <span class="fl">0.8</span>))</span>
<span id="cb5-6"><a></a>testing <span class="op">=</span> data.<span class="bu">filter</span>(ee.Filter.gte(<span class="st">'random'</span>, <span class="fl">0.8</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>2. Stratified Split</strong> (recommended) - Maintain class proportions in both sets - Important for imbalanced datasets - Ensures all classes in test set</p>
<p><strong>3. Spatial Split</strong> - Training from one region, testing from another - Tests geographic transferability - More realistic for operational use</p>
</div></div>
<aside class="notes">
<p>Random 80/20 is standard, but stratified ensures each class has representation in test set. Spatial split is most rigorous - tests if model works in new areas.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="why-accuracy-assessment" class="slide level2">
<h2>Why Accuracy Assessment?</h2>
<ul>
<li class="fragment"><strong>Quantify performance:</strong> How good is the classification?</li>
<li class="fragment"><strong>Compare models:</strong> Which classifier performs better?</li>
<li class="fragment"><strong>Identify weaknesses:</strong> Which classes are confused?</li>
<li class="fragment"><strong>Build confidence:</strong> Can we trust the map for decisions?</li>
<li class="fragment"><strong>Report to stakeholders:</strong> Scientific credibility</li>
</ul>
<div class="fragment">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Golden Rule</strong></p>
</div>
<div class="callout-content">
<p><strong>ALWAYS</strong> use <strong>independent test data</strong> that was NOT used for training. Otherwise, you‚Äôre measuring memorization, not generalization.</p>
</div>
</div>
</div>
</div>
</section>
<section id="confusion-matrix" class="slide level2">
<h2>Confusion Matrix</h2>
<p>A table showing <strong>predicted classes</strong> vs.&nbsp;<strong>actual classes</strong> for test data.</p>
<p><strong>Example: 5-class classification</strong></p>
<table class="caption-top" style="width:100%;">
<colgroup>
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Predicted ‚Üí</strong></th>
<th>Forest</th>
<th>Agriculture</th>
<th>Water</th>
<th>Urban</th>
<th>Bare</th>
<th><strong>Total</strong></th>
<th><strong>User‚Äôs Acc</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Actual ‚Üì</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><strong>Forest</strong></td>
<td></td>
<td><strong>85</strong></td>
<td>8</td>
<td>0</td>
<td>2</td>
<td>5</td>
<td>100</td>
<td>85%</td>
</tr>
<tr class="odd">
<td><strong>Agriculture</strong></td>
<td></td>
<td>12</td>
<td><strong>73</strong></td>
<td>0</td>
<td>5</td>
<td>10</td>
<td>100</td>
<td>73%</td>
</tr>
<tr class="even">
<td><strong>Water</strong></td>
<td></td>
<td>0</td>
<td>1</td>
<td><strong>95</strong></td>
<td>2</td>
<td>2</td>
<td>100</td>
<td>95%</td>
</tr>
<tr class="odd">
<td><strong>Urban</strong></td>
<td></td>
<td>3</td>
<td>7</td>
<td>3</td>
<td><strong>82</strong></td>
<td>5</td>
<td>100</td>
<td>82%</td>
</tr>
<tr class="even">
<td><strong>Bare</strong></td>
<td></td>
<td>5</td>
<td>11</td>
<td>2</td>
<td>9</td>
<td><strong>78</strong></td>
<td>105</td>
<td>74%</td>
</tr>
<tr class="odd">
<td><strong>Total</strong></td>
<td></td>
<td>105</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>505</td>
<td></td>
</tr>
<tr class="even">
<td><strong>Producer‚Äôs Acc</strong></td>
<td></td>
<td>81%</td>
<td>73%</td>
<td>95%</td>
<td>82%</td>
<td>78%</td>
<td></td>
<td><strong>OA: 82.6%</strong></td>
</tr>
</tbody>
</table>
</section>
<section id="accuracy-metrics-explained" class="slide level2">
<h2>Accuracy Metrics Explained</h2>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-2-1">Overall Accuracy</a></li><li><a href="#tabset-2-2">Producer‚Äôs Accuracy</a></li><li><a href="#tabset-2-3">User‚Äôs Accuracy</a></li><li><a href="#tabset-2-4">Kappa Coefficient</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1">
<p><strong>Definition:</strong> Percentage of correctly classified samples</p>
<p><span class="math display">\[
\text{Overall Accuracy} = \frac{\text{Correct Predictions}}{\text{Total Samples}} = \frac{85+73+95+82+78}{505} = \frac{413}{500} = 82.6\%
\]</span></p>
<p><strong>Interpretation:</strong> - Simple, intuitive metric - <strong>Limitation:</strong> Can be misleading with imbalanced classes</p>
<p><strong>Example:</strong> 95% accuracy sounds great, but if 95% of pixels are forest, a ‚Äúclassify everything as forest‚Äù model achieves 95%!</p>
</div>
<div id="tabset-2-2">
<p><strong>Definition:</strong> Percentage of actual class correctly identified (per class)</p>
<p>Also called: <strong>Recall</strong>, <strong>Sensitivity</strong></p>
<p><span class="math display">\[
\text{Producer's Accuracy}_{\text{Forest}} = \frac{85}{105} = 81\%
\]</span></p>
<p><strong>Interpretation:</strong> - ‚ÄúOf all actual forest pixels, how many did we correctly identify?‚Äù - <strong>Producer‚Äôs perspective:</strong> How complete is the map? - Low producer‚Äôs accuracy ‚Üí <strong>omission error</strong> (missing true positives)</p>
<p><strong>Example:</strong> 81% for Forest means we missed 19% of actual forest pixels.</p>
</div>
<div id="tabset-2-3">
<p><strong>Definition:</strong> Percentage of predicted class that is correct (per class)</p>
<p>Also called: <strong>Precision</strong>, <strong>Positive Predictive Value</strong></p>
<p><span class="math display">\[
\text{User's Accuracy}_{\text{Forest}} = \frac{85}{100} = 85\%
\]</span></p>
<p><strong>Interpretation:</strong> - ‚ÄúOf all pixels we labeled as forest, how many are truly forest?‚Äù - <strong>User‚Äôs perspective:</strong> How reliable is the map? - Low user‚Äôs accuracy ‚Üí <strong>commission error</strong> (false positives)</p>
<p><strong>Example:</strong> 85% for Forest means 15% of ‚Äúforest‚Äù pixels are actually other classes.</p>
</div>
<div id="tabset-2-4">
<p><strong>Definition:</strong> Measure of agreement beyond chance</p>
<p><span class="math display">\[
\kappa = \frac{p_o - p_e}{1 - p_e}
\]</span></p>
<p>Where: - <span class="math inline">\(p_o\)</span> = observed accuracy (overall accuracy) - <span class="math inline">\(p_e\)</span> = expected accuracy by chance</p>
<p><strong>Interpretation:</strong> - <strong>Œ∫ &lt; 0.4:</strong> Poor agreement - <strong>Œ∫ = 0.4-0.6:</strong> Moderate agreement - <strong>Œ∫ = 0.6-0.8:</strong> Good agreement - <strong>Œ∫ &gt; 0.8:</strong> Excellent agreement</p>
<p><strong>Why use Kappa?</strong> Accounts for agreement by random chance, especially important for imbalanced datasets.</p>
</div>
</div>
</div>
</section>
<section id="common-confusion-patterns" class="slide level2">
<h2>Common Confusion Patterns</h2>
<p><strong>Example:</strong> Forest vs.&nbsp;Agriculture confusion</p>
<table class="caption-top">
<thead>
<tr class="header">
<th></th>
<th>Predicted Forest</th>
<th>Predicted Agriculture</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Actual Forest</strong></td>
<td>85</td>
<td><strong>8</strong> ‚Üê Confusion</td>
</tr>
<tr class="even">
<td><strong>Actual Agriculture</strong></td>
<td><strong>12</strong> ‚Üê Confusion</td>
<td>73</td>
</tr>
</tbody>
</table>
<p><strong>Why confusion occurs:</strong></p>
<ol type="1">
<li class="fragment"><strong>Spectral Similarity</strong>
<ul>
<li class="fragment">Tree crops (coconut, fruit trees) look like forest</li>
<li class="fragment">Young forest regeneration looks like agriculture</li>
</ul></li>
<li class="fragment"><strong>Mixed Pixels</strong>
<ul>
<li class="fragment">Agroforestry systems</li>
<li class="fragment">Forest edges with agriculture</li>
</ul></li>
<li class="fragment"><strong>Temporal Variability</strong>
<ul>
<li class="fragment">Agriculture changes rapidly (planting, harvesting)</li>
<li class="fragment">Single-date imagery may miss phenology</li>
</ul></li>
<li class="fragment"><strong>Class Definition Ambiguity</strong>
<ul>
<li class="fragment">Where does ‚Äúforest‚Äù end and ‚Äútree plantation‚Äù begin?</li>
</ul></li>
</ol>
</section>
<section id="best-practices-training-data-collection" class="slide level2">
<h2>Best Practices: Training Data Collection</h2>
<p><strong>Practical Tips for High-Quality Training Samples:</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Sample Size Guidelines:</strong></p>
<table class="caption-top">
<thead>
<tr class="header">
<th><strong>Class</strong></th>
<th><strong>Min Samples</strong></th>
<th><strong>Recommended</strong></th>
<th><strong>Notes</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Common (forest)</td>
<td>50</td>
<td>100-200</td>
<td>More coverage</td>
</tr>
<tr class="even">
<td>Moderate (agriculture)</td>
<td>50</td>
<td>100-150</td>
<td>Capture variability</td>
</tr>
<tr class="odd">
<td>Rare (bare soil)</td>
<td>30</td>
<td>50-100</td>
<td>Get what you can</td>
</tr>
</tbody>
</table>
<p><strong>Sampling Strategies:</strong></p>
<p><strong>1. Stratified Random:</strong> - Distribute samples across study area - Avoid clustering in one region - Ensure all sub-types represented</p>
<p><strong>2. Purposive Sampling:</strong> - Target known pure pixels - Use high-resolution imagery (Google Earth) - Field visits when possible</p>
</div><div class="column" style="width:50%;">
<p><strong>Quality Criteria:</strong></p>
<p><strong>‚úì Pure Pixels</strong> - Homogeneous within polygon - Avoid edges and mixed areas - Use ‚â•3x3 pixel minimum areas</p>
<p><strong>‚úì Clear Definition</strong> - Unambiguous class membership - Document class definitions - Use consistent interpretation rules</p>
<p><strong>‚úì Temporal Match</strong> - Training data date matches imagery - Account for phenology (crops) - Update for multi-temporal analysis</p>
<p><strong>Philippine-Specific Tips:</strong> - Use <strong>PhilSA Space+ Dashboard</strong> for recent imagery - Leverage <strong>NAMRIA land cover</strong> for reference - Consult <strong>LGU land use plans</strong> for urban areas - Use <strong>Google Street View</strong> for ground truth</p>
</div></div>
<aside class="notes">
<p>Quality training data is more important than quantity. 100 high-quality samples beats 500 noisy samples. For Philippine applications, leverage existing government datasets as starting points.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="improving-classification-accuracy" class="slide level2">
<h2>Improving Classification Accuracy</h2>
<div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-3-1">Better Training Data</a></li><li><a href="#tabset-3-2">More Features</a></li><li><a href="#tabset-3-3">Better Model</a></li><li><a href="#tabset-3-4">Post-Processing</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1">
<ul>
<li><strong>More samples:</strong> 50-100 per class minimum</li>
<li><strong>Better quality:</strong> Pure pixels, clear boundaries</li>
<li><strong>Balanced:</strong> Equal samples per class</li>
<li><strong>Representative:</strong> Cover all variations within class</li>
<li><strong>Distributed:</strong> Spatial coverage across study area</li>
</ul>
</div>
<div id="tabset-3-2">
<ul>
<li><strong>Multi-temporal data:</strong> Capture seasonal differences</li>
<li><strong>Texture features:</strong> Spatial patterns (GLCM)</li>
<li><strong>Topographic features:</strong> Elevation, slope, aspect</li>
<li><strong>Radar data:</strong> Sentinel-1 SAR (cloud-free)</li>
<li><strong>Ancillary data:</strong> Roads, protected areas</li>
</ul>
</div>
<div id="tabset-3-3">
<ul>
<li><strong>Hyperparameter tuning:</strong> Optimize RF parameters</li>
<li><strong>More trees:</strong> 200-500 trees (diminishing returns after ~300)</li>
<li><strong>Cross-validation:</strong> Ensure generalization</li>
<li><strong>Ensemble methods:</strong> Combine RF with other classifiers</li>
</ul>
</div>
<div id="tabset-3-4">
<ul>
<li><strong>Majority filter:</strong> Smooth noisy pixels</li>
<li><strong>Minimum mapping unit:</strong> Remove small isolated pixels</li>
<li><strong>Expert rules:</strong> Apply domain knowledge</li>
<li><strong>Visual inspection:</strong> Manual correction of obvious errors</li>
</ul>
</div>
</div>
</div>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="google-earth-engine" class="title-slide slide level1 center" data-background-color="#2C5F77">
<h1>Google Earth Engine</h1>

</section>
<section id="why-google-earth-engine" class="slide level2">
<h2>Why Google Earth Engine?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Challenges with Desktop GIS:</strong></p>
<ul>
<li>‚úó Downloading large satellite data</li>
<li>‚úó Storage requirements (TBs)</li>
<li>‚úó Computational limitations</li>
<li>‚úó Manual preprocessing</li>
<li>‚úó Time-consuming workflows</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Google Earth Engine Solutions:</strong></p>
<ul>
<li>‚úì <strong>Petabyte-scale catalog</strong> (Landsat, Sentinel, MODIS‚Ä¶)</li>
<li>‚úì <strong>Cloud computing</strong> (no downloads)</li>
<li>‚úì <strong>Pre-processed data</strong> (atmospherically corrected)</li>
<li>‚úì <strong>Scalable processing</strong> (parallel)</li>
<li>‚úì <strong>Free for research</strong> &amp; education</li>
</ul>
</div></div>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Perfect for This Course</strong></p>
</div>
<div class="callout-content">
<p>GEE enables us to process years of Sentinel-2 data for entire provinces in minutes!</p>
</div>
</div>
</div>
</div>
</section>
<section id="google-earth-engine-architecture" class="slide level2">
<h2>Google Earth Engine Architecture</h2>
<div class="cell" data-reveal="true" data-fig-width="10" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[User Code&lt;br/&gt;Python/JavaScript] --&gt; B[GEE API]
    B --&gt; C[GEE Cloud&lt;br/&gt;Processing]

    D[Satellite Data&lt;br/&gt;Catalog] --&gt; C
    E[Landsat&lt;br/&gt;1972-present] --&gt; D
    F[Sentinel-1/2&lt;br/&gt;2014-present] --&gt; D
    G[MODIS&lt;br/&gt;2000-present] --&gt; D
    H[Climate Data&lt;br/&gt;ERA5, etc.] --&gt; D

    C --&gt; I[Results]
    I --&gt; J[Interactive Map]
    I --&gt; K[Export to Drive]
    I --&gt; L[Charts/Stats]

    style C fill:#4285F4
    style D fill:#34A853
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><strong>Key Concepts:</strong></p>
<ul>
<li><strong>Server-side processing:</strong> Code runs on Google servers, not your laptop</li>
<li><strong>Lazy evaluation:</strong> Operations queued, executed only when needed (e.g., map display, export)</li>
<li><strong>Parallel processing:</strong> Automatically distributed across many machines</li>
</ul>
</section>
<section id="gee-data-catalog-highlights" class="slide level2">
<h2>GEE Data Catalog Highlights</h2>
<p><strong>Relevant for Philippine EO:</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Optical Imagery:</strong></p>
<ul>
<li><strong>Sentinel-2 MSI:</strong> 10m, 13 bands, 5-day revisit</li>
<li><strong>Landsat 8/9 OLI:</strong> 30m, 11 bands, 16-day revisit</li>
<li><strong>MODIS:</strong> 250-500m, daily, long time series</li>
</ul>
<p><strong>Radar:</strong></p>
<ul>
<li><strong>Sentinel-1 SAR:</strong> 10m, cloud-free, day/night</li>
</ul>
<p><strong>Terrain:</strong></p>
<ul>
<li><strong>SRTM DEM:</strong> 30m elevation</li>
<li><strong>ALOS World 3D:</strong> 30m (better for SE Asia)</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Climate:</strong></p>
<ul>
<li><strong>ERA5:</strong> Hourly reanalysis (temp, precip)</li>
<li><strong>CHIRPS:</strong> Daily rainfall</li>
<li><strong>MODIS LST:</strong> Land surface temperature</li>
</ul>
<p><strong>Pre-processed Products:</strong></p>
<ul>
<li><strong>Hansen Global Forest Change:</strong> Annual tree cover loss</li>
<li><strong>ESA WorldCover:</strong> Global 10m land cover</li>
<li><strong>Global Surface Water:</strong> Water occurrence</li>
</ul>
</div></div>
</section>
<section id="gee-code-editor-vs.-python-api" class="slide level2">
<h2>GEE Code Editor vs.&nbsp;Python API</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>JavaScript (Code Editor)</strong></p>
<ul>
<li><strong>Pros:</strong>
<ul>
<li>Browser-based (no installation)</li>
<li>Interactive map interface</li>
<li>Built-in visualization</li>
<li>Great for exploration</li>
</ul></li>
<li><strong>Cons:</strong>
<ul>
<li>Limited to GEE environment</li>
<li>Harder to integrate with other tools</li>
<li>Less powerful for data science</li>
</ul></li>
</ul>
<p><strong>Use Case:</strong> Quick exploration, visualization</p>
</div><div class="column" style="width:50%;">
<p><strong>Python API</strong></p>
<ul>
<li><strong>Pros:</strong>
<ul>
<li>Integrate with NumPy, Pandas, scikit-learn</li>
<li>Jupyter notebooks</li>
<li>Reproducible workflows</li>
<li>Version control (Git)</li>
<li>Advanced analysis</li>
</ul></li>
<li><strong>Cons:</strong>
<ul>
<li>Requires installation/setup</li>
<li>Slightly steeper learning curve</li>
</ul></li>
</ul>
<p><strong>Use Case:</strong> Reproducible research, production workflows</p>
</div></div>
<div class="fragment">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Our Approach</strong></p>
</div>
<div class="callout-content">
<p>We‚Äôll use <strong>Python API</strong> with <strong>geemap</strong> library for best of both worlds: Python ecosystem + interactive maps!</p>
</div>
</div>
</div>
</div>
</section>
<section id="gee-random-forest-workflow" class="slide level2">
<h2>GEE Random Forest Workflow</h2>
<p><strong>High-level workflow for today‚Äôs lab:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="im">import</span> ee</span>
<span id="cb6-2"><a></a><span class="im">import</span> geemap</span>
<span id="cb6-3"><a></a></span>
<span id="cb6-4"><a></a><span class="co"># 1. Initialize GEE</span></span>
<span id="cb6-5"><a></a>ee.Initialize()</span>
<span id="cb6-6"><a></a></span>
<span id="cb6-7"><a></a><span class="co"># 2. Load Sentinel-2 imagery</span></span>
<span id="cb6-8"><a></a>s2 <span class="op">=</span> ee.ImageCollection(<span class="st">'COPERNICUS/S2_SR'</span>) <span class="op">\</span></span>
<span id="cb6-9"><a></a>    .filterBounds(palawan_boundary) <span class="op">\</span></span>
<span id="cb6-10"><a></a>    .filterDate(<span class="st">'2024-01-01'</span>, <span class="st">'2024-12-31'</span>) <span class="op">\</span></span>
<span id="cb6-11"><a></a>    .<span class="bu">filter</span>(ee.Filter.lt(<span class="st">'CLOUDY_PIXEL_PERCENTAGE'</span>, <span class="dv">20</span>))</span>
<span id="cb6-12"><a></a></span>
<span id="cb6-13"><a></a><span class="co"># 3. Compute composite and indices</span></span>
<span id="cb6-14"><a></a>composite <span class="op">=</span> s2.median()</span>
<span id="cb6-15"><a></a>ndvi <span class="op">=</span> composite.normalizedDifference([<span class="st">'B8'</span>, <span class="st">'B4'</span>]).rename(<span class="st">'NDVI'</span>)</span>
<span id="cb6-16"><a></a>ndwi <span class="op">=</span> composite.normalizedDifference([<span class="st">'B3'</span>, <span class="st">'B8'</span>]).rename(<span class="st">'NDWI'</span>)</span>
<span id="cb6-17"><a></a></span>
<span id="cb6-18"><a></a><span class="co"># 4. Stack features</span></span>
<span id="cb6-19"><a></a>features <span class="op">=</span> composite.select([<span class="st">'B2'</span>,<span class="st">'B3'</span>,<span class="st">'B4'</span>,<span class="st">'B8'</span>,<span class="st">'B11'</span>,<span class="st">'B12'</span>]) <span class="op">\</span></span>
<span id="cb6-20"><a></a>    .addBands([ndvi, ndwi])</span>
<span id="cb6-21"><a></a></span>
<span id="cb6-22"><a></a><span class="co"># 5. Sample training data</span></span>
<span id="cb6-23"><a></a>training <span class="op">=</span> features.sampleRegions(collection<span class="op">=</span>training_polygons,</span>
<span id="cb6-24"><a></a>                                   properties<span class="op">=</span>[<span class="st">'class'</span>],</span>
<span id="cb6-25"><a></a>                                   scale<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb6-26"><a></a></span>
<span id="cb6-27"><a></a><span class="co"># 6. Train Random Forest</span></span>
<span id="cb6-28"><a></a>classifier <span class="op">=</span> ee.Classifier.smileRandomForest(numberOfTrees<span class="op">=</span><span class="dv">100</span>) <span class="op">\</span></span>
<span id="cb6-29"><a></a>    .train(features<span class="op">=</span>training, classProperty<span class="op">=</span><span class="st">'class'</span>, inputProperties<span class="op">=</span>features.bandNames())</span>
<span id="cb6-30"><a></a></span>
<span id="cb6-31"><a></a><span class="co"># 7. Classify image</span></span>
<span id="cb6-32"><a></a>classified <span class="op">=</span> features.classify(classifier)</span>
<span id="cb6-33"><a></a></span>
<span id="cb6-34"><a></a><span class="co"># 8. Visualize</span></span>
<span id="cb6-35"><a></a>Map <span class="op">=</span> geemap.Map()</span>
<span id="cb6-36"><a></a>Map.addLayer(classified, vis_params, <span class="st">'Land Cover'</span>)</span>
<span id="cb6-37"><a></a>Map</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="philippine-nrm-applications" class="title-slide slide level1 center" data-background-color="#2C5F77">
<h1>Philippine NRM Applications</h1>

</section>
<section id="forest-monitoring-denr-redd" class="slide level2">
<h2>Forest Monitoring (DENR, REDD+)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Challenges:</strong></p>
<ul>
<li>7,641 islands, 30 million hectares</li>
<li>Cloud cover year-round</li>
<li>Rapid deforestation in some areas</li>
<li>Limited ground-based monitoring</li>
</ul>
<p><strong>RF Classification Helps:</strong></p>
<ul>
<li>Annual forest cover maps</li>
<li>Deforestation hotspot detection</li>
<li>REDD+ MRV (Monitoring, Reporting, Verification)</li>
<li>Protected area encroachment</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Example: Palawan Biosphere Reserve</strong></p>
<ul>
<li><strong>Area:</strong> 1.1 million hectares</li>
<li><strong>Protection:</strong> UNESCO MAB, NIPAS</li>
<li><strong>Threats:</strong> Illegal logging, mining, agriculture</li>
</ul>
<p><strong>Workflow:</strong></p>
<ol type="1">
<li>Annual Sentinel-2 composites (2016-2024)</li>
<li>RF classification (primary forest, secondary, non-forest)</li>
<li>Change detection (forest loss/gain)</li>
<li>Alert system for encroachment</li>
<li>Reports for PCSDS, DENR</li>
</ol>
</div></div>
</section>
<section id="agricultural-monitoring-da-philrice" class="slide level2">
<h2>Agricultural Monitoring (DA, PhilRice)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Rice Production Monitoring:</strong></p>
<ul>
<li><strong>Goal:</strong> Estimate planted area and yield</li>
<li><strong>Importance:</strong> Food security planning</li>
<li><strong>Traditional method:</strong> Field surveys (slow, expensive)</li>
</ul>
<p><strong>RF Approach:</strong></p>
<ul>
<li>Multi-temporal Sentinel-2 (capture crop phenology)</li>
<li>Training data from field surveys</li>
<li>Classify: Rice, Other crops, Non-ag</li>
<li>Area calculation per province/municipality</li>
<li>Early warning for production shortfalls</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Example: Central Luzon Rice Bowl</strong></p>
<p><strong>Classes:</strong> - Rice (wet season) - Rice (dry season) - Vegetables - Fallow/bare - Non-agricultural</p>
<p><strong>Features:</strong> - NDVI time series (captures growth cycle) - LSWI (Land Surface Water Index) - EVI (Enhanced Vegetation Index)</p>
<p><strong>Validation:</strong> - PhilRice field surveys - DA crop cut experiments</p>
</div></div>
</section>
<section id="urban-expansion-monitoring-neda-hlurb" class="slide level2">
<h2>Urban Expansion Monitoring (NEDA, HLURB)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Metro Manila &amp; Major Cities:</strong></p>
<ul>
<li><strong>Rapid urbanization:</strong> 3-5% annual growth</li>
<li><strong>Planning needs:</strong> Infrastructure, transport, housing</li>
<li><strong>Environmental concerns:</strong> Loss of green space, flooding</li>
</ul>
<p><strong>RF Classification:</strong></p>
<ul>
<li>Urban/built-up</li>
<li>Roads and infrastructure</li>
<li>Vegetation (parks, trees)</li>
<li>Bare soil (construction sites)</li>
<li>Water bodies</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Applications:</strong></p>
<ol type="1">
<li><strong>Urban growth tracking</strong>
<ul>
<li>Compare 2015 vs.&nbsp;2024</li>
<li>Identify sprawl patterns</li>
<li>Predict future expansion</li>
</ul></li>
<li><strong>Green space monitoring</strong>
<ul>
<li>Urban vegetation loss</li>
<li>Park accessibility analysis</li>
</ul></li>
<li><strong>Flood risk</strong>
<ul>
<li>Impervious surface mapping</li>
<li>Drainage planning</li>
</ul></li>
<li><strong>Compliance</strong>
<ul>
<li>Illegal construction detection</li>
<li>Zoning violations</li>
</ul></li>
</ol>
</div></div>
</section>
<section id="water-resources-nwrb-lgus" class="slide level2">
<h2>Water Resources (NWRB, LGUs)</h2>
<p><strong>Applications:</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Surface Water Mapping:</strong></p>
<ul>
<li>Rivers, lakes, reservoirs</li>
<li>Seasonal variations</li>
<li>Drought monitoring</li>
<li>Flood extent mapping</li>
</ul>
<p><strong>RF Advantages:</strong> - NDWI as strong predictor - Multi-temporal captures seasonal changes - Can detect small water bodies</p>
</div><div class="column" style="width:50%;">
<p><strong>Watershed Management:</strong></p>
<ul>
<li>Land cover within watersheds</li>
<li>Forest cover (water regulation)</li>
<li>Agriculture (erosion risk)</li>
<li>Urban (runoff)</li>
</ul>
<p><strong>Example: Angat Dam Watershed</strong> - Critical for Metro Manila water supply - Monitor forest cover changes - Detect encroachment - Sediment risk assessment</p>
</div></div>
</section>
<section id="disaster-response-ndrrmc-pagasa" class="slide level2">
<h2>Disaster Response (NDRRMC, PAGASA)</h2>
<p><strong>Post-Typhoon Damage Assessment:</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Challenge:</strong> - Philippines: ~20 typhoons/year - Rapid assessment needed for relief - Cloud-free imagery rare after storms</p>
<p><strong>RF Classification Approach:</strong></p>
<ol type="1">
<li><strong>Pre-event baseline:</strong> Land cover map</li>
<li><strong>Post-event imagery:</strong> First clear Sentinel-2</li>
<li><strong>Damage classes:</strong>
<ul>
<li>Intact forest/vegetation</li>
<li>Damaged vegetation</li>
<li>Exposed soil/landslides</li>
<li>Flooded areas</li>
<li>Building damage (requires very high res)</li>
</ul></li>
</ol>
</div><div class="column" style="width:50%;">
<p><strong>Example: Typhoon Odette (2021)</strong></p>
<ul>
<li><strong>Affected:</strong> Visayas, Mindanao</li>
<li><strong>Assessment needs:</strong>
<ul>
<li>Agricultural damage (coconut, rice)</li>
<li>Forest destruction</li>
<li>Coastal erosion</li>
<li>Flooded areas</li>
</ul></li>
</ul>
<p><strong>RF Workflow:</strong> - Pre-typhoon: December 2021 composite - Post-typhoon: January 2022 composite - Classify: Intact, Damaged, Destroyed - Area statistics per municipality - Priority areas for relief</p>
</div></div>
</section>
<section id="recap-session-1-theory" class="slide level2">
<h2>Recap: Session 1 Theory</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>What We Learned:</strong></p>
<p>‚úì Supervised classification workflow</p>
<p>‚úì Decision trees: Intuitive but limited</p>
<p>‚úì Random Forest: Ensemble of trees - Bootstrap sampling - Random feature selection - Majority voting</p>
<p>‚úì Feature importance: Which bands matter?</p>
<p>‚úì Accuracy assessment: - Confusion matrix - Overall, Producer‚Äôs, User‚Äôs accuracy - Kappa coefficient</p>
<p>‚úì Google Earth Engine: Cloud-based EO</p>
</div><div class="column" style="width:50%;">
<p><strong>Key Takeaways:</strong></p>
<ol type="1">
<li>Random Forest is <strong>powerful</strong> for EO classification
<ul>
<li>High accuracy</li>
<li>Handles non-linear relationships</li>
<li>Robust to overfitting</li>
</ul></li>
<li><strong>Training data quality</strong> is critical
<ul>
<li>Representative samples</li>
<li>Balanced classes</li>
<li>Sufficient quantity</li>
</ul></li>
<li><strong>Feature engineering</strong> improves results
<ul>
<li>Spectral indices (NDVI, NDWI)</li>
<li>Multi-temporal data</li>
<li>Auxiliary data (DEM)</li>
</ul></li>
<li><strong>Accuracy assessment</strong> builds confidence
<ul>
<li>Always use independent test data</li>
<li>Understand confusion patterns</li>
</ul></li>
</ol>
</div></div>
</section>
<section id="break" class="slide level2" data-background-color="#FBC02D">
<h2>Break</h2>
<p><strong>15-minute break before hands-on lab</strong></p>
<div class="r-fit-text">
<p>üî∏ Stretch</p>
<p>üî∏ Coffee/water</p>
<p>üî∏ Check your setup: - Google Earth Engine account - Python environment activated - Jupyter notebook ready</p>
</div>
<p><strong>Coming up:</strong> Hands-on lab with Palawan land cover classification!</p>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="part-b-hands-on-lab" class="title-slide slide level1 center" data-background-color="#2C5F77">
<h1>Part B: Hands-on Lab</h1>

</section>
<section id="lab-overview" class="slide level2">
<h2>Lab Overview</h2>
<p><strong>What We‚Äôll Build:</strong> Palawan Land Cover Classification using Random Forest</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Steps:</strong></p>
<ol type="1">
<li>Setup and authentication</li>
<li>Load Sentinel-2 imagery</li>
<li>Create cloud-free composite</li>
<li>Calculate spectral indices</li>
<li>Prepare training data</li>
<li>Train Random Forest model</li>
<li>Generate classification map</li>
<li>Validate accuracy</li>
<li>Analyze results</li>
</ol>
<p><strong>Duration:</strong> ~1.5 hours</p>
</div><div class="column" style="width:50%;">
<p><strong>Study Area:</strong> Palawan Province</p>
<ul>
<li><strong>Location:</strong> Western Philippines</li>
<li><strong>Area:</strong> ~14,649 km¬≤</li>
<li><strong>Significance:</strong> UNESCO Biosphere Reserve</li>
<li><strong>Diversity:</strong> Forest, mangroves, agriculture, urban</li>
</ul>
<p><strong>Classes:</strong> 1. Forest 2. Agriculture 3. Water 4. Urban 5. Bare Soil</p>
</div></div>
</section>
<section id="spectral-indices-for-classification" class="slide level2">
<h2>Spectral Indices for Classification</h2>
<p><strong>Key Features Beyond Raw Bands:</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Vegetation Indices:</strong></p>
<table class="caption-top">
<colgroup>
<col style="width: 29%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Index</strong></th>
<th><strong>Formula</strong></th>
<th><strong>Purpose</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>NDVI</strong></td>
<td>(NIR - Red) / (NIR + Red)</td>
<td>Vegetation vigor</td>
</tr>
<tr class="even">
<td><strong>EVI</strong></td>
<td>2.5 √ó (NIR - Red) / (NIR + 6√óRed - 7.5√óBlue + 1)</td>
<td>Enhanced sensitivity in high biomass</td>
</tr>
</tbody>
</table>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a><span class="co"># Calculate NDVI</span></span>
<span id="cb7-2"><a></a>ndvi <span class="op">=</span> image.normalizedDifference([<span class="st">'B8'</span>, <span class="st">'B4'</span>]).rename(<span class="st">'NDVI'</span>)</span>
<span id="cb7-3"><a></a></span>
<span id="cb7-4"><a></a><span class="co"># Calculate EVI</span></span>
<span id="cb7-5"><a></a>evi <span class="op">=</span> image.expression(</span>
<span id="cb7-6"><a></a>    <span class="st">'2.5 * ((NIR - RED) / (NIR + 6*RED - 7.5*BLUE + 1))'</span>,</span>
<span id="cb7-7"><a></a>    {<span class="st">'NIR'</span>: image.select(<span class="st">'B8'</span>),</span>
<span id="cb7-8"><a></a>     <span class="st">'RED'</span>: image.select(<span class="st">'B4'</span>),</span>
<span id="cb7-9"><a></a>     <span class="st">'BLUE'</span>: image.select(<span class="st">'B2'</span>)</span>
<span id="cb7-10"><a></a>    }).rename(<span class="st">'EVI'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div><div class="column" style="width:50%;">
<p><strong>Water &amp; Built-up Indices:</strong></p>
<table class="caption-top">
<colgroup>
<col style="width: 29%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Index</strong></th>
<th><strong>Formula</strong></th>
<th><strong>Purpose</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>NDWI</strong></td>
<td>(Green - NIR) / (Green + NIR)</td>
<td>Water bodies</td>
</tr>
<tr class="even">
<td><strong>MNDWI</strong></td>
<td>(Green - SWIR) / (Green + SWIR)</td>
<td>Water/wetlands (better separation)</td>
</tr>
<tr class="odd">
<td><strong>NDBI</strong></td>
<td>(SWIR - NIR) / (SWIR + NIR)</td>
<td>Built-up areas</td>
</tr>
</tbody>
</table>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a><span class="co"># Calculate water indices</span></span>
<span id="cb8-2"><a></a>ndwi <span class="op">=</span> image.normalizedDifference([<span class="st">'B3'</span>, <span class="st">'B8'</span>]).rename(<span class="st">'NDWI'</span>)</span>
<span id="cb8-3"><a></a>mndwi <span class="op">=</span> image.normalizedDifference([<span class="st">'B3'</span>, <span class="st">'B11'</span>]).rename(<span class="st">'MNDWI'</span>)</span>
<span id="cb8-4"><a></a></span>
<span id="cb8-5"><a></a><span class="co"># Calculate built-up index</span></span>
<span id="cb8-6"><a></a>ndbi <span class="op">=</span> image.normalizedDifference([<span class="st">'B11'</span>, <span class="st">'B8'</span>]).rename(<span class="st">'NDBI'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div class="fragment">
<p><strong>Why MNDWI?</strong> Better separates water from built-up areas than NDWI (uses SWIR instead of NIR)</p>
</div>
<aside class="notes">
<p>MNDWI is particularly useful in coastal areas like Palawan where you need to distinguish water bodies from urban areas. SWIR absorption by water creates stronger contrast.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lab-instructions" class="slide level2">
<h2>Lab Instructions</h2>
<p><strong>Follow along in Jupyter notebook:</strong></p>
<pre><code>../notebooks/session1_hands_on_lab_student.ipynb</code></pre>
<p><strong>Student version:</strong> With TODO markers for exercises</p>
<p><strong>Instructor version:</strong> Complete solutions</p>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tips for Success</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Read markdown cells carefully before running code</li>
<li>Experiment with parameters</li>
<li>Visualize intermediate results</li>
<li>Ask questions when stuck!</li>
</ul>
</div>
</div>
</div>
</div>
</section>
<section id="expected-outputs" class="slide level2">
<h2>Expected Outputs</h2>
<p>By the end of the lab, you will have:</p>
<ol type="1">
<li class="fragment">‚úì Interactive map of Palawan with Sentinel-2 composite</li>
<li class="fragment">‚úì Calculated spectral indices (NDVI, NDWI, NDBI)</li>
<li class="fragment">‚úì Trained Random Forest classifier (100 trees)</li>
<li class="fragment">‚úì Land cover classification map</li>
<li class="fragment">‚úì Confusion matrix and accuracy metrics</li>
<li class="fragment">‚úì Feature importance ranking</li>
<li class="fragment">‚úì Area statistics per land cover class</li>
<li class="fragment">‚úì Exported classification to Google Drive</li>
</ol>
<p><strong>Accuracy Target:</strong> &gt;80% overall accuracy</p>
</section>
<section id="session-1-summary" class="slide level2">
<h2>Session 1 Summary</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Theory Concepts:</strong></p>
<ul>
<li>Supervised classification workflow</li>
<li>Decision trees ‚Üí Random Forest</li>
<li>Bootstrap aggregating</li>
<li>Random feature selection</li>
<li>Feature importance</li>
<li>Accuracy assessment metrics</li>
<li>Confusion matrix interpretation</li>
</ul>
<p><strong>Tools:</strong></p>
<ul>
<li>Google Earth Engine</li>
<li>Python API (geemap)</li>
<li>Sentinel-2 imagery</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Practical Skills:</strong></p>
<ul>
<li>GEE authentication</li>
<li>ImageCollection filtering</li>
<li>Composite generation</li>
<li>Spectral index calculation</li>
<li>Training data preparation</li>
<li>RF model training</li>
<li>Classification execution</li>
<li>Accuracy validation</li>
<li>Map visualization</li>
</ul>
<p><strong>Philippine Context:</strong></p>
<ul>
<li>Palawan land cover mapping</li>
<li>DENR forest monitoring</li>
<li>DA agricultural mapping</li>
<li>NDRRMC disaster response</li>
</ul>
</div></div>
</section>
<section id="next-session-preview" class="slide level2">
<h2>Next Session Preview</h2>
<p><strong>Session 2: Advanced Palawan Land Cover Lab</strong></p>
<ul>
<li>Multi-temporal composites (dry/wet season)</li>
<li>Advanced feature engineering (GLCM texture)</li>
<li>Topographic features (DEM)</li>
<li>8-class detailed classification</li>
<li>Hyperparameter tuning</li>
<li>Change detection (2020 vs.&nbsp;2024)</li>
<li>Deforestation analysis</li>
<li>Stakeholder reporting</li>
</ul>
<div class="fragment">
<p><strong>Preparation:</strong></p>
<ul>
<li>Complete Session 1 exercises</li>
<li>Review confusion matrix analysis</li>
<li>Think about classification improvements</li>
</ul>
</div>
</section>
<section id="resources" class="slide level2">
<h2>Resources</h2>
<p><strong>Documentation:</strong></p>
<ul>
<li>Google Earth Engine: https://developers.google.com/earth-engine</li>
<li>geemap: https://geemap.org</li>
<li>Sentinel-2: https://sentinel.esa.int/web/sentinel/missions/sentinel-2</li>
<li>Random Forest paper: Breiman (2001) - Machine Learning 45:5-32</li>
</ul>
<p><strong>Philippine EO:</strong></p>
<ul>
<li>PhilSA: https://philsa.gov.ph</li>
<li>NAMRIA: https://namria.gov.ph</li>
<li>DOST-ASTI PANDA: https://panda.stamina4space.upd.edu.ph</li>
</ul>
<p><strong>Course Materials:</strong></p>
<ul>
<li>GitHub: [repository link]</li>
<li>Datasets: [Google Drive link]</li>
</ul>
</section>
<section id="thank-you" class="slide level2" data-background-color="#2C5F77">
<h2>Thank You!</h2>
<div class="r-fit-text">
<p>Questions?</p>
</div>
<p><strong>Contact:</strong></p>
<ul>
<li>Email: skotsopoulos@neuralio.ai</li>
<li>Office Hours: [schedule]</li>
</ul>
<div class="fragment">
<p><strong>Let‚Äôs move to the hands-on lab!</strong></p>
<p>üöÄ Open: <code>session1_hands_on_lab.ipynb</code></p>


</div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="images/copphil_logo.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>DAY 2 - Session 1 | Random Forest for Earth Observation | 20-23 October 2025</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script src="https://utteranc.es/client.js" repo="cophil-training-v1.0" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
    </script>
    

</body></html>