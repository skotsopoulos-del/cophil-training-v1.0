<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="CoPhil Advanced Training Program">
<meta name="dcterms.date" content="2025-10-19">

<title>Session 4: CNN Hands-on Lab ‚Äì CoPhil EO AI/ML Training</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../day2/notebooks/session1_theory_notebook_STUDENT.html" rel="next">
<link href="../../day2/sessions/session3.html" rel="prev">
<link href="../../images/favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-c9822816d3895e59fda95a6fa7545fef.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-3775014fae9fc394bbda1d6ff89dd45e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-509191933"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-509191933', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="../../styles/custom.css">
<link rel="stylesheet" href="../../styles/phase2-enhancements.css">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">CoPhil EO AI/ML Training</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-training-days" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Training Days</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-training-days">    
        <li>
    <a class="dropdown-item" href="../../day1/index.html">
 <span class="dropdown-text">Day 1: EO Data &amp; Fundamentals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../day2/index.html">
 <span class="dropdown-text">Day 2: Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../day3/index.html">
 <span class="dropdown-text">Day 3: Deep Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../day4/index.html">
 <span class="dropdown-text">Day 4: Advanced Topics</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="../../resources/setup.html">
 <span class="dropdown-text">Setup Guide</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../resources/philippine-eo.html">
 <span class="dropdown-text">Philippine EO Links</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../resources/cheatsheets.html">
 <span class="dropdown-text">Cheat Sheets</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../resources/faq.html">
 <span class="dropdown-text">FAQ</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../resources/glossary.html">
 <span class="dropdown-text">Glossary</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../resources/downloads.html"> <i class="bi bi-download" role="img">
</i> 
<span class="menu-text">Materials</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../day2/sessions/session1.html">Sessions</a></li><li class="breadcrumb-item"><a href="../../day2/sessions/session4.html">Session 4: CNN Hands-on Lab</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../../index.html" class="sidebar-logo-link">
      </a>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Day 2: Machine Learning for Earth Observation</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Sessions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/sessions/session1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 1: Supervised Classification with Random Forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/sessions/session2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 2: Advanced Palawan Land Cover Lab</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/sessions/session3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 3: Introduction to Deep Learning and CNNs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/sessions/session4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Session 4: CNN Hands-on Lab</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Notebooks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session1_theory_notebook_STUDENT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 1 Theory: Understanding Random Forest for Earth Observation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session1_hands_on_lab_student.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 1 Hands-on Lab: Palawan Land Cover Classification with Random Forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session2_extended_lab_STUDENT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 2: Advanced Palawan Land Cover Classification Lab</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session3_theory_interactive.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 3: Deep Learning &amp; CNN Theory - Interactive Notebook</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session4_cnn_classification_STUDENT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 4: CNN Hands-On Lab - EuroSAT Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session4_transfer_learning_STUDENT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 4 Part B: Transfer Learning with ResNet50</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On This Page</h2>
   
  <ul>
  <li><a href="#session-4-cnn-hands-on-lab" id="toc-session-4-cnn-hands-on-lab" class="nav-link active" data-scroll-target="#session-4-cnn-hands-on-lab">Session 4: CNN Hands-on Lab</a>
  <ul class="collapse">
  <li><a href="#building-and-training-cnns-for-eo-image-classification" id="toc-building-and-training-cnns-for-eo-image-classification" class="nav-link" data-scroll-target="#building-and-training-cnns-for-eo-image-classification">Building and Training CNNs for EO Image Classification</a></li>
  </ul></li>
  <li><a href="#session-overview" id="toc-session-overview" class="nav-link" data-scroll-target="#session-overview">Session Overview</a></li>
  <li><a href="#presentation-slides" id="toc-presentation-slides" class="nav-link" data-scroll-target="#presentation-slides">Presentation Slides</a></li>
  <li><a href="#what-youll-accomplish" id="toc-what-youll-accomplish" class="nav-link" data-scroll-target="#what-youll-accomplish">What You‚Äôll Accomplish</a></li>
  <li><a href="#why-this-matters-for-philippine-eo" id="toc-why-this-matters-for-philippine-eo" class="nav-link" data-scroll-target="#why-this-matters-for-philippine-eo">Why This Matters for Philippine EO</a></li>
  <li><a href="#session-structure" id="toc-session-structure" class="nav-link" data-scroll-target="#session-structure">Session Structure</a>
  <ul class="collapse">
  <li><a href="#part-a-environment-setup-data-preparation-30-minutes" id="toc-part-a-environment-setup-data-preparation-30-minutes" class="nav-link" data-scroll-target="#part-a-environment-setup-data-preparation-30-minutes">Part A: Environment Setup &amp; Data Preparation (30 minutes)</a></li>
  <li><a href="#part-b-building-cnn-from-scratch-40-minutes" id="toc-part-b-building-cnn-from-scratch-40-minutes" class="nav-link" data-scroll-target="#part-b-building-cnn-from-scratch-40-minutes">Part B: Building CNN from Scratch (40 minutes)</a></li>
  <li><a href="#part-c-u-net-for-semantic-segmentation-60-minutes" id="toc-part-c-u-net-for-semantic-segmentation-60-minutes" class="nav-link" data-scroll-target="#part-c-u-net-for-semantic-segmentation-60-minutes">Part C: U-Net for Semantic Segmentation (60 minutes)</a></li>
  <li><a href="#part-d-comprehensive-evaluation-30-minutes" id="toc-part-d-comprehensive-evaluation-30-minutes" class="nav-link" data-scroll-target="#part-d-comprehensive-evaluation-30-minutes">Part D: Comprehensive Evaluation (30 minutes)</a></li>
  <li><a href="#part-e-transfer-learning-20-minutes" id="toc-part-e-transfer-learning-20-minutes" class="nav-link" data-scroll-target="#part-e-transfer-learning-20-minutes">Part E: Transfer Learning (20 minutes)</a></li>
  <li><a href="#part-f-philippine-eo-applications-10-minutes" id="toc-part-f-philippine-eo-applications-10-minutes" class="nav-link" data-scroll-target="#part-f-philippine-eo-applications-10-minutes">Part F: Philippine EO Applications (10 minutes)</a></li>
  </ul></li>
  <li><a href="#hands-on-notebook" id="toc-hands-on-notebook" class="nav-link" data-scroll-target="#hands-on-notebook">Hands-On Notebook</a></li>
  <li><a href="#expected-outcomes" id="toc-expected-outcomes" class="nav-link" data-scroll-target="#expected-outcomes">Expected Outcomes</a></li>
  <li><a href="#troubleshooting-guide" id="toc-troubleshooting-guide" class="nav-link" data-scroll-target="#troubleshooting-guide">Troubleshooting Guide</a>
  <ul class="collapse">
  <li><a href="#common-issues-solutions" id="toc-common-issues-solutions" class="nav-link" data-scroll-target="#common-issues-solutions">Common Issues &amp; Solutions</a></li>
  </ul></li>
  <li><a href="#key-concepts-recap" id="toc-key-concepts-recap" class="nav-link" data-scroll-target="#key-concepts-recap">Key Concepts Recap</a>
  <ul class="collapse">
  <li><a href="#convolutional-layers" id="toc-convolutional-layers" class="nav-link" data-scroll-target="#convolutional-layers">Convolutional Layers</a></li>
  <li><a href="#pooling-layers" id="toc-pooling-layers" class="nav-link" data-scroll-target="#pooling-layers">Pooling Layers</a></li>
  <li><a href="#activation-functions" id="toc-activation-functions" class="nav-link" data-scroll-target="#activation-functions">Activation Functions</a></li>
  <li><a href="#loss-functions" id="toc-loss-functions" class="nav-link" data-scroll-target="#loss-functions">Loss Functions</a></li>
  <li><a href="#optimizers" id="toc-optimizers" class="nav-link" data-scroll-target="#optimizers">Optimizers</a></li>
  </ul></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources">Resources</a>
  <ul class="collapse">
  <li><a href="#documentation-tutorials" id="toc-documentation-tutorials" class="nav-link" data-scroll-target="#documentation-tutorials">Documentation &amp; Tutorials</a></li>
  <li><a href="#pre-trained-models" id="toc-pre-trained-models" class="nav-link" data-scroll-target="#pre-trained-models">Pre-trained Models</a></li>
  <li><a href="#philippine-eo-resources" id="toc-philippine-eo-resources" class="nav-link" data-scroll-target="#philippine-eo-resources">Philippine EO Resources</a></li>
  <li><a href="#course-materials" id="toc-course-materials" class="nav-link" data-scroll-target="#course-materials">Course Materials</a></li>
  </ul></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next Steps</a></li>
  <li><a href="#assessment-exercises" id="toc-assessment-exercises" class="nav-link" data-scroll-target="#assessment-exercises">Assessment &amp; Exercises</a>
  <ul class="collapse">
  <li><a href="#formative-assessment-in-notebook" id="toc-formative-assessment-in-notebook" class="nav-link" data-scroll-target="#formative-assessment-in-notebook">Formative Assessment (In-Notebook)</a></li>
  <li><a href="#challenge-exercises" id="toc-challenge-exercises" class="nav-link" data-scroll-target="#challenge-exercises">Challenge Exercises</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../day2/sessions/session1.html">Sessions</a></li><li class="breadcrumb-item"><a href="../../day2/sessions/session4.html">Session 4: CNN Hands-on Lab</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Session 4: CNN Hands-on Lab</h1>
<p class="subtitle lead">Building and Training CNNs for EO Image Classification</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Instructor</div>
    <div class="quarto-title-meta-contents">
             <p>CoPhil Advanced Training Program </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Date</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 19, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<nav class="breadcrumb" aria-label="Breadcrumb">
<a href="../../index.html">Home</a> <span class="breadcrumb-separator" aria-hidden="true">‚Ä∫</span> <a href="../index.html">Day 2</a> <span class="breadcrumb-separator" aria-hidden="true">‚Ä∫</span> <span class="breadcrumb-current">Session 4</span>
</nav>
<section id="session-4-cnn-hands-on-lab" class="level1 hero">
<h1>Session 4: CNN Hands-on Lab</h1>
<section id="building-and-training-cnns-for-eo-image-classification" class="level3">
<h3 class="anchored" data-anchor-id="building-and-training-cnns-for-eo-image-classification">Building and Training CNNs for EO Image Classification</h3>
<p>From theory to implementation with TensorFlow and PyTorch</p>
</section>
</section>
<section id="session-overview" class="level2">
<h2 class="anchored" data-anchor-id="session-overview">Session Overview</h2>
<p><strong>Duration:</strong> 2.5 hours | <strong>Type:</strong> Intensive Hands-On Lab | <strong>Difficulty:</strong> Intermediate-Advanced</p>
<hr>
<p>This session transforms CNN theory from Session 3 into working code. You‚Äôll build, train, and evaluate real deep learning models for Earth Observation, achieving significantly higher accuracy than the Random Forest models from Sessions 1-2.</p>
</section>
<section id="presentation-slides" class="level2">
<h2 class="anchored" data-anchor-id="presentation-slides">Presentation Slides</h2>
<iframe src="../presentations/session4_cnn_lab.html" width="100%" height="600" style="border: 1px solid #ccc; border-radius: 4px;">
</iframe>
<hr>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Prerequisites
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Technical Requirements:</strong> - ‚úì Complete Session 3 (CNN theory and concepts) - ‚úì Understand convolution, pooling, activation functions - ‚úì Python programming proficiency (NumPy, pandas basics) - ‚úì Google Colab account with GPU access - ‚úì Stable internet connection (for dataset downloads)</p>
<p><strong>Conceptual Understanding:</strong> - ‚úì Know difference between traditional ML and deep learning - ‚úì Understand supervised learning workflow - ‚úì Familiar with classification metrics (accuracy, confusion matrix) - ‚úì Basic understanding of gradient descent optimization</p>
</div>
</div>
<hr>
</section>
<section id="what-youll-accomplish" class="level2">
<h2 class="anchored" data-anchor-id="what-youll-accomplish">What You‚Äôll Accomplish</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Learning Outcomes
</div>
</div>
<div class="callout-body-container callout-body">
<p>After completing this session, you will be able to:</p>
<section id="implement-cnns-in-tensorflowkeras" class="level3">
<h3 class="anchored" data-anchor-id="implement-cnns-in-tensorflowkeras">1. Implement CNNs in TensorFlow/Keras</h3>
<ul>
<li>Set up GPU-accelerated deep learning environment</li>
<li>Load and preprocess Earth observation datasets</li>
<li>Build CNN architectures layer-by-layer from scratch</li>
<li>Compile models with appropriate loss functions and optimizers</li>
<li>Train models with advanced callbacks (early stopping, checkpointing)</li>
</ul>
</section>
<section id="work-with-eurosat-benchmark-dataset" class="level3">
<h3 class="anchored" data-anchor-id="work-with-eurosat-benchmark-dataset">2. Work with EuroSAT Benchmark Dataset</h3>
<ul>
<li>Download and prepare standardized EO dataset</li>
<li>Understand 10-class land use classification task</li>
<li>Create efficient data pipelines with tf.data.Dataset</li>
<li>Apply data augmentation strategies for satellite imagery</li>
<li>Handle train/validation/test splits properly</li>
</ul>
</section>
<section id="evaluate-deep-learning-models" class="level3">
<h3 class="anchored" data-anchor-id="evaluate-deep-learning-models">3. Evaluate Deep Learning Models</h3>
<ul>
<li>Generate and interpret confusion matrices</li>
<li>Calculate per-class precision, recall, and F1-scores</li>
<li>Visualize training and validation curves</li>
<li>Analyze misclassifications and model errors</li>
<li>Compare CNN performance with Random Forest baseline</li>
</ul>
</section>
<section id="apply-transfer-learning" class="level3">
<h3 class="anchored" data-anchor-id="apply-transfer-learning">4. Apply Transfer Learning</h3>
<ul>
<li>Load pre-trained models (ResNet50, VGG16, EfficientNet)</li>
<li>Understand when and why to use pre-trained weights</li>
<li>Freeze and fine-tune network layers strategically</li>
<li>Adapt ImageNet models for Earth observation tasks</li>
<li>Compare from-scratch vs.&nbsp;transfer learning performance</li>
</ul>
</section>
<section id="optimize-and-debug-models" class="level3">
<h3 class="anchored" data-anchor-id="optimize-and-debug-models">5. Optimize and Debug Models</h3>
<ul>
<li>Prevent overfitting with dropout and regularization</li>
<li>Tune hyperparameters (learning rate, batch size, architecture)</li>
<li>Diagnose training issues (vanishing gradients, exploding loss)</li>
<li>Use callbacks for adaptive learning</li>
<li>Implement best practices for reproducibility</li>
</ul>
</section>
</div>
</div>
<hr>
</section>
<section id="why-this-matters-for-philippine-eo" class="level2">
<h2 class="anchored" data-anchor-id="why-this-matters-for-philippine-eo">Why This Matters for Philippine EO</h2>
<div class="feature-grid">
<div class="feature-card">
<p><strong>üéØ Accuracy Improvement</strong></p>
<p>CNNs consistently outperform Random Forest: - <strong>EuroSAT:</strong> 92-98% vs 87-90% - <strong>Palawan:</strong> Estimated +5-10% accuracy - <strong>Critical for:</strong> DRR applications where errors cost lives</p>
</div>
<div class="feature-card">
<p><strong>üåç Spatial Context</strong></p>
<p>CNNs understand image context: - <strong>RF:</strong> Treats pixels independently - <strong>CNN:</strong> Captures spatial patterns - <strong>Benefit:</strong> Better forest boundary detection, fewer misclassifications</p>
</div>
<div class="feature-card">
<p><strong>‚ö° Scalability</strong></p>
<p>Once trained, CNNs scale efficiently: - <strong>Deployment:</strong> Fast inference on new imagery - <strong>Automation:</strong> Process entire Philippines nightly - <strong>Operations:</strong> PhilSA operational monitoring</p>
</div>
<div class="feature-card">
<p><strong>üîÑ Transfer Learning</strong></p>
<p>Pre-trained models accelerate development: - <strong>Small Data:</strong> Works with limited labeled samples - <strong>Time Savings:</strong> Days vs weeks of training - <strong>Philippine Context:</strong> Adapt global models locally</p>
</div>
</div>
<hr>
</section>
<section id="session-structure" class="level2">
<h2 class="anchored" data-anchor-id="session-structure">Session Structure</h2>
<section id="part-a-environment-setup-data-preparation-30-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-a-environment-setup-data-preparation-30-minutes">Part A: Environment Setup &amp; Data Preparation (30 minutes)</h3>
<p><strong>Setup Google Colab Environment</strong> - Configure GPU runtime for acceleration - Install required libraries (TensorFlow, Keras, auxiliary packages) - Verify GPU detection and availability - Set random seeds for reproducibility</p>
<p><strong>Download EuroSAT Dataset</strong> - Understand the benchmark dataset (27,000 Sentinel-2 patches) - Automated download and extraction - Verify data integrity with checksums - Explore directory structure and file formats</p>
<p><strong>Data Loading and Exploration</strong> - Load images and labels efficiently - Visualize sample images from each class - Analyze class distribution and balance - Calculate dataset statistics (mean, std)</p>
<p><strong>Create Data Pipeline</strong> - Split data (70% train, 15% validation, 15% test) - Build tf.data.Dataset for efficient loading - Apply normalization and preprocessing - Implement data augmentation for training set - Configure batching, shuffling, and prefetching</p>
<hr>
</section>
<section id="part-b-building-cnn-from-scratch-40-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-b-building-cnn-from-scratch-40-minutes">Part B: Building CNN from Scratch (40 minutes)</h3>
<p><strong>Design CNN Architecture</strong> - Start with simple 3-block architecture - Understand layer choices and progression - Calculate output dimensions at each layer - Visualize network architecture diagram</p>
<p><strong>Implementation Details:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example architecture (you'll implement in notebook)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>Model: <span class="st">"eurosat_cnn"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>_________________________________________________________________</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>Layer (<span class="bu">type</span>)                Output Shape              Param <span class="co">#   </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">=================================================================</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>conv2d_1 (Conv2D)          (<span class="va">None</span>, <span class="dv">62</span>, <span class="dv">62</span>, <span class="dv">32</span>)        <span class="dv">896</span>       </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>activation_1 (ReLU)        (<span class="va">None</span>, <span class="dv">62</span>, <span class="dv">62</span>, <span class="dv">32</span>)        <span class="dv">0</span>         </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>max_pooling2d_1            (<span class="va">None</span>, <span class="dv">31</span>, <span class="dv">31</span>, <span class="dv">32</span>)        <span class="dv">0</span>         </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>conv2d_2 (Conv2D)          (<span class="va">None</span>, <span class="dv">29</span>, <span class="dv">29</span>, <span class="dv">64</span>)        <span class="dv">18</span>,<span class="dv">496</span>    </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>activation_2 (ReLU)        (<span class="va">None</span>, <span class="dv">29</span>, <span class="dv">29</span>, <span class="dv">64</span>)        <span class="dv">0</span>         </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>max_pooling2d_2            (<span class="va">None</span>, <span class="dv">14</span>, <span class="dv">14</span>, <span class="dv">64</span>)        <span class="dv">0</span>         </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>conv2d_3 (Conv2D)          (<span class="va">None</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">128</span>)       <span class="dv">73</span>,<span class="dv">856</span>    </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>activation_3 (ReLU)        (<span class="va">None</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">128</span>)       <span class="dv">0</span>         </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>max_pooling2d_3            (<span class="va">None</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">128</span>)         <span class="dv">0</span>         </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>flatten (Flatten)          (<span class="va">None</span>, <span class="dv">4608</span>)              <span class="dv">0</span>         </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>dropout (Dropout)          (<span class="va">None</span>, <span class="dv">4608</span>)              <span class="dv">0</span>         </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>dense_1 (Dense)            (<span class="va">None</span>, <span class="dv">128</span>)               <span class="dv">589</span>,<span class="dv">952</span>   </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>activation_4 (ReLU)        (<span class="va">None</span>, <span class="dv">128</span>)               <span class="dv">0</span>         </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>dropout_2 (Dropout)        (<span class="va">None</span>, <span class="dv">128</span>)               <span class="dv">0</span>         </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>dense_2 (Dense)            (<span class="va">None</span>, <span class="dv">10</span>)                <span class="dv">1</span>,<span class="dv">290</span>     </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>activation_5 (Softmax)     (<span class="va">None</span>, <span class="dv">10</span>)                <span class="dv">0</span>         </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="op">=================================================================</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>Total params: <span class="dv">684</span>,<span class="dv">490</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>Trainable params: <span class="dv">684</span>,<span class="dv">490</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>Non<span class="op">-</span>trainable params: <span class="dv">0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Key Architectural Decisions:</strong> - <strong>Filter progression (32‚Üí64‚Üí128):</strong> Capture features at multiple scales - <strong>3√ó3 convolutions:</strong> Standard choice balancing receptive field and parameters - <strong>MaxPooling:</strong> Spatial dimension reduction and translation invariance - <strong>Dropout (0.3-0.5):</strong> Regularization to prevent overfitting - <strong>Dense layers:</strong> Final classification from learned features - <strong>Softmax output:</strong> Probability distribution over 10 classes</p>
<p><strong>Model Compilation:</strong> - <strong>Loss function:</strong> Categorical cross-entropy (multi-class classification) - <strong>Optimizer:</strong> Adam (adaptive learning rate, generally robust) - <strong>Metrics:</strong> Accuracy, top-3 accuracy - <strong>Learning rate:</strong> Start with 0.001 (default), tune if needed</p>
<hr>
</section>
<section id="part-c-u-net-for-semantic-segmentation-60-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-c-u-net-for-semantic-segmentation-60-minutes">Part C: U-Net for Semantic Segmentation (60 minutes)</h3>
<p><strong>Configure Training Callbacks</strong></p>
<div class="feature-grid">
<div class="feature-card">
<p><strong>EarlyStopping</strong></p>
<p>Stop training when validation loss stops improving:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>EarlyStopping(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    restore_best_weights<span class="op">=</span><span class="va">True</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Prevents overfitting, saves time</em></p>
</div>
<div class="feature-card">
<p><strong>ModelCheckpoint</strong></p>
<p>Save best model during training:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>ModelCheckpoint(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'best_model.h5'</span>,</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    save_best_only<span class="op">=</span><span class="va">True</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Preserves optimal weights</em></p>
</div>
<div class="feature-card">
<p><strong>ReduceLROnPlateau</strong></p>
<p>Lower learning rate when stuck:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>ReduceLROnPlateau(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    factor<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">3</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Helps escape local minima</em></p>
</div>
<div class="feature-card">
<p><strong>TensorBoard</strong></p>
<p>Real-time training visualization:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>TensorBoard(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    log_dir<span class="op">=</span><span class="st">'./logs'</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Monitor metrics live</em></p>
</div>
</div>
<p><strong>Execute Training</strong> - Train for 20-30 epochs (likely stops early) - Monitor training/validation metrics in real-time - Observe learning curves for overfitting signs - Track GPU utilization and training speed</p>
<p><strong>Interpret Learning Curves</strong></p>
<p><strong>Healthy Training:</strong> - Train loss decreases steadily - Validation loss decreases, plateaus - Small train-val gap (&lt;5-10%) - Validation accuracy plateaus at high value</p>
<p><strong>Overfitting Signs:</strong> - Train accuracy ‚Üí 100%, val accuracy plateaus low - Large train-val gap (&gt;15-20%) - Validation loss increases while train loss decreases - <strong>Solution:</strong> More dropout, stronger regularization, more data</p>
<p><strong>Underfitting Signs:</strong> - Both train and val accuracy low - Loss plateaus at high value - No improvement with more epochs - <strong>Solution:</strong> More complex model, lower regularization, train longer</p>
<hr>
</section>
<section id="part-d-comprehensive-evaluation-30-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-d-comprehensive-evaluation-30-minutes">Part D: Comprehensive Evaluation (30 minutes)</h3>
<p><strong>Test Set Performance</strong> - Load best saved model - Evaluate on held-out test set - Calculate final accuracy and loss - Compare with validation performance</p>
<p><strong>Confusion Matrix Analysis</strong></p>
<p>Generate and visualize 10√ó10 confusion matrix:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>True ‚Üì / Pred ‚Üí</th>
<th>AnnualCrop</th>
<th>Forest</th>
<th>Herbaceous</th>
<th>Highway</th>
<th>‚Ä¶</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AnnualCrop</td>
<td><strong>450</strong></td>
<td>12</td>
<td>8</td>
<td>2</td>
<td>‚Ä¶</td>
</tr>
<tr class="even">
<td>Forest</td>
<td>5</td>
<td><strong>492</strong></td>
<td>3</td>
<td>0</td>
<td>‚Ä¶</td>
</tr>
<tr class="odd">
<td>Herbaceous</td>
<td>18</td>
<td>7</td>
<td><strong>441</strong></td>
<td>1</td>
<td>‚Ä¶</td>
</tr>
<tr class="even">
<td>‚Ä¶</td>
<td>‚Ä¶</td>
<td>‚Ä¶</td>
<td>‚Ä¶</td>
<td>‚Ä¶</td>
<td>‚Ä¶</td>
</tr>
</tbody>
</table>
<p><strong>Insights from Confusion:</strong> - <strong>Diagonal values:</strong> Correct classifications (darker = better) - <strong>Off-diagonal:</strong> Common confusions - <strong>Typical EO confusions:</strong> - AnnualCrop ‚ÜîÔ∏é Herbaceous (similar vegetation) - Industrial ‚ÜîÔ∏é Highway (both gray infrastructure) - Forest ‚ÜîÔ∏é PermanentCrop (tree canopies)</p>
<p><strong>Per-Class Metrics</strong></p>
<pre><code>              precision    recall  f1-score   support

  AnnualCrop       0.93      0.94      0.93       478
      Forest       0.96      0.97      0.97       507
  Herbaceous       0.91      0.92      0.92       481
     Highway       0.94      0.92      0.93       453
  Industrial       0.89      0.87      0.88       461
     Pasture       0.90      0.91      0.91       489
PermanentCrop      0.92      0.91      0.92       471
 Residential       0.95      0.96      0.95       498
       River       0.98      0.97      0.98       502
     SeaLake       0.97      0.98      0.98       510

    accuracy                           0.94      4850
   macro avg       0.94      0.94      0.94      4850
weighted avg       0.94      0.94      0.94      4850</code></pre>
<p><strong>Error Analysis</strong> - Identify most confused class pairs - Visualize misclassified examples - Understand model failure modes - Suggest improvements</p>
<hr>
</section>
<section id="part-e-transfer-learning-20-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-e-transfer-learning-20-minutes">Part E: Transfer Learning (20 minutes)</h3>
<p><strong>Why Transfer Learning for EO?</strong></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Transfer Learning Benefits
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>ImageNet Pre-training Advantages:</strong> - <strong>Low-level features transfer:</strong> Edges, textures, colors are universal - <strong>Reduced training time:</strong> 80-90% faster convergence - <strong>Better with limited data:</strong> Works with 100s of samples vs 1000s - <strong>Higher accuracy:</strong> +2-5% typical improvement - <strong>Regularization effect:</strong> Pre-trained weights prevent overfitting</p>
<p><strong>When to Use:</strong> - Limited labeled training data (&lt;5000 samples) - Similar task to ImageNet (object recognition) - Time/compute constraints - Need strong baseline quickly</p>
<p><strong>When NOT to Use:</strong> - Very different from natural images (SAR, hyperspectral) - Abundant labeled data (&gt;50K samples) - Highly specialized task</p>
</div>
</div>
<p><strong>Load Pre-trained Model</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.applications <span class="im">import</span> ResNet50</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load ResNet50 with ImageNet weights</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>base_model <span class="op">=</span> ResNet50(</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    include_top<span class="op">=</span><span class="va">False</span>,  <span class="co"># Exclude classification head</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    weights<span class="op">=</span><span class="st">'imagenet'</span>,  <span class="co"># Use pre-trained weights</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    input_shape<span class="op">=</span>(<span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">3</span>),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    pooling<span class="op">=</span><span class="st">'avg'</span>  <span class="co"># Global average pooling</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Fine-tuning Strategy</strong></p>
<p><strong>Option 1: Freeze All Layers (Feature Extraction)</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze all base model layers</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Add custom classification head</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    base_model,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    Dropout(<span class="fl">0.5</span>),</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Fast training, use when data is very limited</em></p>
<p><strong>Option 2: Freeze Early, Train Late (Partial Fine-tuning)</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze first 80% of layers</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer <span class="kw">in</span> base_model.layers[:<span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(base_model.layers))]:</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    layer.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fine-tune top layers + custom head</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Balanced approach, best for moderate data</em></p>
<p><strong>Option 3: Full Fine-tuning</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># All layers trainable</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">True</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use lower learning rate (0.0001 instead of 0.001)</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">1e-4</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Slowest, use when data is abundant</em></p>
<p><strong>Compare Results:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Approach</th>
<th>Train Time</th>
<th>Test Accuracy</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>From Scratch</td>
<td>25 min</td>
<td>93.2%</td>
<td>Baseline</td>
</tr>
<tr class="even">
<td>Feature Extraction</td>
<td>8 min</td>
<td>94.1%</td>
<td>Fast, good boost</td>
</tr>
<tr class="odd">
<td>Partial Fine-tuning</td>
<td>15 min</td>
<td>95.3%</td>
<td>Best balance</td>
</tr>
<tr class="even">
<td>Full Fine-tuning</td>
<td>30 min</td>
<td>95.8%</td>
<td>Marginal gain</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="part-f-philippine-eo-applications-10-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-f-philippine-eo-applications-10-minutes">Part F: Philippine EO Applications (10 minutes)</h3>
<p><strong>Adapting CNNs for Philippine Contexts</strong></p>
<div class="feature-grid">
<div class="feature-card">
<p><strong>Multi-spectral Considerations</strong></p>
<p><strong>Challenge:</strong> Sentinel-2 has 13 bands, ResNet expects 3</p>
<p><strong>Solutions:</strong> 1. <strong>Band selection:</strong> Use only RGB (B4, B3, B2) 2. <strong>Band combinations:</strong> NIR-Red-Green false color 3. <strong>PCA:</strong> Reduce 13‚Üí3 dimensions 4. <strong>Architecture modification:</strong> Change input layer to accept 13 channels</p>
<p><strong>Recommendation for Palawan:</strong> - Start with RGB for transfer learning - Train custom CNN with all bands for production</p>
</div>
<div class="feature-card">
<p><strong>Scaling to Operational Use</strong></p>
<p><strong>PhilSA Production Pipeline:</strong> 1. <strong>Training:</strong> Palawan pilot (this session) 2. <strong>Validation:</strong> Other provinces 3. <strong>Deployment:</strong> Nationwide monitoring 4. <strong>Updates:</strong> Retrain quarterly</p>
<p><strong>Computational Needs:</strong> - Training: Cloud GPU (Colab, AWS, Azure) - Inference: Can run on CPU for deployment - Storage: Model weights ~50-200 MB</p>
</div>
<div class="feature-card">
<p><strong>CNN for Disaster Response</strong></p>
<p><strong>Typhoon Damage Assessment:</strong> - <strong>Input:</strong> Pre/post imagery pairs - <strong>Task:</strong> Binary (damaged/not damaged) - <strong>Architecture:</strong> Siamese network or stacked CNN - <strong>Speed:</strong> Process 1000 km¬≤ in hours</p>
<p><strong>Flood Extent Mapping:</strong> - <strong>Advance to Day 3:</strong> U-Net for pixel-level segmentation - <strong>Real-time:</strong> CNN classification during event - <strong>Integration:</strong> Feed into NOAH or Project DOST systems</p>
</div>
<div class="feature-card">
<p><strong>Accuracy Requirements</strong></p>
<p><strong>Application-Specific Needs:</strong> - <strong>Land cover monitoring:</strong> 85-90% sufficient - <strong>Forest law enforcement:</strong> 95%+ required - <strong>Disaster response:</strong> Speed &gt; perfect accuracy - <strong>REDD+ MRV:</strong> High precision needed</p>
<p><strong>Session 4 Achievement:</strong> 93-96% on EuroSAT</p>
</div>
</div>
<hr>
</section>
</section>
<section id="hands-on-notebook" class="level2">
<h2 class="anchored" data-anchor-id="hands-on-notebook">Hands-On Notebook</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>üìì Interactive Jupyter Notebook
</div>
</div>
<div class="callout-body-container callout-body">
<p>The complete hands-on lab is available as an executable Jupyter notebook:</p>
<p><strong>Student Version</strong> (with exercises and TODOs):<br>
<a href="../../day2/notebooks/session4_cnn_classification_STUDENT.html"><code>session4_cnn_classification_STUDENT.ipynb</code></a></p>
<p><strong>Google Colab Direct Link:</strong><br>
<a href="https://colab.research.google.com/github/DimitrisKasabalis/EO_trainning/blob/main/course_site/day2/notebooks/session4_cnn_classification_STUDENT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" class="img-fluid" alt="Open In Colab"></a></p>
<p><strong>What‚Äôs Included:</strong> - Complete environment setup (TensorFlow, GPU config) - EuroSAT download and preparation scripts - CNN architecture implementation (from-scratch and transfer learning) - Training loops with callbacks - Comprehensive evaluation code - Visualization functions - Interactive exercises</p>
<p><strong>Estimated Execution Time:</strong> - Setup: 5 minutes - Data download: 3-5 minutes (90 MB) - Training from scratch: 15-20 minutes (GPU) - Transfer learning: 5-10 minutes (GPU) - Evaluation: 5 minutes - <strong>Total:</strong> ~30-40 minutes with GPU</p>
</div>
</div>
<hr>
</section>
<section id="expected-outcomes" class="level2">
<h2 class="anchored" data-anchor-id="expected-outcomes">Expected Outcomes</h2>
<p>By the end of this session, you will have:</p>
<p>‚úÖ <strong>Completed Projects:</strong> - Working EuroSAT CNN classifier (93-96% accuracy) - Transfer learning model with ResNet50 (94-97% accuracy) - Comprehensive evaluation report with confusion matrix - Trained model weights saved for deployment</p>
<p>‚úÖ <strong>Technical Skills:</strong> - TensorFlow/Keras proficiency for CNNs - Data pipeline creation with tf.data - Training with advanced callbacks - Model evaluation and debugging - Transfer learning implementation</p>
<p>‚úÖ <strong>Practical Deliverables:</strong> - Executable Jupyter notebook (student version completed) - Trained models (<code>.h5</code> or SavedModel format) - Learning curve plots - Confusion matrix visualizations - Classification report (precision, recall, F1)</p>
<p>‚úÖ <strong>Understanding:</strong> - When CNNs outperform traditional ML - How to choose architecture for EO tasks - Transfer learning for small datasets - Hyperparameter tuning strategies - Deployment considerations</p>
<hr>
</section>
<section id="troubleshooting-guide" class="level2">
<h2 class="anchored" data-anchor-id="troubleshooting-guide">Troubleshooting Guide</h2>
<section id="common-issues-solutions" class="level3">
<h3 class="anchored" data-anchor-id="common-issues-solutions">Common Issues &amp; Solutions</h3>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>GPU Not Detected
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong></p>
<pre><code>Physical devices: []
WARNING: No GPU available, using CPU</code></pre>
<p><strong>Solutions:</strong> 1. <strong>Colab:</strong> Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU 2. <strong>Verify:</strong> Run <code>tf.config.list_physical_devices('GPU')</code> 3. <strong>Restart runtime:</strong> Runtime ‚Üí Restart runtime 4. <strong>Check quota:</strong> Colab has usage limits (reconnect after 12 hours) 5. <strong>Alternative:</strong> Use Kaggle Notebooks (30 hrs/week GPU free)</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Out of Memory Error
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong></p>
<pre><code>ResourceExhaustedError: OOM when allocating tensor</code></pre>
<p><strong>Solutions:</strong> 1. <strong>Reduce batch size:</strong> 32 ‚Üí 16 ‚Üí 8 2. <strong>Smaller model:</strong> Fewer filters (128‚Üí64), fewer layers 3. <strong>Mixed precision:</strong> <code>tf.keras.mixed_precision.set_global_policy('mixed_float16')</code> 4. <strong>Clear memory:</strong> <code>tf.keras.backend.clear_session()</code> 5. <strong>Restart runtime:</strong> Fresh start clears memory</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Training Not Improving
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong> - Accuracy stuck at ~10% (random guessing) - Loss = NaN or infinity - Very slow convergence</p>
<p><strong>Solutions:</strong> 1. <strong>Learning rate too high:</strong> Reduce to 0.0001 2. <strong>Check data normalization:</strong> Images should be 0-1 or standardized 3. <strong>Verify labels:</strong> One-hot encoded correctly (shape: [batch, 10]) 4. <strong>Gradient clipping:</strong> <code>optimizer = Adam(clipnorm=1.0)</code> 5. <strong>Simpler model:</strong> Start with 2 conv blocks instead of 3 6. <strong>Check for bugs:</strong> Print shapes, verify data loading</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Overfitting Severely
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong> - Train accuracy: 99%, Val accuracy: 75% - Validation loss increases while train loss decreases</p>
<p><strong>Solutions:</strong> 1. <strong>More dropout:</strong> Increase from 0.3 to 0.5 2. <strong>Data augmentation:</strong> Add rotation, flip, zoom 3. <strong>L2 regularization:</strong> <code>Conv2D(..., kernel_regularizer=l2(0.001))</code> 4. <strong>Reduce model capacity:</strong> Fewer filters, fewer layers 5. <strong>Early stopping:</strong> Patience=3-5 epochs 6. <strong>More training data:</strong> Use full EuroSAT (27K images)</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Dataset Download Fails
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong></p>
<pre><code>HTTPError: 404 Not Found
Connection timeout</code></pre>
<p><strong>Solutions:</strong> 1. <strong>Use mirror site:</strong> TensorFlow Datasets, Kaggle 2. <strong>Manual download:</strong> Provide local copy 3. <strong>Check internet:</strong> Colab connectivity issues 4. <strong>Retry:</strong> <code>wget</code> with retries 5. <strong>Pre-downloaded:</strong> Load from Google Drive</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Augmentation Visualization Error
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong></p>
<pre><code>TypeError: only integer scalar arrays can be converted to a scalar index
# OR
IndexError: invalid index to scalar variable</code></pre>
<p><strong>When:</strong> In the ‚ÄúVisualize Augmentation‚Äù cell when trying to display augmented images</p>
<p><strong>Root Cause:</strong> The code uses <code>class_names[sample_label.numpy()]</code> but <code>sample_label.numpy()</code> returns a numpy scalar (e.g., <code>numpy.int64(3)</code>) which some Python versions don‚Äôt accept as a list index.</p>
<p><strong>Solutions:</strong></p>
<p><strong>Quick Fix (Add one line):</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># After: sample_image, sample_label = next(iter(ds_train))</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Add this line:</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>label_idx <span class="op">=</span> <span class="bu">int</span>(sample_label.numpy())</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Then change plt.suptitle line to use label_idx:</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="ss">f'Data Augmentation Examples</span><span class="ch">\n</span><span class="ss">Class: </span><span class="sc">{</span>class_names[label_idx]<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Complete Fixed Cell:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show original vs augmented</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>sample_image, sample_label <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(ds_train))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert label to integer for indexing</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>label_idx <span class="op">=</span> <span class="bu">int</span>(sample_label.numpy())  <span class="co"># &lt;-- ADD THIS LINE</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">7</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Original</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].imshow(sample_image.numpy())</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Original'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Augmented versions</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">8</span>):</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> idx <span class="op">//</span> <span class="dv">4</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> idx <span class="op">%</span> <span class="dv">4</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    augmented <span class="op">=</span> data_augmentation(tf.expand_dims(sample_image, <span class="dv">0</span>), training<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    axes[row, col].imshow(augmented.numpy())</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    axes[row, col].set_title(<span class="ss">f'Augmented </span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    axes[row, col].axis(<span class="st">'off'</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Use label_idx instead of sample_label.numpy()</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="ss">f'Data Augmentation Examples</span><span class="ch">\n</span><span class="ss">Class: </span><span class="sc">{</span>class_names[label_idx]<span class="sc">}</span><span class="ss">'</span>,  <span class="co"># &lt;-- CHANGED</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">‚úì Augmentation creates realistic variations"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Why This Works:</strong> - <code>int()</code> explicitly converts numpy scalar to Python integer - Python lists accept native integers as indices reliably - Prevents type mismatch between numpy and Python types</p>
<p><strong>Note:</strong> A fixed version of the notebook is available: <code>session4_cnn_classification_STUDENT_FIXED.ipynb</code></p>
</div>
</div>
<hr>
</section>
</section>
<section id="key-concepts-recap" class="level2">
<h2 class="anchored" data-anchor-id="key-concepts-recap">Key Concepts Recap</h2>
<section id="convolutional-layers" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-layers">Convolutional Layers</h3>
<p><strong>What they do:</strong> - Apply learnable filters to extract features - Preserve spatial relationships - Translation invariant (feature detected anywhere in image)</p>
<p><strong>Parameters:</strong> - <code>filters</code>: Number of feature maps (32, 64, 128, ‚Ä¶) - <code>kernel_size</code>: Filter dimensions (3√ó3, 5√ó5, ‚Ä¶) - <code>strides</code>: Step size (usually 1) - <code>padding</code>: ‚Äòvalid‚Äô (shrinks) or ‚Äòsame‚Äô (maintains size) - <code>activation</code>: Usually ReLU</p>
</section>
<section id="pooling-layers" class="level3">
<h3 class="anchored" data-anchor-id="pooling-layers">Pooling Layers</h3>
<p><strong>Purpose:</strong> - Reduce spatial dimensions - Add translation invariance - Reduce parameters and computation</p>
<p><strong>MaxPooling vs AveragePooling:</strong> - <strong>MaxPooling:</strong> Keeps strongest activation (most common) - <strong>AveragePooling:</strong> Smooths response - Typically 2√ó2 with stride 2 (halves dimensions)</p>
</section>
<section id="activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="activation-functions">Activation Functions</h3>
<p><strong>ReLU (Rectified Linear Unit):</strong> - <code>f(x) = max(0, x)</code> - Most common in hidden layers - Addresses vanishing gradient problem - Fast to compute</p>
<p><strong>Softmax:</strong> - Converts logits to probabilities - Sum to 1.0 - Used in output layer for multi-class classification</p>
</section>
<section id="loss-functions" class="level3">
<h3 class="anchored" data-anchor-id="loss-functions">Loss Functions</h3>
<p><strong>Categorical Cross-Entropy:</strong> - For multi-class classification (&gt;2 classes) - Requires one-hot encoded labels - Formula: <code>-Œ£ y_true * log(y_pred)</code> - Penalizes confident wrong predictions heavily</p>
</section>
<section id="optimizers" class="level3">
<h3 class="anchored" data-anchor-id="optimizers">Optimizers</h3>
<p><strong>Adam (Adaptive Moment Estimation):</strong> - Adaptive learning rate per parameter - Combines momentum + RMSprop - Generally robust, good default choice - Learning rate: 0.001 (default) to 0.0001 (fine-tuning)</p>
<hr>
</section>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<section id="documentation-tutorials" class="level3">
<h3 class="anchored" data-anchor-id="documentation-tutorials">Documentation &amp; Tutorials</h3>
<ul>
<li><a href="https://www.tensorflow.org/guide/keras">TensorFlow Keras Guide</a></li>
<li><a href="https://cs231n.github.io/">Deep Learning for Computer Vision</a></li>
<li><a href="https://github.com/phelber/EuroSAT">EuroSAT Dataset Paper</a></li>
<li><a href="https://www.tensorflow.org/tutorials/images/transfer_learning">Transfer Learning Guide</a></li>
</ul>
</section>
<section id="pre-trained-models" class="level3">
<h3 class="anchored" data-anchor-id="pre-trained-models">Pre-trained Models</h3>
<ul>
<li><a href="https://keras.io/api/applications/">Keras Applications</a></li>
<li><a href="https://tfhub.dev/">TensorFlow Hub</a></li>
<li><a href="https://modelzoo.co/">Model Zoo</a></li>
</ul>
</section>
<section id="philippine-eo-resources" class="level3">
<h3 class="anchored" data-anchor-id="philippine-eo-resources">Philippine EO Resources</h3>
<ul>
<li><a href="https://data.philsa.gov.ph/">PhilSA Space+ Data</a></li>
<li><a href="https://panda.stamina4space.upd.edu.ph/">DOST-ASTI Panda</a></li>
<li><a href="https://www.namria.gov.ph/geoportal.html">NAMRIA Geoportal</a></li>
</ul>
</section>
<section id="course-materials" class="level3">
<h3 class="anchored" data-anchor-id="course-materials">Course Materials</h3>
<div class="quick-links">
<p><a href="../../day2/sessions/session3.html" class="quick-link">‚Üê Back to Session 3</a> <a href="../../day2/index.html" class="quick-link">Day 2 Overview</a> <a href="../../day2/notebooks/session4_cnn_classification_STUDENT.html" class="quick-link">Lab Notebook</a> <a href="../../resources/setup.html" class="quick-link">Setup Guide</a> <a href="../../resources/faq.html" class="quick-link">FAQ</a></p>
</div>
<hr>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>What Comes After Session 4?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Immediate:</strong> - Complete all exercises in the notebook - Experiment with different architectures - Try your own hyperparameter combinations - Apply to Philippine imagery (optional challenge)</p>
<p><strong>Day 3 Preview:</strong> - <strong>U-Net for Semantic Segmentation:</strong> Pixel-level land cover classification - <strong>Flood Mapping Case Study:</strong> Central Luzon with Sentinel-1 SAR - <strong>Object Detection:</strong> Metro Manila building/settlement detection - <strong>Advanced Architectures:</strong> Deeper networks, attention mechanisms</p>
<p><strong>Preparation for Day 3:</strong> - Ensure you understand CNN fundamentals - Be comfortable with TensorFlow/Keras syntax - Know how to debug training issues - Understand when to use different architectures</p>
<p><a href="../../day3/index.html" class="btn btn-outline-primary">Preview Day 3 ‚Üí</a></p>
</div>
</div>
<hr>
</section>
<section id="assessment-exercises" class="level2">
<h2 class="anchored" data-anchor-id="assessment-exercises">Assessment &amp; Exercises</h2>
<section id="formative-assessment-in-notebook" class="level3">
<h3 class="anchored" data-anchor-id="formative-assessment-in-notebook">Formative Assessment (In-Notebook)</h3>
<ul class="task-list">
<li><label><input type="checkbox">Successfully configure GPU environment</label></li>
<li><label><input type="checkbox">Load and visualize EuroSAT dataset</label></li>
<li><label><input type="checkbox">Build CNN architecture from scratch</label></li>
<li><label><input type="checkbox">Train model to &gt;90% accuracy</label></li>
<li><label><input type="checkbox">Generate confusion matrix</label></li>
<li><label><input type="checkbox">Implement transfer learning with ResNet50</label></li>
<li><label><input type="checkbox">Compare results from-scratch vs transfer learning</label></li>
</ul>
</section>
<section id="challenge-exercises" class="level3">
<h3 class="anchored" data-anchor-id="challenge-exercises">Challenge Exercises</h3>
<p><strong>Exercise 1: Architecture Design</strong> - Modify the CNN to have 4 convolutional blocks instead of 3 - Add batch normalization after each convolution - Compare training speed and final accuracy</p>
<p><strong>Exercise 2: Hyperparameter Tuning</strong> - Test learning rates: [0.001, 0.0001, 0.00001] - Test batch sizes: [16, 32, 64] - Find optimal combination for fastest convergence</p>
<p><strong>Exercise 3: Advanced Augmentation</strong> - Add RandomBrightness and RandomContrast - Implement mixup augmentation - Measure impact on validation accuracy</p>
<p><strong>Exercise 4: Multi-spectral CNN</strong> (Advanced) - Load EuroSAT 13-band version - Modify input layer to accept all bands - Compare RGB vs multi-spectral performance</p>
<p><strong>Exercise 5: Philippine Application</strong> (Capstone) - Apply trained model to Palawan Sentinel-2 patches - Compare predictions with Session 2 Random Forest - Identify areas where CNN performs better/worse</p>
<hr>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>üí° Instructor Notes
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Timing Management:</strong> - <strong>Part A (Setup &amp; Data):</strong> Can take 35-40 min if students unfamiliar with Colab GPU setup - <strong>Part B (Build CNN):</strong> Usually 40-45 min, architecture design is tricky for beginners - <strong>Part C (Training):</strong> 30-40 min including watching training live - <strong>Part D (Evaluation):</strong> 25-30 min, confusion matrix analysis takes time - <strong>Part E (Transfer Learning):</strong> 15-20 min, can be shortened if running behind - <strong>Part F (Philippine Context):</strong> 10-15 min discussion</p>
<p><strong>Common Student Questions:</strong> - ‚ÄúWhy is my GPU not detected?‚Äù ‚Üí Check runtime type, may need reconnect - ‚ÄúTraining is very slow on CPU‚Äù ‚Üí Emphasize GPU requirement, show how to enable - ‚ÄúWhat batch size should I use?‚Äù ‚Üí Start with 32, reduce if OOM errors - ‚ÄúWhy transfer learning?‚Äù ‚Üí Explain data efficiency, show time savings - ‚ÄúCan I use PyTorch instead?‚Äù ‚Üí Yes, but maintain focus; TensorFlow for consistency</p>
<p><strong>Teaching Tips:</strong> - <strong>Show failures:</strong> Demonstrate overfitting, then fix it - <strong>Visualize:</strong> Use TensorBoard or matplotlib for learning curves in real-time - <strong>Pause for training:</strong> Use 5-10 min training time for Q&amp;A or breaks - <strong>Compare with RF:</strong> Reinforce why we learned both approaches</p>
<p><strong>Technical Preparation:</strong> - Pre-download EuroSAT to Google Drive as backup - Test notebook 24 hours before session - Have pre-trained models ready in case training fails - Prepare troubleshooting guide printout - Test on both GPU and CPU for comparison</p>
<p><strong>Extension Activities for Fast Finishers:</strong> - Implement ensemble of multiple CNNs - Try different pre-trained models (EfficientNet, MobileNet) - Explore GradCAM for visualization - Start Day 3 preview material</p>
</div>
</div>
</div>
<hr>
<p><em>This session is part of the CoPhil 4-Day Advanced Training on AI/ML for Earth Observation, funded by the European Union under the Global Gateway initiative and delivered in partnership with PhilSA and DOST.</em></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<script src="https://utteranc.es/client.js" repo="cophil-training-v1.0" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../day2/sessions/session3.html" class="pagination-link" aria-label="Session 3: Introduction to Deep Learning and CNNs">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Session 3: Introduction to Deep Learning and CNNs</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../day2/notebooks/session1_theory_notebook_STUDENT.html" class="pagination-link" aria-label="Session 1 Theory: Understanding Random Forest for Earth Observation">
        <span class="nav-page-text">Session 1 Theory: Understanding Random Forest for Earth Observation</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>CoPhil EO AI/ML Training Programme</p>
</div>   
    <div class="nav-footer-center">
<p>Funded by the European Union - Global Gateway Initiative</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:skotsopoulos@neuralio.ai">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://philsa.gov.ph">
      <i class="bi bi-globe" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>