{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0922ee7b",
   "metadata": {},
   "source": [
    "# Day 4, Session 2 · Instructor Notebook\n",
    "### LSTM drought forecasting with Google Earth Engine NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7933713",
   "metadata": {},
   "source": [
    "## 0. Session guide\n",
    "\n",
    "- Run this notebook before class to ensure Earth Engine access is configured.\n",
    "- Keep the student notebook side-by-side; mirror the same sequence but provide full solutions here.\n",
    "- If Earth Engine is unavailable during delivery, use the cached sample CSV to proceed with the modelling part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71958666",
   "metadata": {},
   "source": [
    "## 1. Environment check\n",
    "\n",
    "Install Earth Engine if it is missing (one-time per environment). Uncomment the cell below when provisioning new machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99690e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install earthengine-api --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e2a120",
   "metadata": {},
   "source": [
    "Authenticate once per user (opens a browser window). Skip if already authenticated on this machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8799a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "\n",
    "# Update this to your Cloud project that has the Earth Engine API enabled.\n",
    "GEE_PROJECT = os.environ.get('EE_PROJECT') or os.environ.get('GEE_PROJECT') or 'your-ee-project-id'\n",
    "\n",
    "if GEE_PROJECT == 'your-ee-project-id':\n",
    "    raise ValueError('Set GEE_PROJECT to your Earth Engine project ID (or export EE_PROJECT env var).')\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=GEE_PROJECT)\n",
    "    print(f'Connected to Earth Engine project: {GEE_PROJECT}')\n",
    "except Exception as exc:\n",
    "    print('Earth Engine initialization failed, attempting authentication...')\n",
    "    ee.Authenticate(auth_mode='notebook', project=GEE_PROJECT)\n",
    "    ee.Initialize(project=GEE_PROJECT)\n",
    "    print(f'Authenticated and connected to project: {GEE_PROJECT}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48ee69",
   "metadata": {},
   "source": [
    "## 2. Imports & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397cb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a4b462",
   "metadata": {},
   "source": [
    "## 3. Define Mindanao regions (Earth Engine geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c41f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_GEOMETRIES = {\n",
    "    \"Bukidnon\": ee.Geometry.Polygon([\n",
    "        [124.36, 8.84],\n",
    "        [124.36, 7.05],\n",
    "        [125.63, 7.05],\n",
    "        [125.63, 8.84],\n",
    "        [124.36, 8.84]\n",
    "    ]),\n",
    "    \"South Cotabato\": ee.Geometry.Polygon([\n",
    "        [124.28, 6.88],\n",
    "        [124.28, 5.68],\n",
    "        [125.30, 5.68],\n",
    "        [125.30, 6.88],\n",
    "        [124.28, 6.88]\n",
    "    ])\n",
    "}\n",
    "\n",
    "REGION_GEOMETRIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424bd48b",
   "metadata": {},
   "source": [
    "## 4. Helper to fetch Sentinel-2 NDVI from Google Earth Engine\n",
    "\n",
    "Adjust the parameters as needed (cloud filter, temporal window, reducer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_monthly_ndvi(regions, start_date='2018-01-01', end_date='2023-12-31', cloud_pct=35, scale=20):\n",
    "    \"\"\"Return a wide DataFrame with monthly NDVI for each region.\"\"\"\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    months = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "\n",
    "    def mask_s2_sr(image):\n",
    "        scl = image.select('SCL')\n",
    "        mask = (\n",
    "            scl.neq(0)\n",
    "            .And(scl.neq(1))\n",
    "            .And(scl.neq(3))\n",
    "            .And(scl.neq(7))\n",
    "            .And(scl.neq(8))\n",
    "            .And(scl.neq(9))\n",
    "            .And(scl.neq(10))\n",
    "            .And(scl.neq(11))\n",
    "        )\n",
    "        return image.updateMask(mask).copyProperties(image, image.propertyNames())\n",
    "\n",
    "    def add_ndvi(image):\n",
    "        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "        return image.addBands(ndvi)\n",
    "\n",
    "    collection = (\n",
    "        ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterDate(start_date.strftime('%Y-%m-%d'), (end_date + pd.offsets.Day(1)).strftime('%Y-%m-%d'))\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', cloud_pct))\n",
    "        .map(mask_s2_sr)\n",
    "        .map(add_ndvi)\n",
    "    )\n",
    "\n",
    "    records = []\n",
    "    for location, geometry in regions.items():\n",
    "        for month_start in months:\n",
    "            month_end = month_start + pd.offsets.MonthBegin(1)\n",
    "            exclusive_end = min(month_end, end_date + pd.offsets.Day(1))\n",
    "            monthly = collection.filterDate(\n",
    "                month_start.strftime('%Y-%m-%d'),\n",
    "                exclusive_end.strftime('%Y-%m-%d')\n",
    "            )\n",
    "            if monthly.size().getInfo() == 0:\n",
    "                ndvi_value = None\n",
    "            else:\n",
    "                composite = monthly.median()\n",
    "                stats = composite.select('NDVI').reduceRegion(\n",
    "                    reducer=ee.Reducer.mean(),\n",
    "                    geometry=geometry,\n",
    "                    scale=scale,\n",
    "                    bestEffort=True,\n",
    "                    maxPixels=1_000_000\n",
    "                )\n",
    "                ndvi_info = stats.get('NDVI')\n",
    "                ndvi_value = ee.Number(ndvi_info).getInfo() if ndvi_info is not None else None\n",
    "            records.append({\n",
    "                'month': month_start,\n",
    "                'location': location,\n",
    "                'ndvi': ndvi_value\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df['month'] = pd.to_datetime(df['month'])\n",
    "    df.sort_values(['location', 'month'], inplace=True)\n",
    "    pivot = df.pivot(index='month', columns='location', values='ndvi')\n",
    "    pivot = pivot.interpolate(limit_direction='both')\n",
    "    pivot = pivot.reset_index()\n",
    "    pivot.columns = ['month'] + [f'NDVI_{col.replace(\" \", \"\")}' for col in pivot.columns[1:]]\n",
    "    return pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a17fb5",
   "metadata": {},
   "source": [
    "## 5. Load data (choose Earth Engine or cached sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = Path('day4/data')\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "CACHE_PATH = CACHE_DIR / 'mindanao_ndvi_sample.csv'  # provided sample export\n",
    "LATEST_EXPORT_PATH = CACHE_DIR / 'mindanao_ndvi_gee.csv'\n",
    "\n",
    "USE_GEE = True  # set to False only if Earth Engine is unavailable\n",
    "\n",
    "if USE_GEE:\n",
    "    try:\n",
    "        ndvi_df = fetch_monthly_ndvi(\n",
    "            REGION_GEOMETRIES,\n",
    "            start_date='2018-01-01',\n",
    "            end_date='2023-12-31',\n",
    "            cloud_pct=35,\n",
    "            scale=20\n",
    "        )\n",
    "        ndvi_df.to_csv(LATEST_EXPORT_PATH, index=False)\n",
    "        print(f'Fetched {len(ndvi_df)} monthly observations from Earth Engine (project: {GEE_PROJECT}).')\n",
    "    except Exception as exc:\n",
    "        print(f'Earth Engine fetch failed ({exc}). Falling back to cached sample CSV...')\n",
    "        ndvi_df = pd.read_csv(CACHE_PATH)\n",
    "else:\n",
    "    print('USE_GEE is False – reading cached sample export. Switch to True for live Sentinel-2 NDVI.')\n",
    "    ndvi_df = pd.read_csv(CACHE_PATH)\n",
    "\n",
    "ndvi_df['month'] = pd.to_datetime(ndvi_df['month'])\n",
    "ndvi_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd62a69",
   "metadata": {},
   "source": [
    "### Notes for instructors\n",
    "\n",
    "- The sample CSV is a lightweight export from this pipeline—use only when Earth Engine access is unavailable.\n",
    "- Keep both files in `day4/data/` so the class can fall back gracefully if GEE is down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c34dac",
   "metadata": {},
   "source": [
    "## 6. Explore NDVI trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb43cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [col for col in ndvi_df.columns if col.startswith('NDVI_')]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for column in locations:\n",
    "    label = column.replace('NDVI_', '')\n",
    "    ax.plot(ndvi_df['month'], ndvi_df[column], marker='o', label=label)\n",
    "\n",
    "ax.axhline(0.4, color='red', linestyle='--', linewidth=1, label='NDVI 0.40 threshold')\n",
    "ax.set_title('Monthly NDVI (GEE export / fallback)\n",
    "Bukidnon vs South Cotabato')\n",
    "ax.set_ylabel('NDVI')\n",
    "ax.set_xlabel('Month')\n",
    "ax.legend(loc='lower right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fecd09",
   "metadata": {},
   "source": [
    "## 7. Seasonal statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_months = [5, 6, 7, 8, 9, 10]\n",
    "wet_months = [11, 12, 1, 2, 3, 4]\n",
    "\n",
    "summary_rows = []\n",
    "for column in locations:\n",
    "    series = ndvi_df[['month', column]].copy()\n",
    "    dry_mean = series[series['month'].dt.month.isin(dry_months)][column].mean()\n",
    "    wet_mean = series[series['month'].dt.month.isin(wet_months)][column].mean()\n",
    "    min_idx = series[column].idxmin()\n",
    "    summary_rows.append({\n",
    "        'location': column.replace('NDVI_', ''),\n",
    "        'dry_mean': round(dry_mean, 3),\n",
    "        'wet_mean': round(wet_mean, 3),\n",
    "        'lowest_ndvi': round(series.loc[min_idx, column], 3),\n",
    "        'lowest_month': series.loc[min_idx, 'month'].strftime('%Y-%m')\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147b5ff5",
   "metadata": {},
   "source": [
    "## 8. Build sliding-window sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70eac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK = 12  # months\n",
    "HORIZON = 1    # predict 1 month ahead\n",
    "\n",
    "records = []\n",
    "for column in locations:\n",
    "    values = ndvi_df[column].values.astype(np.float32)\n",
    "    months = ndvi_df['month'].values\n",
    "    for idx in range(LOOKBACK, len(values) - HORIZON + 1):\n",
    "        history = values[idx - LOOKBACK:idx]\n",
    "        target_value = values[idx + HORIZON - 1]\n",
    "        target_month = months[idx + HORIZON - 1]\n",
    "        records.append({\n",
    "            'location': column,\n",
    "            'target_month': target_month,\n",
    "            'sequence': history,\n",
    "            'target': target_value\n",
    "        })\n",
    "\n",
    "sequence_df = pd.DataFrame(records)\n",
    "sequence_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332db33",
   "metadata": {},
   "source": [
    "## 9. Temporal train/validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = pd.Timestamp('2021-12-31')\n",
    "val_end = pd.Timestamp('2022-12-31')\n",
    "\n",
    "train_mask = sequence_df['target_month'] <= train_end\n",
    "val_mask = (sequence_df['target_month'] > train_end) & (sequence_df['target_month'] <= val_end)\n",
    "test_mask = sequence_df['target_month'] > val_end\n",
    "\n",
    "print(f'Train samples: {train_mask.sum()}')\n",
    "print(f'Validation samples: {val_mask.sum()}')\n",
    "print(f'Test samples: {test_mask.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349904b",
   "metadata": {},
   "source": [
    "## 10. Scaling using training range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f605393",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_month_mask = ndvi_df['month'] <= train_end\n",
    "train_values = ndvi_df.loc[train_month_mask, locations].values.flatten()\n",
    "ndvi_min, ndvi_max = train_values.min(), train_values.max()\n",
    "print(f'Training NDVI range: {ndvi_min:.3f} → {ndvi_max:.3f}')\n",
    "\n",
    "if ndvi_max - ndvi_min < 1e-6:\n",
    "    raise ValueError('Training NDVI range is too narrow for scaling.')\n",
    "\n",
    "scale = lambda arr: (arr - ndvi_min) / (ndvi_max - ndvi_min)\n",
    "invert = lambda arr: arr * (ndvi_max - ndvi_min) + ndvi_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435baf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_split(mask):\n",
    "    X = np.stack(sequence_df.loc[mask, 'sequence'].values)\n",
    "    y = sequence_df.loc[mask, 'target'].values.astype(np.float32)\n",
    "    dates = sequence_df.loc[mask, 'target_month'].values\n",
    "    locs = sequence_df.loc[mask, 'location'].values\n",
    "\n",
    "    X_scaled = scale(X)[:, :, None].astype(np.float32)\n",
    "    y_scaled = scale(y)[:, None].astype(np.float32)\n",
    "    return X_scaled, y_scaled, dates, locs\n",
    "\n",
    "X_train, y_train, dates_train, locs_train = stack_split(train_mask)\n",
    "X_val, y_val, dates_val, locs_val = stack_split(val_mask)\n",
    "X_test, y_test, dates_test, locs_test = stack_split(test_mask)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c5b9b",
   "metadata": {},
   "source": [
    "## 11. PyTorch datasets & data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = SequenceDataset(X_train, y_train)\n",
    "val_dataset = SequenceDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f4d6bd",
   "metadata": {},
   "source": [
    "## 12. Define LSTM forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDVIForecaster(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_sizes=(64, 32), dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_sizes[0],\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.projection = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[1], 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_hidden = lstm_out[:, -1, :]\n",
    "        projected = self.activation(self.projection(last_hidden))\n",
    "        return self.output_layer(projected)\n",
    "\n",
    "model = NDVIForecaster().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68447634",
   "metadata": {},
   "source": [
    "## 13. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f824ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_loader, model, criterion, optimizer=None):\n",
    "    if optimizer:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss, total_mae = 0.0, 0.0\n",
    "    for features, targets in data_loader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        if optimizer:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        batch_size = features.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_mae += torch.mean(torch.abs(outputs - targets)).item() * batch_size\n",
    "\n",
    "    dataset_size = len(data_loader.dataset)\n",
    "    return total_loss / dataset_size, total_mae / dataset_size\n",
    "\n",
    "EPOCHS = 75\n",
    "history = {'epoch': [], 'train_loss': [], 'val_loss': [], 'train_mae': [], 'val_mae': []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_mae = run_epoch(train_loader, model, criterion, optimizer)\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_mae = run_epoch(val_loader, model, criterion)\n",
    "\n",
    "    history['epoch'].append(epoch)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_mae'].append(train_mae)\n",
    "    history['val_mae'].append(val_mae)\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f'Epoch {epoch:03d} | train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_mae={val_mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11061fc6",
   "metadata": {},
   "source": [
    "## 14. Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(history_df['epoch'], history_df['train_loss'], label='Train MSE')\n",
    "axes[0].plot(history_df['epoch'], history_df['val_loss'], label='Val MSE')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('MSE')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history_df['epoch'], history_df['train_mae'], label='Train MAE')\n",
    "axes[1].plot(history_df['epoch'], history_df['val_mae'], label='Val MAE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('MAE')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b9f1d",
   "metadata": {},
   "source": [
    "## 15. Evaluation on held-out months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(torch.tensor(X_test, dtype=torch.float32, device=device))\n",
    "\n",
    "y_test_pred = test_predictions.cpu().numpy().squeeze()\n",
    "y_test_true = y_test.squeeze()\n",
    "\n",
    "pred_ndvi = invert(y_test_pred)\n",
    "true_ndvi = invert(y_test_true)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'target_month': pd.to_datetime(dates_test),\n",
    "    'location': [loc.replace('NDVI_', '') for loc in locs_test],\n",
    "    'actual_ndvi': true_ndvi,\n",
    "    'predicted_ndvi': pred_ndvi\n",
    "}).sort_values('target_month')\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa721802",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(pred_ndvi - true_ndvi))\n",
    "rmse = np.sqrt(np.mean((pred_ndvi - true_ndvi) ** 2))\n",
    "print(f'Test MAE: {mae:.3f}')\n",
    "print(f'Test RMSE: {rmse:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f28730",
   "metadata": {},
   "outputs": [],
   "source": [
    "for location, group in results_df.groupby('location'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(group['target_month'], group['actual_ndvi'], marker='o', label='Actual')\n",
    "    ax.plot(group['target_month'], group['predicted_ndvi'], marker='x', linestyle='--', label='Predicted')\n",
    "    ax.axhline(0.4, color='red', linestyle='--', linewidth=1, label='NDVI 0.40 threshold')\n",
    "    ax.set_title(f'{location} · held-out NDVI forecast')\n",
    "    ax.set_ylabel('NDVI')\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b656a89",
   "metadata": {},
   "source": [
    "## 16. Drought alert metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROUGHT_THRESHOLD = 0.40\n",
    "\n",
    "results_df['actual_drought'] = results_df['actual_ndvi'] < DROUGHT_THRESHOLD\n",
    "results_df['predicted_drought'] = results_df['predicted_ndvi'] < DROUGHT_THRESHOLD\n",
    "\n",
    "confusion = pd.crosstab(results_df['actual_drought'], results_df['predicted_drought'],\n",
    "                        rownames=['actual'], colnames=['predicted'], dropna=False)\n",
    "print(confusion)\n",
    "\n",
    "true_positives = int(((results_df['actual_drought']) & (results_df['predicted_drought'])).sum())\n",
    "false_positives = int((~results_df['actual_drought'] & results_df['predicted_drought']).sum())\n",
    "false_negatives = int((results_df['actual_drought'] & ~results_df['predicted_drought']).sum())\n",
    "precision = true_positives / (true_positives + false_positives + 1e-6)\n",
    "recall = true_positives / (true_positives + false_negatives + 1e-6)\n",
    "\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503440d",
   "metadata": {},
   "source": [
    "## 17. Teaching notes & extensions\n",
    "\n",
    "- Demonstrate toggling `USE_GEE` to show real-time access vs cached workflow.\n",
    "- Encourage participants to export their own geometries (barangay, irrigation system) for custom runs.\n",
    "- Extensions: merge rainfall/SPEI, try multi-output LSTMs, or run explainability (SHAP, integrated gradients)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
