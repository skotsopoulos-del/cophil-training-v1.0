{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4, Session 2: LSTM Drought Monitoring Lab - INSTRUCTOR VERSION\n",
    "## Complete Solution for Mindanao Drought Forecasting\n",
    "\n",
    "This notebook contains complete working code for the LSTM drought monitoring lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mindanao_drought_data(start_date='2015-01-01', end_date='2021-12-31'):\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "    n_months = len(dates)\n",
    "    \n",
    "    ndvi = np.zeros(n_months)\n",
    "    rainfall = np.zeros(n_months)\n",
    "    temperature = np.zeros(n_months)\n",
    "    oni = np.zeros(n_months)\n",
    "    \n",
    "    base_ndvi = 0.70\n",
    "    \n",
    "    for i, date in enumerate(dates):\n",
    "        month = date.month\n",
    "        year = date.year\n",
    "        \n",
    "        if month in [11, 12, 1, 2, 3]:\n",
    "            seasonal_factor = 0.85 + 0.10 * np.sin(2 * np.pi * month / 12)\n",
    "            rain_base = 250\n",
    "            temp_base = 26\n",
    "        else:\n",
    "            seasonal_factor = 0.75 + 0.05 * np.sin(2 * np.pi * month / 12)\n",
    "            rain_base = 80\n",
    "            temp_base = 28\n",
    "        \n",
    "        drought_factor = 1.0\n",
    "        if year == 2015 and month >= 6:\n",
    "            drought_factor = 0.60\n",
    "            oni[i] = 2.5 + np.random.randn() * 0.3\n",
    "            rain_base *= 0.4\n",
    "            temp_base += 2\n",
    "        elif year == 2016 and month <= 6:\n",
    "            drought_factor = 0.65\n",
    "            oni[i] = 2.0 + np.random.randn() * 0.3\n",
    "            rain_base *= 0.5\n",
    "            temp_base += 1.5\n",
    "        else:\n",
    "            oni[i] = np.random.randn() * 0.5\n",
    "        \n",
    "        ndvi[i] = base_ndvi * seasonal_factor * drought_factor + np.random.normal(0, 0.03)\n",
    "        ndvi[i] = np.clip(ndvi[i], 0.2, 0.9)\n",
    "        rainfall[i] = max(0, rain_base + np.random.normal(0, 40))\n",
    "        temperature[i] = temp_base + np.random.normal(0, 1.5)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'ndvi': ndvi,\n",
    "        'rainfall': rainfall,\n",
    "        'temperature': temperature,\n",
    "        'oni': oni\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = generate_mindanao_drought_data()\n",
    "print(f\"Generated {len(df)} months\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "axes[0].plot(df['date'], df['ndvi'], 'g-', linewidth=2)\n",
    "axes[0].axvspan(pd.Timestamp('2015-06-01'), pd.Timestamp('2016-06-01'), \n",
    "                alpha=0.2, color='red', label='2015-16 Drought')\n",
    "axes[0].set_ylabel('NDVI')\n",
    "axes[0].set_title('Mindanao NDVI (2015-2021)', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].bar(df['date'], df['rainfall'], color='blue', alpha=0.6, width=20)\n",
    "axes[1].set_ylabel('Rainfall (mm)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "colors = ['red' if x > 0.5 else 'blue' if x < -0.5 else 'gray' for x in df['oni']]\n",
    "axes[2].bar(df['date'], df['oni'], color=colors, alpha=0.7, width=20)\n",
    "axes[2].axhline(y=0.5, color='red', linestyle='--', alpha=0.5)\n",
    "axes[2].set_ylabel('ONI Index')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "# Seasonal means\n",
    "dry_season_ndvi = df[df['month'].isin([5,6,7,8,9,10])]['ndvi'].mean()\n",
    "wet_season_ndvi = df[df['month'].isin([11,12,1,2,3,4])]['ndvi'].mean()\n",
    "\n",
    "print(f\"Dry season mean NDVI: {dry_season_ndvi:.3f}\")\n",
    "print(f\"Wet season mean NDVI: {wet_season_ndvi:.3f}\")\n",
    "\n",
    "# Lowest NDVI\n",
    "lowest_idx = df['ndvi'].idxmin()\n",
    "print(f\"\\nLowest NDVI: {df.loc[lowest_idx, 'ndvi']:.3f} on {df.loc[lowest_idx, 'date']}\")\n",
    "\n",
    "# Correlation\n",
    "correlation = df['ndvi'].corr(df['rainfall'])\n",
    "print(f\"\\nNDVI-Rainfall correlation: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK_WINDOW = 12\n",
    "FORECAST_HORIZON = 1\n",
    "\n",
    "feature_columns = ['ndvi', 'rainfall', 'temperature', 'oni']\n",
    "target_column = 'ndvi'\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_scaled = df.copy()\n",
    "df_scaled[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "\n",
    "def create_sequences(data, features, target, lookback, horizon):\n",
    "    X, y, dates = [], [], []\n",
    "    feature_data = data[features].values\n",
    "    target_data = data[target].values\n",
    "    date_data = data['date'].values\n",
    "    \n",
    "    for i in range(lookback, len(data) - horizon + 1):\n",
    "        X.append(feature_data[i - lookback:i])\n",
    "        y.append(target_data[i + horizon - 1])\n",
    "        dates.append(date_data[i + horizon - 1])\n",
    "    \n",
    "    return np.array(X), np.array(y), np.array(dates)\n",
    "\n",
    "X, y, dates = create_sequences(df_scaled, feature_columns, target_column, \n",
    "                                LOOKBACK_WINDOW, FORECAST_HORIZON)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Val-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = pd.Timestamp('2019-12-31')\n",
    "val_end = pd.Timestamp('2020-12-31')\n",
    "\n",
    "train_mask = dates <= train_end\n",
    "val_mask = (dates > train_end) & (dates <= val_end)\n",
    "test_mask = dates > val_end\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_val, y_val = X[val_mask], y[val_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "dates_train = dates[train_mask]\n",
    "dates_val = dates[val_mask]\n",
    "dates_test = dates[test_mask]\n",
    "\n",
    "print(f\"Train: {len(X_train)} sequences\")\n",
    "print(f\"Val: {len(X_val)} sequences\")\n",
    "print(f\"Test: {len(X_test)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape, lstm_units=[64, 32], dropout=0.2, learning_rate=0.001):\n",
    "    model = Sequential(name='LSTM_Drought_Forecaster')\n",
    "    \n",
    "    # First LSTM layer\n",
    "    model.add(LSTM(lstm_units[0], return_sequences=True, input_shape=input_shape, name='LSTM_1'))\n",
    "    model.add(Dropout(dropout, name='Dropout_1'))\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(lstm_units[1], return_sequences=False, name='LSTM_2'))\n",
    "    model.add(Dropout(dropout, name='Dropout_2'))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Dense(16, activation='relu', name='Dense_1'))\n",
    "    model.add(Dense(1, activation='linear', name='Output'))\n",
    "    \n",
    "    # Compile\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (LOOKBACK_WINDOW, len(feature_columns))\n",
    "model = build_lstm_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('Training History', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history.history['mae'], label='Train MAE')\n",
    "axes[1].plot(history.history['val_mae'], label='Val MAE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('MAE History', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test).flatten()\n",
    "\n",
    "def inverse_transform_ndvi(values, scaler, feature_columns):\n",
    "    dummy = np.zeros((len(values), len(feature_columns)))\n",
    "    ndvi_idx = feature_columns.index('ndvi')\n",
    "    dummy[:, ndvi_idx] = values\n",
    "    inverse = scaler.inverse_transform(dummy)\n",
    "    return inverse[:, ndvi_idx]\n",
    "\n",
    "y_test_actual = inverse_transform_ndvi(y_test, scaler, feature_columns)\n",
    "y_test_pred_original = inverse_transform_ndvi(y_test_pred, scaler, feature_columns)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, y_test_pred_original))\n",
    "mae = mean_absolute_error(y_test_actual, y_test_pred_original)\n",
    "r2 = r2_score(y_test_actual, y_test_pred_original)\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE:  {mae:.4f}\")\n",
    "print(f\"  RÂ²:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Time series\n",
    "axes[0].plot(dates_test, y_test_actual, 'g-', linewidth=2, marker='o', \n",
    "             markersize=4, label='Actual NDVI')\n",
    "axes[0].plot(dates_test, y_test_pred_original, 'r--', linewidth=2, marker='x', \n",
    "             markersize=4, label='Predicted NDVI')\n",
    "axes[0].set_xlabel('Date', fontsize=12)\n",
    "axes[0].set_ylabel('NDVI', fontsize=12)\n",
    "axes[0].set_title('LSTM Drought Forecasting: Test Set (2021)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot\n",
    "axes[1].scatter(y_test_actual, y_test_pred_original, alpha=0.6, edgecolors='k', linewidths=0.5)\n",
    "min_val = min(y_test_actual.min(), y_test_pred_original.min())\n",
    "max_val = max(y_test_actual.max(), y_test_pred_original.max())\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect')\n",
    "axes[1].set_xlabel('Actual NDVI', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted NDVI', fontsize=12)\n",
    "axes[1].set_title('Prediction Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operational Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROUGHT_THRESHOLD = 0.4\n",
    "\n",
    "predicted_drought = y_test_pred_original < DROUGHT_THRESHOLD\n",
    "actual_drought = y_test_actual < DROUGHT_THRESHOLD\n",
    "\n",
    "true_positives = np.sum(predicted_drought & actual_drought)\n",
    "false_positives = np.sum(predicted_drought & ~actual_drought)\n",
    "true_negatives = np.sum(~predicted_drought & ~actual_drought)\n",
    "false_negatives = np.sum(~predicted_drought & actual_drought)\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives) if (false_positives + true_negatives) > 0 else 0\n",
    "\n",
    "print(\"\\nðŸ“Š Operational Performance (NDVI < 0.4 = Drought):\")\n",
    "print(f\"  True Positives: {true_positives}\")\n",
    "print(f\"  False Positives: {false_positives}\")\n",
    "print(f\"  True Negatives: {true_negatives}\")\n",
    "print(f\"  False Negatives: {false_negatives}\")\n",
    "print(f\"\\n  Precision: {precision:.2%}\")\n",
    "print(f\"  Recall: {recall:.2%}\")\n",
    "print(f\"  False Alarm Rate: {false_alarm_rate:.2%}\")\n",
    "\n",
    "print(\"\\nâœ… Model is ready for operational deployment!\")\n",
    "print(\"   Integration points:\")\n",
    "print(\"   - PAGASA seasonal forecast system\")\n",
    "print(\"   - DA agricultural advisory platform\")\n",
    "print(\"   - PhilSA Space+ Dashboard\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
