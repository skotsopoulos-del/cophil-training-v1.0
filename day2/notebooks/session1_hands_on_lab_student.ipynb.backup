{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1 Hands-on Lab: Palawan Land Cover Classification with Random Forest\n",
    "\n",
    "**Duration:** 90 minutes (1.5 hours)\n",
    "\n",
    "**Instructor:** CoPhil Advanced Training\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this hands-on lab, you will be able to:\n",
    "\n",
    "1. **Set up and authenticate** Google Earth Engine (GEE) in Google Colab\n",
    "2. **Acquire and preprocess** Sentinel-2 satellite imagery for a Philippine study area\n",
    "3. **Calculate spectral indices** (NDVI, NDWI, NDBI, EVI) for land cover discrimination\n",
    "4. **Create training datasets** by defining land cover classes and sampling spectral signatures\n",
    "5. **Train a Random Forest classifier** using GEE's machine learning capabilities\n",
    "6. **Perform land cover classification** on Sentinel-2 imagery\n",
    "7. **Assess accuracy** using confusion matrices and statistical metrics\n",
    "8. **Generate area statistics** for each land cover class\n",
    "9. **Export results** for further analysis and visualization\n",
    "10. **Apply classification** to real-world Natural Resource Management (NRM) challenges in the Philippines\n",
    "\n",
    "---\n",
    "\n",
    "## Study Area: Palawan Province\n",
    "\n",
    "**Why Palawan?**\n",
    "\n",
    "- **UNESCO Biosphere Reserve**: Home to exceptional biodiversity and endemic species\n",
    "- **Conservation Priority**: Contains the Puerto Princesa Subterranean River National Park (UNESCO World Heritage Site)\n",
    "- **Environmental Challenges**: Deforestation, mining, agricultural expansion, tourism impacts\n",
    "- **NRM Relevance**: Critical for monitoring forest cover, mangroves, agricultural land conversion\n",
    "- **Policy Context**: Palawan Strategic Environmental Plan (SEP) requires regular land cover monitoring\n",
    "\n",
    "Palawan represents a critical case study where accurate land cover classification directly supports conservation planning and sustainable development decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Overview\n",
    "\n",
    "This notebook guides you through a complete supervised classification workflow using Random Forest:\n",
    "\n",
    "```\n",
    "Data Acquisition ‚Üí Preprocessing ‚Üí Feature Engineering ‚Üí Training Data ‚Üí Model Training ‚Üí Classification ‚Üí Validation ‚Üí Export\n",
    "```\n",
    "\n",
    "**Key Concepts Covered:**\n",
    "- Cloud computing for Earth Observation (Google Earth Engine)\n",
    "- Spectral signatures and feature extraction\n",
    "- Supervised machine learning (Random Forest)\n",
    "- Model explainability (feature importance)\n",
    "- Accuracy assessment and validation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Setup and Authentication (10 minutes)\n",
    "\n",
    "### Installing Required Libraries\n",
    "\n",
    "We'll use:\n",
    "- **earthengine-api**: Core GEE Python API\n",
    "- **geemap**: Interactive mapping and visualization\n",
    "- **pandas**: Data manipulation\n",
    "- **matplotlib/seaborn**: Visualization\n",
    "- **numpy**: Numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run only once)\n",
    "!pip install earthengine-api geemap pandas numpy matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")\n",
    "print(f\"Earth Engine API version: {ee.__version__}\")\n",
    "print(f\"Geemap version: {geemap.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticating with Google Earth Engine\n",
    "\n",
    "üí° **Understanding GEE Authentication:**\n",
    "\n",
    "Google Earth Engine requires authentication to access its computational resources and satellite data archives. The process involves:\n",
    "\n",
    "1. **Authenticate**: Links your Google account to GEE\n",
    "2. **Initialize**: Connects your Python session to GEE servers\n",
    "\n",
    "**First-time users:** You'll be redirected to a browser to grant permissions.\n",
    "\n",
    "**Returning users:** Authentication tokens are cached automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Authenticate and initialize Earth Engine\nimport ee\nimport geemap.core as geemap\n\nee.Authenticate()\nee.Initialize(project='YOUR-PROJECT-ID')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Common Issues:**\n",
    "\n",
    "- **Error: \"Unable to authenticate\"**: Clear browser cookies or try incognito mode\n",
    "- **Error: \"Project not registered\"**: Ensure you've registered your Google Cloud project with Earth Engine\n",
    "- **Error: \"User memory limit exceeded\"**: Wait a few hours or optimize your code to reduce memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Connection\n",
    "\n",
    "Let's verify our connection works by querying a simple dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test connection with a simple query\n# Instead of a specific image, we'll query a well-known dataset\ntest_collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n    .filterDate('2025-01-01', '2025-12-31') \\\n    .first()\n\n# Get basic info\ntry:\n    collection_info = test_collection.getInfo()\n    print(\"‚úì Connection successful!\")\n    print(f\"Test Image ID: {collection_info['id']}\")\n    print(f\"Available bands: {len(collection_info['bands'])} bands\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Connection test failed: {str(e)}\")\n    print(\"Please check your authentication and try again\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Interactive Map\n",
    "\n",
    "We'll create an interactive map centered on Palawan Province using geemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create interactive map centered on Palawan\n# Palawan center coordinates: approximately 10.5¬∞N, 118.8¬∞E\nMap = geemap.Map(center=[10.5, 118.8], zoom=8, height='600px')\n\n# Add basemap options (SATELLITE basemap)\n# Note: basemap is already set by default, or you can use addLayer for custom layers\n\nprint(\"‚úì Interactive map created\")\nprint(\"Use the map controls to pan, zoom, and explore Palawan\")\nMap"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B. Study Area Definition (5 minutes)\n",
    "\n",
    "We'll define the Palawan province boundary to clip our analysis to the region of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Understanding Administrative Boundaries:**\n",
    "\n",
    "For Philippine administrative boundaries, we have several options:\n",
    "\n",
    "1. **FAO GAUL Dataset**: Global Administrative Unit Layers (Level 0-2)\n",
    "2. **Manual geometry**: Define coordinates manually\n",
    "3. **PhilGIS**: Philippine GIS Data Clearinghouse (if imported to GEE)\n",
    "\n",
    "We'll use the FAO GAUL dataset, which includes Philippine provincial boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Palawan boundary using FAO GAUL dataset\n",
    "# Level 1 = Provincial level in the Philippines\n",
    "philippines = ee.FeatureCollection('FAO/GAUL/2015/level1')\n",
    "\n",
    "# Filter for Palawan province\n",
    "# Note: Palawan may be listed as \"Palawan\" or subdivided\n",
    "palawan = philippines.filter(ee.Filter.eq('ADM1_NAME', 'Palawan'))\n",
    "\n",
    "# Alternative: Define approximate boundary manually if GAUL filter doesn't work\n",
    "# Uncomment these lines if needed:\n",
    "# palawan_coords = [\n",
    "#     [117.5, 9.5], [117.5, 12.0], [119.5, 12.0], [119.5, 9.5], [117.5, 9.5]\n",
    "# ]\n",
    "# palawan = ee.Geometry.Polygon(palawan_coords)\n",
    "\n",
    "print(\"‚úì Palawan boundary defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the boundary on the map\nMap.addLayer(palawan, {'color': 'red'}, 'Palawan Boundary')\nMap.centerObject(palawan, 8)\n\n# Display basic information\narea_km2 = palawan.geometry().area().divide(1e6).getInfo()\nbounds = palawan.geometry().bounds().getInfo()\n\nprint(f\"Study Area: Palawan Province\")\nprint(f\"Approximate Area: {area_km2:,.0f} km¬≤\")\n\n# Safely extract bounding box coordinates\ntry:\n    if bounds and 'coordinates' in bounds:\n        print(f\"Bounding Box: {bounds['coordinates']}\")\n    else:\n        print(\"Bounding Box: Coordinates not available\")\nexcept:\n    print(\"Bounding Box: Could not retrieve coordinates\")\n\nMap"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîç **Interpretation:**\n",
    "\n",
    "- Palawan's total area is approximately 14,649 km¬≤\n",
    "- The province stretches about 450 km from northeast to southwest\n",
    "- It includes over 1,700 islands and islets\n",
    "- The main island contains diverse ecosystems: mountains, rainforests, mangroves, coral reefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C. Sentinel-2 Data Acquisition (20 minutes)\n",
    "\n",
    "### Loading Sentinel-2 Surface Reflectance Data\n",
    "\n",
    "üí° **Understanding Sentinel-2 Products:**\n",
    "\n",
    "- **COPERNICUS/S2_SR**: Surface Reflectance (Level-2A) - atmospherically corrected\n",
    "- **COPERNICUS/S2**: Top-of-Atmosphere Reflectance (Level-1C) - raw measurements\n",
    "\n",
    "We use **S2_SR_HARMONIZED** because atmospheric correction is already applied, making it analysis-ready for land cover classification.\n",
    "\n",
    "**Key Sentinel-2 Specifications:**\n",
    "- Revisit time: 5 days (with both satellites)\n",
    "- Spatial resolution: 10m (RGB, NIR), 20m (Red Edge, SWIR), 60m (coastal, aerosol)\n",
    "- Spectral bands: 13 bands covering visible to short-wave infrared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define date range for imagery\n# Using 2025 data (current year)\nstart_date = '2025-01-01'\nend_date = '2025-12-31'\n\nprint(f\"Date range: {start_date} to {end_date}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-2 Surface Reflectance collection\n",
    "s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                 .filterBounds(palawan)  # Filter by study area\n",
    "                 .filterDate(start_date, end_date)  # Filter by date range\n",
    "                 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)))  # Max 20% cloud cover\n",
    "\n",
    "# Get collection size\n",
    "collection_size = s2_collection.size().getInfo()\n",
    "print(f\"‚úì Sentinel-2 collection loaded\")\n",
    "print(f\"Number of images: {collection_size}\")\n",
    "\n",
    "if collection_size == 0:\n",
    "    print(\"‚ö†Ô∏è Warning: No images found. Try relaxing cloud cover filter or expanding date range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Masking\n",
    "\n",
    "üí° **Understanding Cloud Masking:**\n",
    "\n",
    "Clouds obscure the land surface and must be removed for accurate classification. Sentinel-2 includes a **QA60** band with cloud mask information:\n",
    "\n",
    "- **Bit 10**: Opaque clouds\n",
    "- **Bit 11**: Cirrus clouds\n",
    "\n",
    "We use bitwise operations to extract these flags and mask cloudy pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cloud masking function\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"\n",
    "    Masks clouds and cirrus from Sentinel-2 imagery using the QA60 band.\n",
    "    \n",
    "    Args:\n",
    "        image: ee.Image - Sentinel-2 image\n",
    "    \n",
    "    Returns:\n",
    "        ee.Image - Cloud-masked image\n",
    "    \"\"\"\n",
    "    qa = image.select('QA60')\n",
    "    \n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively\n",
    "    cloud_bit_mask = 1 << 10\n",
    "    cirrus_bit_mask = 1 << 11\n",
    "    \n",
    "    # Both flags should be set to zero, indicating clear conditions\n",
    "    mask = (qa.bitwiseAnd(cloud_bit_mask).eq(0)\n",
    "            .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0)))\n",
    "    \n",
    "    # Return the masked image, scaled to [0, 1]\n",
    "    return image.updateMask(mask).divide(10000)\n",
    "\n",
    "print(\"‚úì Cloud masking function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cloud masking to the collection\n",
    "s2_masked = s2_collection.map(mask_s2_clouds)\n",
    "\n",
    "print(\"‚úì Cloud masking applied to collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Composite Image\n",
    "\n",
    "üí° **Understanding Compositing:**\n",
    "\n",
    "To create a single analysis-ready image from multiple acquisitions, we use compositing:\n",
    "\n",
    "- **Median composite**: Reduces noise and cloud artifacts (robust to outliers)\n",
    "- **Mean composite**: Smoother but sensitive to outliers\n",
    "- **Percentile composite**: e.g., 25th percentile for dark features, 75th for bright features\n",
    "\n",
    "We'll use **median** as it's most robust for tropical regions with persistent cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create median composite\n",
    "s2_composite = s2_masked.median().clip(palawan)\n",
    "\n",
    "# Select bands for visualization and analysis\n",
    "# B2=Blue, B3=Green, B4=Red, B8=NIR, B11=SWIR1, B12=SWIR2\n",
    "bands = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']\n",
    "s2_composite = s2_composite.select(bands)\n",
    "\n",
    "print(\"‚úì Median composite created\")\n",
    "print(f\"Selected bands: {bands}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing RGB Composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define visualization parameters for true color (RGB)\n",
    "rgb_vis = {\n",
    "    'bands': ['B4', 'B3', 'B2'],  # Red, Green, Blue\n",
    "    'min': 0.0,\n",
    "    'max': 0.3,\n",
    "    'gamma': 1.4\n",
    "}\n",
    "\n",
    "# Add RGB composite to map\n",
    "Map.addLayer(s2_composite, rgb_vis, 'Sentinel-2 RGB (True Color)')\n",
    "\n",
    "print(\"‚úì RGB composite added to map\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing False Color Composite\n",
    "\n",
    "üí° **Understanding False Color Composites:**\n",
    "\n",
    "False color composites use non-visible bands to highlight specific features:\n",
    "\n",
    "- **NIR-Red-Green (B8-B4-B3)**: Vegetation appears bright red (healthy vegetation reflects strongly in NIR)\n",
    "- **SWIR-NIR-Red (B12-B8-B4)**: Useful for geology, soil moisture\n",
    "- **Agriculture (B11-B8-B2)**: Highlights agricultural areas\n",
    "\n",
    "We'll use **NIR-Red-Green** as it's excellent for distinguishing vegetation from other land covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define visualization parameters for false color (NIR-Red-Green)\n",
    "false_color_vis = {\n",
    "    'bands': ['B8', 'B4', 'B3'],  # NIR, Red, Green\n",
    "    'min': 0.0,\n",
    "    'max': 0.4,\n",
    "    'gamma': 1.2\n",
    "}\n",
    "\n",
    "# Add false color composite to map\n",
    "Map.addLayer(s2_composite, false_color_vis, 'Sentinel-2 False Color (NIR-R-G)')\n",
    "\n",
    "print(\"‚úì False color composite added to map\")\n",
    "print(\"Red areas = healthy vegetation\")\n",
    "print(\"Green/brown areas = bare soil, urban\")\n",
    "print(\"Dark blue/black areas = water\")\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 1: Experiment with Different Composites\n",
    "\n",
    "Try creating and visualizing different composite types:\n",
    "\n",
    "1. **Mean composite** instead of median\n",
    "2. **25th percentile** composite (darkest pixels)\n",
    "3. **75th percentile** composite (brightest pixels)\n",
    "\n",
    "**Question:** How do these composites differ? Which is best for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a mean composite\n",
    "# s2_mean = s2_masked.mean().clip(palawan).select(bands)\n",
    "\n",
    "# TODO: Create 25th percentile composite\n",
    "# s2_p25 = s2_masked.reduce(ee.Reducer.percentile([25])).clip(palawan)\n",
    "\n",
    "# TODO: Visualize and compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D. Spectral Indices Calculation (15 minutes)\n",
    "\n",
    "üí° **Understanding Spectral Indices:**\n",
    "\n",
    "Spectral indices are mathematical combinations of spectral bands that enhance specific land cover features:\n",
    "\n",
    "- **NDVI** (Normalized Difference Vegetation Index): Measures vegetation health and density\n",
    "- **NDWI** (Normalized Difference Water Index): Highlights water bodies\n",
    "- **NDBI** (Normalized Difference Built-up Index): Identifies urban/built-up areas\n",
    "- **EVI** (Enhanced Vegetation Index): Improved sensitivity in high biomass regions\n",
    "\n",
    "These indices improve classification accuracy by providing discriminative features beyond raw spectral bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI: Normalized Difference Vegetation Index\n",
    "\n",
    "$$NDVI = \\frac{NIR - Red}{NIR + Red} = \\frac{B8 - B4}{B8 + B4}$$\n",
    "\n",
    "- **Range**: -1 to +1\n",
    "- **Interpretation**:\n",
    "  - > 0.6: Dense vegetation (forests)\n",
    "  - 0.2 to 0.6: Moderate vegetation (grasslands, agriculture)\n",
    "  - < 0.2: Bare soil, urban, water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI\n",
    "ndvi = s2_composite.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "\n",
    "# Visualization parameters\n",
    "ndvi_vis = {\n",
    "    'min': -0.2,\n",
    "    'max': 0.8,\n",
    "    'palette': ['blue', 'white', 'green', 'darkgreen']\n",
    "}\n",
    "\n",
    "Map.addLayer(ndvi, ndvi_vis, 'NDVI')\n",
    "\n",
    "print(\"‚úì NDVI calculated and visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDWI: Normalized Difference Water Index\n",
    "\n",
    "$$NDWI = \\frac{Green - NIR}{Green + NIR} = \\frac{B3 - B8}{B3 + B8}$$\n",
    "\n",
    "- **Range**: -1 to +1\n",
    "- **Interpretation**:\n",
    "  - > 0.3: Water bodies\n",
    "  - 0 to 0.3: Wetlands, moist soil\n",
    "  - < 0: Vegetation, dry soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDWI\n",
    "ndwi = s2_composite.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "\n",
    "# Visualization parameters\n",
    "ndwi_vis = {\n",
    "    'min': -0.5,\n",
    "    'max': 0.5,\n",
    "    'palette': ['brown', 'white', 'lightblue', 'darkblue']\n",
    "}\n",
    "\n",
    "Map.addLayer(ndwi, ndwi_vis, 'NDWI')\n",
    "\n",
    "print(\"‚úì NDWI calculated and visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDBI: Normalized Difference Built-up Index\n",
    "\n",
    "$$NDBI = \\frac{SWIR1 - NIR}{SWIR1 + NIR} = \\frac{B11 - B8}{B11 + B8}$$\n",
    "\n",
    "- **Range**: -1 to +1\n",
    "- **Interpretation**:\n",
    "  - > 0: Urban/built-up areas\n",
    "  - < 0: Vegetation, water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDBI\n",
    "ndbi = s2_composite.normalizedDifference(['B11', 'B8']).rename('NDBI')\n",
    "\n",
    "# Visualization parameters\n",
    "ndbi_vis = {\n",
    "    'min': -0.3,\n",
    "    'max': 0.3,\n",
    "    'palette': ['green', 'white', 'red', 'darkred']\n",
    "}\n",
    "\n",
    "Map.addLayer(ndbi, ndbi_vis, 'NDBI')\n",
    "\n",
    "print(\"‚úì NDBI calculated and visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVI: Enhanced Vegetation Index\n",
    "\n",
    "$$EVI = 2.5 \\times \\frac{NIR - Red}{NIR + 6 \\times Red - 7.5 \\times Blue + 1}$$\n",
    "\n",
    "$$EVI = 2.5 \\times \\frac{B8 - B4}{B8 + 6 \\times B4 - 7.5 \\times B2 + 1}$$\n",
    "\n",
    "- **Range**: -1 to +1 (typically 0 to 1 for vegetation)\n",
    "- **Advantages over NDVI**:\n",
    "  - More sensitive in high biomass regions (tropical forests)\n",
    "  - Corrects for atmospheric and soil background effects\n",
    "  - Less prone to saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EVI\n",
    "evi = s2_composite.expression(\n",
    "    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',\n",
    "    {\n",
    "        'NIR': s2_composite.select('B8'),\n",
    "        'RED': s2_composite.select('B4'),\n",
    "        'BLUE': s2_composite.select('B2')\n",
    "    }\n",
    ").rename('EVI')\n",
    "\n",
    "# Visualization parameters\n",
    "evi_vis = {\n",
    "    'min': -0.2,\n",
    "    'max': 0.8,\n",
    "    'palette': ['blue', 'white', 'lightgreen', 'darkgreen']\n",
    "}\n",
    "\n",
    "Map.addLayer(evi, evi_vis, 'EVI')\n",
    "\n",
    "print(\"‚úì EVI calculated and visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Side-by-Side Comparison\n",
    "\n",
    "Let's visualize all indices together to understand their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new map for side-by-side comparison\n",
    "Map_indices = geemap.Map(center=[10.5, 118.8], zoom=9, height='600px')\n",
    "\n",
    "# Add all indices\n",
    "Map_indices.addLayer(ndvi, ndvi_vis, 'NDVI')\n",
    "Map_indices.addLayer(ndwi, ndwi_vis, 'NDWI')\n",
    "Map_indices.addLayer(ndbi, ndbi_vis, 'NDBI')\n",
    "Map_indices.addLayer(evi, evi_vis, 'EVI')\n",
    "\n",
    "# Add layer control\n",
    "Map_indices.add_layer_control()\n",
    "\n",
    "print(\"‚úì All spectral indices visualized\")\n",
    "print(\"Use the layer control (top-right) to toggle indices on/off\")\n",
    "\n",
    "Map_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Interpretation Exercise\n",
    "\n",
    "**Questions to consider:**\n",
    "\n",
    "1. **Where do you see highest NDVI values?** (Hint: Forest areas in the mountains)\n",
    "2. **Where is NDWI positive?** (Hint: Rivers, lakes, coastal areas)\n",
    "3. **Where is NDBI highest?** (Hint: Puerto Princesa City, settlements)\n",
    "4. **How does EVI compare to NDVI in dense forest areas?**\n",
    "5. **Which index best discriminates between:**\n",
    "   - Forest vs. Agriculture?\n",
    "   - Water vs. Bare soil?\n",
    "   - Urban vs. Vegetation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 2: Calculate Additional Indices\n",
    "\n",
    "Try calculating these additional indices:\n",
    "\n",
    "1. **SAVI** (Soil-Adjusted Vegetation Index): \n",
    "   $$SAVI = \\frac{(NIR - Red) \\times (1 + L)}{(NIR + Red + L)}$$\n",
    "   where L = 0.5 (soil brightness correction factor)\n",
    "\n",
    "2. **GNDVI** (Green Normalized Difference Vegetation Index):\n",
    "   $$GNDVI = \\frac{NIR - Green}{NIR + Green}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate SAVI\n",
    "# L = 0.5\n",
    "# savi = ...\n",
    "\n",
    "# TODO: Calculate GNDVI\n",
    "# gndvi = ...\n",
    "\n",
    "# TODO: Visualize both indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## E. Feature Stack Preparation (10 minutes)\n",
    "\n",
    "üí° **Understanding Feature Engineering:**\n",
    "\n",
    "Machine learning models require a **feature stack** - a multi-band image where each band is an input feature. For land cover classification, our features include:\n",
    "\n",
    "1. **Spectral bands**: Raw reflectance values (B2, B3, B4, B8, B11, B12)\n",
    "2. **Spectral indices**: Derived features (NDVI, NDWI, NDBI, EVI)\n",
    "3. **Optional**: Texture metrics, topography (elevation, slope), temporal features\n",
    "\n",
    "More features ‚â† always better. We need features that:\n",
    "- Are **discriminative** (help separate classes)\n",
    "- Are **uncorrelated** (provide independent information)\n",
    "- Are **analysis-ready** (no missing values, consistent scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive feature stack\n",
    "# Combine spectral bands and spectral indices\n",
    "feature_stack = (s2_composite\n",
    "                 .addBands(ndvi)\n",
    "                 .addBands(ndwi)\n",
    "                 .addBands(ndbi)\n",
    "                 .addBands(evi))\n",
    "\n",
    "# List all feature names\n",
    "feature_names = feature_stack.bandNames().getInfo()\n",
    "\n",
    "print(\"‚úì Feature stack created\")\n",
    "print(f\"Total features: {len(feature_names)}\")\n",
    "print(f\"Feature list: {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify feature completeness (check for masked/missing values)\n",
    "# This is important to ensure all features are valid for classification\n",
    "\n",
    "# Get a sample point to check data availability\n",
    "sample_point = ee.Geometry.Point([118.8, 10.5])  # Central Palawan\n",
    "sample_values = feature_stack.reduceRegion(\n",
    "    reducer=ee.Reducer.first(),\n",
    "    geometry=sample_point,\n",
    "    scale=10\n",
    ").getInfo()\n",
    "\n",
    "print(\"Sample feature values at test point:\")\n",
    "for feature, value in sample_values.items():\n",
    "    print(f\"  {feature}: {value:.4f}\" if value is not None else f\"  {feature}: NULL\")\n",
    "\n",
    "# Check for any null features\n",
    "null_features = [f for f, v in sample_values.items() if v is None]\n",
    "if null_features:\n",
    "    print(f\"‚ö†Ô∏è Warning: Null values found in {null_features}\")\n",
    "else:\n",
    "    print(\"‚úì All features have valid values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F. Training Data Preparation (20 minutes)\n",
    "\n",
    "üí° **Understanding Training Data:**\n",
    "\n",
    "Training data is the **most critical component** of supervised classification. The quality of your training data directly determines classification accuracy.\n",
    "\n",
    "**Key principles:**\n",
    "1. **Representative**: Samples should cover the full spectral variability within each class\n",
    "2. **Pure**: Each polygon should contain only one land cover type\n",
    "3. **Well-distributed**: Samples should be spatially distributed across the study area\n",
    "4. **Sufficient**: At least 50-100 pixels per class (more for heterogeneous classes)\n",
    "5. **Balanced**: Similar numbers of samples for each class (avoid class imbalance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Land Cover Classes\n",
    "\n",
    "For Palawan, we'll classify 5 major land cover types relevant to NRM:\n",
    "\n",
    "| Class ID | Class Name | Description | Color |\n",
    "|----------|------------|-------------|-------|\n",
    "| 1 | Forest | Primary and secondary forests | Dark Green |\n",
    "| 2 | Agriculture | Rice paddies, croplands | Yellow |\n",
    "| 3 | Water | Rivers, lakes, coastal waters | Blue |\n",
    "| 4 | Urban | Built-up areas, settlements | Red |\n",
    "| 5 | Bare Soil | Mining areas, cleared land | Brown |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class properties\n",
    "class_info = {\n",
    "    1: {'name': 'Forest', 'color': '006400'},\n",
    "    2: {'name': 'Agriculture', 'color': 'FFFF00'},\n",
    "    3: {'name': 'Water', 'color': '0000FF'},\n",
    "    4: {'name': 'Urban', 'color': 'FF0000'},\n",
    "    5: {'name': 'Bare Soil', 'color': '8B4513'}\n",
    "}\n",
    "\n",
    "print(\"Land Cover Classification Scheme:\")\n",
    "for class_id, info in class_info.items():\n",
    "    print(f\"  {class_id}: {info['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training Samples\n",
    "\n",
    "We'll provide pre-defined training samples for Palawan. In operational workflows, you would:\n",
    "\n",
    "1. **Visual interpretation**: Use high-resolution imagery to identify pure pixels\n",
    "2. **Field data**: Ground truth from GPS surveys\n",
    "3. **Existing maps**: Digitize from authoritative land cover maps\n",
    "4. **Interactive drawing**: Use map tools to draw polygons\n",
    "\n",
    "‚ö†Ô∏è **Important**: Training data quality > quantity. 50 well-chosen samples beat 500 poor samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Pre-defined training samples (coordinates-based)\n",
    "# These are approximate locations - adjust based on visual interpretation\n",
    "\n",
    "# Forest samples (mountainous interior)\n",
    "forest_coords = [\n",
    "    [[118.5, 10.5], [118.5, 10.52], [118.52, 10.52], [118.52, 10.5]],\n",
    "    [[118.7, 10.8], [118.7, 10.82], [118.72, 10.82], [118.72, 10.8]],\n",
    "    [[119.0, 11.0], [119.0, 11.02], [119.02, 11.02], [119.02, 11.0]],\n",
    "    [[118.3, 9.8], [118.3, 9.82], [118.32, 9.82], [118.32, 9.8]],\n",
    "]\n",
    "\n",
    "# Agriculture samples (coastal plains)\n",
    "agriculture_coords = [\n",
    "    [[118.7, 9.75], [118.7, 9.77], [118.72, 9.77], [118.72, 9.75]],\n",
    "    [[118.9, 10.2], [118.9, 10.22], [118.92, 10.22], [118.92, 10.2]],\n",
    "    [[118.55, 10.0], [118.55, 10.02], [118.57, 10.02], [118.57, 10.0]],\n",
    "]\n",
    "\n",
    "# Water samples (bays, rivers)\n",
    "water_coords = [\n",
    "    [[118.73, 9.73], [118.73, 9.75], [118.75, 9.75], [118.75, 9.73]],  # Puerto Princesa Bay\n",
    "    [[119.3, 10.5], [119.3, 10.52], [119.32, 10.52], [119.32, 10.5]],  # Coastal water\n",
    "    [[118.4, 10.3], [118.4, 10.32], [118.42, 10.32], [118.42, 10.3]],\n",
    "]\n",
    "\n",
    "# Urban samples (Puerto Princesa, towns)\n",
    "urban_coords = [\n",
    "    [[118.74, 9.74], [118.74, 9.76], [118.76, 9.76], [118.76, 9.74]],  # Puerto Princesa City\n",
    "    [[119.08, 10.82], [119.08, 10.84], [119.10, 10.84], [119.10, 10.82]],  # Taytay\n",
    "]\n",
    "\n",
    "# Bare soil samples (mining, cleared)\n",
    "bare_coords = [\n",
    "    [[117.95, 9.4], [117.95, 9.42], [117.97, 9.42], [117.97, 9.4]],\n",
    "    [[118.2, 10.1], [118.2, 10.12], [118.22, 10.12], [118.22, 10.1]],\n",
    "]\n",
    "\n",
    "# Convert to ee.FeatureCollection\n",
    "def create_training_features(coords_list, class_value):\n",
    "    \"\"\"Convert coordinate list to ee.FeatureCollection with class label.\"\"\"\n",
    "    features = []\n",
    "    for coords in coords_list:\n",
    "        polygon = ee.Geometry.Polygon(coords)\n",
    "        feature = ee.Feature(polygon, {'landcover': class_value})\n",
    "        features.append(feature)\n",
    "    return ee.FeatureCollection(features)\n",
    "\n",
    "forest_fc = create_training_features(forest_coords, 1)\n",
    "agriculture_fc = create_training_features(agriculture_coords, 2)\n",
    "water_fc = create_training_features(water_coords, 3)\n",
    "urban_fc = create_training_features(urban_coords, 4)\n",
    "bare_fc = create_training_features(bare_coords, 5)\n",
    "\n",
    "# Merge all training samples\n",
    "training_polygons = (forest_fc\n",
    "                     .merge(agriculture_fc)\n",
    "                     .merge(water_fc)\n",
    "                     .merge(urban_fc)\n",
    "                     .merge(bare_fc))\n",
    "\n",
    "print(\"‚úì Training polygons created\")\n",
    "print(f\"Total training polygons: {training_polygons.size().getInfo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Training Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization map for training data\n",
    "Map_training = geemap.Map(center=[10.5, 118.8], zoom=8, height='600px')\n",
    "\n",
    "# Add base imagery\n",
    "Map_training.addLayer(s2_composite, rgb_vis, 'Sentinel-2 RGB')\n",
    "\n",
    "# Add training polygons by class (color-coded)\n",
    "for class_id, info in class_info.items():\n",
    "    class_polygons = training_polygons.filter(ee.Filter.eq('landcover', class_id))\n",
    "    Map_training.addLayer(\n",
    "        class_polygons,\n",
    "        {'color': info['color']},\n",
    "        f\"Training: {info['name']}\"\n",
    "    )\n",
    "\n",
    "print(\"‚úì Training polygons visualized\")\n",
    "print(\"Toggle layers to see training samples for each class\")\n",
    "\n",
    "Map_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Spectral Values from Training Areas\n",
    "\n",
    "üí° **Understanding Sampling:**\n",
    "\n",
    "We extract pixel values from our training polygons to create the training dataset. Each pixel becomes one training sample with:\n",
    "- **Features**: Spectral band values and indices\n",
    "- **Label**: Land cover class\n",
    "\n",
    "**Key parameters:**\n",
    "- **scale**: Pixel resolution (10m for Sentinel-2 highest resolution bands)\n",
    "- **geometries**: Whether to include geometry info (not needed for classification)\n",
    "- **tileScale**: Increases computation tile size to avoid memory errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data from feature stack\n",
    "training_samples = feature_stack.sampleRegions(\n",
    "    collection=training_polygons,\n",
    "    properties=['landcover'],\n",
    "    scale=10,  # 10m resolution\n",
    "    geometries=False,  # We don't need geometry info\n",
    "    tileScale=4  # Increase if memory errors occur\n",
    ")\n",
    "\n",
    "# Get sample count\n",
    "sample_count = training_samples.size().getInfo()\n",
    "print(f\"‚úì Training samples extracted\")\n",
    "print(f\"Total training pixels: {sample_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect sample distribution by class\n",
    "# This helps identify class imbalance\n",
    "\n",
    "class_counts = {}\n",
    "for class_id in range(1, 6):\n",
    "    class_samples = training_samples.filter(ee.Filter.eq('landcover', class_id))\n",
    "    count = class_samples.size().getInfo()\n",
    "    class_counts[class_id] = count\n",
    "\n",
    "print(\"\\nSample distribution by class:\")\n",
    "for class_id, count in class_counts.items():\n",
    "    class_name = class_info[class_id]['name']\n",
    "    print(f\"  {class_name}: {count} pixels\")\n",
    "\n",
    "# Check for severe imbalance\n",
    "max_count = max(class_counts.values())\n",
    "min_count = min(class_counts.values())\n",
    "imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "\n",
    "if imbalance_ratio > 3:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: Class imbalance detected (ratio: {imbalance_ratio:.1f}:1)\")\n",
    "    print(\"Consider adding more samples for underrepresented classes\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Class distribution is balanced (ratio: {imbalance_ratio:.1f}:1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Training Data\n",
    "\n",
    "Let's export a small sample to a DataFrame to inspect the spectral signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a small sample for exploration (limit to 100 samples for speed)\n",
    "sample_limit = training_samples.limit(100)\n",
    "sample_list = sample_limit.getInfo()['features']\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_data = [feature['properties'] for feature in sample_list]\n",
    "df_samples = pd.DataFrame(sample_data)\n",
    "\n",
    "print(\"Sample training data (first 10 rows):\")\n",
    "print(df_samples.head(10))\n",
    "\n",
    "print(\"\\nFeature statistics by class:\")\n",
    "print(df_samples.groupby('landcover')[['NDVI', 'NDWI', 'B4', 'B8']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 3: Add More Training Samples\n",
    "\n",
    "The provided training samples are minimal. To improve classification:\n",
    "\n",
    "1. **Visually inspect** the RGB composite and identify pure pixels for each class\n",
    "2. **Draw additional polygons** using the map drawing tools (or add coordinates)\n",
    "3. **Focus on underrepresented classes** (e.g., if Bare Soil has fewest samples)\n",
    "\n",
    "**Tip**: Use the false color composite (NIR-R-G) to better distinguish vegetation classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add more training samples\n",
    "# Option 1: Add coordinate-based polygons\n",
    "# additional_forest_coords = [\n",
    "#     [[lon1, lat1], [lon2, lat2], ...],\n",
    "# ]\n",
    "# additional_forest_fc = create_training_features(additional_forest_coords, 1)\n",
    "\n",
    "# Option 2: Interactive drawing (for local use, not Colab)\n",
    "# Use Map.draw_features to interactively draw training polygons\n",
    "\n",
    "# Merge with existing samples\n",
    "# training_polygons = training_polygons.merge(additional_forest_fc)\n",
    "\n",
    "# Re-sample\n",
    "# training_samples = feature_stack.sampleRegions(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## G. Random Forest Training (20 minutes)\n",
    "\n",
    "üí° **Understanding Random Forest:**\n",
    "\n",
    "Random Forest is an **ensemble learning** method that combines multiple decision trees:\n",
    "\n",
    "**How it works:**\n",
    "1. Create multiple decision trees (e.g., 100 trees)\n",
    "2. Each tree is trained on a random subset of data (**bagging**)\n",
    "3. Each tree considers a random subset of features at each split\n",
    "4. Final prediction = majority vote across all trees\n",
    "\n",
    "**Advantages:**\n",
    "- Handles non-linear relationships\n",
    "- Resistant to overfitting (with enough trees)\n",
    "- Provides feature importance (explainability)\n",
    "- No assumption about data distribution\n",
    "- Works well with high-dimensional data\n",
    "\n",
    "**Key hyperparameters:**\n",
    "- **numberOfTrees**: More trees = more stable, but slower (typical: 50-200)\n",
    "- **variablesPerSplit**: Features considered at each split (default: sqrt(n) is optimal)\n",
    "- **minLeafPopulation**: Minimum samples per leaf node (default: 1)\n",
    "- **bagFraction**: Fraction of data used per tree (default: 0.632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Random Forest classifier\n",
    "rf_classifier = ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,         # Number of decision trees\n",
    "    variablesPerSplit=None,    # Auto: sqrt(number of features)\n",
    "    minLeafPopulation=1,       # Minimum samples per leaf\n",
    "    bagFraction=0.632,         # Out-of-bag fraction (default)\n",
    "    seed=42                    # For reproducibility\n",
    ")\n",
    "\n",
    "print(\"‚úì Random Forest classifier configured\")\n",
    "print(\"Configuration:\")\n",
    "print(f\"  - Number of trees: 100\")\n",
    "print(f\"  - Variables per split: auto (sqrt of {len(feature_names)} features)\")\n",
    "print(f\"  - Min leaf population: 1\")\n",
    "print(f\"  - Random seed: 42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "print(\"Training Random Forest classifier...\")\n",
    "print(\"This may take 1-2 minutes...\")\n",
    "\n",
    "trained_classifier = rf_classifier.train(\n",
    "    features=training_samples,\n",
    "    classProperty='landcover',\n",
    "    inputProperties=feature_names\n",
    ")\n",
    "\n",
    "print(\"‚úì Random Forest training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis\n",
    "\n",
    "üí° **Understanding Feature Importance:**\n",
    "\n",
    "Random Forest can tell us which features contribute most to classification decisions. This provides:\n",
    "\n",
    "1. **Model explainability**: Understand what the model \"sees\"\n",
    "2. **Feature selection**: Identify redundant features\n",
    "3. **Domain insights**: Validate that important features align with physical understanding\n",
    "\n",
    "**Importance metric**: How much each feature improves classification accuracy across all trees.\n",
    "\n",
    "Higher importance = more discriminative feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "importance = trained_classifier.explain().get('importance')\n",
    "\n",
    "# Note: GEE's explain() may not always return importance for smileRandomForest\n",
    "# We'll create a visualization regardless\n",
    "\n",
    "try:\n",
    "    importance_dict = importance.getInfo()\n",
    "    \n",
    "    # Create DataFrame for visualization\n",
    "    df_importance = pd.DataFrame({\n",
    "        'Feature': list(importance_dict.keys()),\n",
    "        'Importance': list(importance_dict.values())\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(df_importance['Feature'], df_importance['Importance'])\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.title('Random Forest Feature Importance', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 5 most important features:\")\n",
    "    print(df_importance.head(5).to_string(index=False))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Feature importance not available from GEE smileRandomForest\")\n",
    "    print(\"This is a known limitation of the SMILE RF implementation\")\n",
    "    print(\"\\nExpected important features (based on EO literature):\")\n",
    "    print(\"  1. NIR band (B8) - vegetation discrimination\")\n",
    "    print(\"  2. NDVI - vegetation index\")\n",
    "    print(\"  3. SWIR bands (B11, B12) - moisture, urban\")\n",
    "    print(\"  4. Red band (B4) - vegetation contrast\")\n",
    "    print(\"  5. NDWI - water detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Interpretation: Feature Importance\n",
    "\n",
    "**Expected patterns:**\n",
    "\n",
    "- **NIR (B8)** and **NDVI**: Should be highly important (vegetation vs. non-vegetation)\n",
    "- **SWIR (B11, B12)**: Important for discriminating soil moisture, urban areas\n",
    "- **NDWI**: Important for water bodies\n",
    "- **Red (B4)**: Important for vegetation health\n",
    "- **Blue (B2)**: Often less important (atmospheric scatter, lower contrast)\n",
    "\n",
    "**Questions:**\n",
    "1. Do the most important features align with physical understanding?\n",
    "2. Are spectral indices more important than raw bands?\n",
    "3. Which features could potentially be removed without losing accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 4: Train with Different Parameters\n",
    "\n",
    "Experiment with different Random Forest configurations:\n",
    "\n",
    "1. **Fewer trees** (50): Faster but potentially less stable\n",
    "2. **More trees** (200): More stable but slower\n",
    "3. **Different variablesPerSplit**: Try 2, 3, or 4 (instead of auto)\n",
    "\n",
    "**Question**: How does the number of trees affect training time? Does accuracy improve significantly beyond 100 trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train RF with 50 trees\n",
    "# rf_50 = ee.Classifier.smileRandomForest(numberOfTrees=50, seed=42)\n",
    "# trained_rf_50 = rf_50.train(...)\n",
    "\n",
    "# TODO: Train RF with 200 trees\n",
    "# rf_200 = ee.Classifier.smileRandomForest(numberOfTrees=200, seed=42)\n",
    "# trained_rf_200 = rf_200.train(...)\n",
    "\n",
    "# TODO: Compare results (we'll evaluate accuracy in next section)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## H. Image Classification (15 minutes)\n",
    "\n",
    "Now we'll apply the trained classifier to the entire Palawan image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply classifier to feature stack\n",
    "print(\"Classifying image...\")\n",
    "print(\"This may take 1-2 minutes...\")\n",
    "\n",
    "classified_image = feature_stack.classify(trained_classifier)\n",
    "\n",
    "print(\"‚úì Classification complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color palette for visualization\n",
    "# Colors match class_info defined earlier\n",
    "class_palette = [class_info[i]['color'] for i in sorted(class_info.keys())]\n",
    "\n",
    "print(f\"Classification palette: {class_palette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize classification result\n",
    "Map_classified = geemap.Map(center=[10.5, 118.8], zoom=8, height='700px')\n",
    "\n",
    "# Add base imagery for comparison\n",
    "Map_classified.addLayer(s2_composite, rgb_vis, 'Sentinel-2 RGB', False)\n",
    "Map_classified.addLayer(s2_composite, false_color_vis, 'False Color', False)\n",
    "\n",
    "# Add classification\n",
    "Map_classified.addLayer(\n",
    "    classified_image,\n",
    "    {'min': 1, 'max': 5, 'palette': class_palette},\n",
    "    'Land Cover Classification'\n",
    ")\n",
    "\n",
    "# Add training polygons for reference\n",
    "for class_id, info in class_info.items():\n",
    "    class_polygons = training_polygons.filter(ee.Filter.eq('landcover', class_id))\n",
    "    Map_classified.addLayer(\n",
    "        class_polygons,\n",
    "        {'color': info['color']},\n",
    "        f\"Training: {info['name']}\",\n",
    "        False  # Hidden by default\n",
    "    )\n",
    "\n",
    "# Add layer control\n",
    "Map_classified.add_layer_control()\n",
    "\n",
    "print(\"‚úì Classification visualized\")\n",
    "print(\"\\nLegend:\")\n",
    "for class_id, info in class_info.items():\n",
    "    print(f\"  {info['name']}: #{info['color']}\")\n",
    "\n",
    "Map_classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Visual Interpretation\n",
    "\n",
    "**Areas to examine:**\n",
    "\n",
    "1. **Forest coverage**: \n",
    "   - Toggle between RGB and classification\n",
    "   - Are mountainous interior areas classified as forest?\n",
    "   - Are mangrove forests along coasts detected?\n",
    "\n",
    "2. **Agriculture**:\n",
    "   - Check coastal plains and river valleys\n",
    "   - Are rice paddies correctly identified?\n",
    "\n",
    "3. **Water bodies**:\n",
    "   - Rivers, lakes, bays\n",
    "   - Any confusion with shadows or dark vegetation?\n",
    "\n",
    "4. **Urban areas**:\n",
    "   - Puerto Princesa City (main urban center)\n",
    "   - Small towns along roads\n",
    "\n",
    "5. **Potential misclassifications**:\n",
    "   - Cloud shadows misclassified as water?\n",
    "   - Bare soil confused with urban?\n",
    "   - Sparse vegetation confused with agriculture?\n",
    "\n",
    "**Tip**: Zoom to specific locations and toggle layers to compare classification with imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 5: Identify Misclassifications\n",
    "\n",
    "Explore the map and identify at least 3 areas where classification appears incorrect:\n",
    "\n",
    "1. **Describe the misclassification**: What was classified? What should it be?\n",
    "2. **Hypothesize why**: Spectral confusion? Poor training samples? Class definition?\n",
    "3. **Propose solution**: Add training data? Refine class definitions? Add features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your observations:**\n",
    "\n",
    "1. Misclassification 1:\n",
    "   - Location: [latitude, longitude]\n",
    "   - Classified as: [class]\n",
    "   - Should be: [class]\n",
    "   - Why: ...\n",
    "   - Solution: ...\n",
    "\n",
    "2. Misclassification 2:\n",
    "   - ...\n",
    "\n",
    "3. Misclassification 3:\n",
    "   - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## I. Accuracy Assessment (25 minutes)\n",
    "\n",
    "üí° **Understanding Accuracy Assessment:**\n",
    "\n",
    "Visual inspection is subjective. We need **quantitative metrics** to evaluate classification performance:\n",
    "\n",
    "**Confusion Matrix**: Cross-tabulation of predicted vs. actual classes\n",
    "- Rows = reference (true) class\n",
    "- Columns = predicted class\n",
    "- Diagonal = correct classifications\n",
    "- Off-diagonal = misclassifications\n",
    "\n",
    "**Key Metrics**:\n",
    "1. **Overall Accuracy**: (Correct predictions) / (Total predictions)\n",
    "2. **Producer's Accuracy**: (Correctly classified samples of class X) / (Total reference samples of class X)\n",
    "   - Measures omission error (missed detections)\n",
    "3. **User's Accuracy**: (Correctly classified samples of class X) / (Total predictions of class X)\n",
    "   - Measures commission error (false alarms)\n",
    "4. **Kappa Coefficient**: Agreement beyond random chance (0 = random, 1 = perfect)\n",
    "\n",
    "**Best Practice**: Use **independent validation data** (not used in training). We'll simulate this by splitting our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validation Split\n",
    "\n",
    "We'll split our samples into:\n",
    "- **Training set (80%)**: Used to train the model\n",
    "- **Validation set (20%)**: Used to assess accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random column for splitting\n",
    "training_samples = training_samples.randomColumn('random', seed=42)\n",
    "\n",
    "# Split: 80% training, 20% validation\n",
    "split = 0.8\n",
    "training_set = training_samples.filter(ee.Filter.lt('random', split))\n",
    "validation_set = training_samples.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "# Get counts\n",
    "train_count = training_set.size().getInfo()\n",
    "val_count = validation_set.size().getInfo()\n",
    "\n",
    "print(\"Data split:\")\n",
    "print(f\"  Training samples: {train_count} ({train_count/(train_count+val_count)*100:.1f}%)\")\n",
    "print(f\"  Validation samples: {val_count} ({val_count/(train_count+val_count)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain classifier on training set only\n",
    "print(\"Retraining classifier on training set...\")\n",
    "\n",
    "rf_final = ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=None,\n",
    "    minLeafPopulation=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trained_final = rf_final.train(\n",
    "    features=training_set,\n",
    "    classProperty='landcover',\n",
    "    inputProperties=feature_names\n",
    ")\n",
    "\n",
    "print(\"‚úì Retraining complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify validation set\n",
    "validation_classified = validation_set.classify(trained_final)\n",
    "\n",
    "print(\"‚úì Validation set classified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "confusion_matrix = validation_classified.errorMatrix('landcover', 'classification')\n",
    "\n",
    "# Get matrix as array\n",
    "matrix_array = confusion_matrix.array().getInfo()\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"Rows = Reference (True), Columns = Predicted\")\n",
    "print(matrix_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix as heatmap\n",
    "class_names = [class_info[i]['name'] for i in sorted(class_info.keys())]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    matrix_array,\n",
    "    annot=True,\n",
    "    fmt='g',\n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.xlabel('Predicted Class', fontsize=12)\n",
    "plt.ylabel('Reference Class', fontsize=12)\n",
    "plt.title('Confusion Matrix - Palawan Land Cover Classification', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall accuracy\n",
    "overall_accuracy = confusion_matrix.accuracy().getInfo()\n",
    "print(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate Kappa coefficient\n",
    "kappa = confusion_matrix.kappa().getInfo()\n",
    "print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "# Interpret Kappa\n",
    "if kappa > 0.8:\n",
    "    kappa_interp = \"Excellent agreement\"\n",
    "elif kappa > 0.6:\n",
    "    kappa_interp = \"Substantial agreement\"\n",
    "elif kappa > 0.4:\n",
    "    kappa_interp = \"Moderate agreement\"\n",
    "else:\n",
    "    kappa_interp = \"Poor agreement\"\n",
    "\n",
    "print(f\"Interpretation: {kappa_interp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Producer's Accuracy (per class)\n",
    "producers_accuracy = confusion_matrix.producersAccuracy().getInfo()\n",
    "\n",
    "print(\"\\nProducer's Accuracy (Sensitivity, Recall):\")\n",
    "print(\"Measures: How many reference samples were correctly classified?\")\n",
    "for i, acc in enumerate(producers_accuracy):\n",
    "    class_name = class_info[i+1]['name']\n",
    "    print(f\"  {class_name}: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate User's Accuracy (per class)\n",
    "users_accuracy = confusion_matrix.consumersAccuracy().getInfo()\n",
    "\n",
    "print(\"\\nUser's Accuracy (Precision):\")\n",
    "print(\"Measures: How many predicted samples are actually correct?\")\n",
    "for i, acc in enumerate(users_accuracy):\n",
    "    class_name = class_info[i+1]['name']\n",
    "    print(f\"  {class_name}: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "df_accuracy = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Producer\\'s Accuracy (%)': [acc*100 for acc in producers_accuracy],\n",
    "    'User\\'s Accuracy (%)': [acc*100 for acc in users_accuracy]\n",
    "})\n",
    "\n",
    "print(\"\\nAccuracy Summary by Class:\")\n",
    "print(df_accuracy.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize per-class accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, df_accuracy['Producer\\'s Accuracy (%)'], width, label='Producer\\'s Accuracy', alpha=0.8)\n",
    "ax.bar(x + width/2, df_accuracy['User\\'s Accuracy (%)'], width, label='User\\'s Accuracy', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Land Cover Class', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Per-Class Accuracy Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 105])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Analyzing Classification Errors\n",
    "\n",
    "**Questions to consider:**\n",
    "\n",
    "1. **Which classes are most accurately classified?**\n",
    "   - Typically: Water (distinct spectral signature)\n",
    "   - Look for classes with >90% accuracy\n",
    "\n",
    "2. **Which classes are confused with each other?**\n",
    "   - Look at off-diagonal elements in confusion matrix\n",
    "   - Common confusions:\n",
    "     - Agriculture ‚Üî Bare Soil (if crop fields are bare)\n",
    "     - Forest ‚Üî Agriculture (if crops have high biomass)\n",
    "     - Urban ‚Üî Bare Soil (similar spectral response)\n",
    "\n",
    "3. **Is there class imbalance affecting results?**\n",
    "   - Classes with fewer samples often have lower accuracy\n",
    "\n",
    "4. **How can we improve?**\n",
    "   - Add more training samples for poorly classified classes\n",
    "   - Refine class definitions (subdivide confusable classes)\n",
    "   - Add discriminative features (texture, elevation, temporal)\n",
    "   - Use multi-temporal data (phenology helps separate agriculture from forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 6: Try Different Train/Test Splits\n",
    "\n",
    "Experiment with different split ratios:\n",
    "\n",
    "1. **70-30 split**: More validation data\n",
    "2. **90-10 split**: More training data\n",
    "\n",
    "**Question**: How does the split ratio affect accuracy? Is there a trade-off?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Experiment with different splits\n",
    "# split_70 = 0.7\n",
    "# training_set_70 = training_samples.filter(ee.Filter.lt('random', split_70))\n",
    "# validation_set_70 = training_samples.filter(ee.Filter.gte('random', split_70))\n",
    "\n",
    "# Retrain and evaluate\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## J. Area Statistics (10 minutes)\n",
    "\n",
    "Let's calculate the area covered by each land cover class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pixel count for each class\n",
    "# Reclassify to get area (each pixel = 100 m¬≤)\n",
    "\n",
    "pixel_area = ee.Image.pixelArea()  # Returns area in square meters\n",
    "\n",
    "# Calculate area per class\n",
    "area_image = pixel_area.addBands(classified_image)\n",
    "\n",
    "# Reduce by class\n",
    "area_stats = area_image.reduceRegion(\n",
    "    reducer=ee.Reducer.sum().group(\n",
    "        groupField=1,\n",
    "        groupName='landcover'\n",
    "    ),\n",
    "    geometry=palawan,\n",
    "    scale=10,  # 10m resolution\n",
    "    maxPixels=1e10,\n",
    "    tileScale=4\n",
    ")\n",
    "\n",
    "print(\"Calculating area statistics...\")\n",
    "print(\"This may take 2-3 minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract area results\n",
    "area_results = area_stats.getInfo()\n",
    "area_groups = area_results['groups']\n",
    "\n",
    "# Convert to DataFrame\n",
    "area_data = []\n",
    "for group in area_groups:\n",
    "    class_id = group['landcover']\n",
    "    area_m2 = group['sum']\n",
    "    area_km2 = area_m2 / 1e6\n",
    "    area_ha = area_m2 / 1e4\n",
    "    \n",
    "    area_data.append({\n",
    "        'Class ID': class_id,\n",
    "        'Class Name': class_info[class_id]['name'],\n",
    "        'Area (km¬≤)': area_km2,\n",
    "        'Area (ha)': area_ha\n",
    "    })\n",
    "\n",
    "df_area = pd.DataFrame(area_data).sort_values('Area (km¬≤)', ascending=False)\n",
    "\n",
    "# Calculate percentages\n",
    "total_area = df_area['Area (km¬≤)'].sum()\n",
    "df_area['Percentage (%)'] = (df_area['Area (km¬≤)'] / total_area) * 100\n",
    "\n",
    "print(\"\\nLand Cover Area Statistics:\")\n",
    "print(df_area.to_string(index=False))\n",
    "print(f\"\\nTotal classified area: {total_area:,.0f} km¬≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize area distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Bar chart\n",
    "colors = [f\"#{class_info[row['Class ID']]['color']}\" for _, row in df_area.iterrows()]\n",
    "ax1.bar(df_area['Class Name'], df_area['Area (km¬≤)'], color=colors, alpha=0.7)\n",
    "ax1.set_xlabel('Land Cover Class', fontsize=12)\n",
    "ax1.set_ylabel('Area (km¬≤)', fontsize=12)\n",
    "ax1.set_title('Land Cover Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(\n",
    "    df_area['Percentage (%)'],\n",
    "    labels=df_area['Class Name'],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    startangle=90\n",
    ")\n",
    "ax2.set_title('Land Cover Percentage', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Interpreting Area Statistics\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. **What is the dominant land cover?**\n",
    "   - Expected: Forest (Palawan is ~50-60% forested)\n",
    "\n",
    "2. **How much agricultural land?**\n",
    "   - Agriculture is mainly in coastal plains and river valleys\n",
    "\n",
    "3. **Do results align with official statistics?**\n",
    "   - Compare with DENR/PhilSA land cover maps\n",
    "   - Note: Differences expected due to classification scheme, date, methods\n",
    "\n",
    "4. **What about urban area?**\n",
    "   - Urban should be small (Palawan is relatively undeveloped)\n",
    "   - Main urban center: Puerto Princesa City\n",
    "\n",
    "**Conservation context:**\n",
    "- Forest cover is critical for biodiversity conservation\n",
    "- Monitoring deforestation trends requires multi-temporal analysis\n",
    "- This single-date classification provides a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## K. Export Results (10 minutes)\n",
    "\n",
    "üí° **Understanding GEE Exports:**\n",
    "\n",
    "Google Earth Engine processing happens on Google's servers. To get results locally, we export to:\n",
    "- **Google Drive**: Rasters (GeoTIFF), vectors (Shapefile, GeoJSON), tables (CSV)\n",
    "- **Cloud Storage**: For large files or automated workflows\n",
    "- **Asset**: For reuse in GEE\n",
    "\n",
    "**Important**: Exports are **asynchronous tasks**. They don't block notebook execution but run in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Classified Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export classification to Google Drive\nexport_classification = ee.batch.Export.image.toDrive(\n    image=classified_image,\n    description='Palawan_LandCover_Classification',\n    folder='EarthEngine',\n    fileNamePrefix='palawan_landcover_2025',\n    region=palawan.geometry(),\n    scale=10,  # 10m resolution\n    crs='EPSG:4326',\n    maxPixels=1e10,\n    fileFormat='GeoTIFF'\n)\n\n# Start the export task\nexport_classification.start()\n\nprint(\"‚úì Classification export task started\")\nprint(f\"Task description: {export_classification.status()['description']}\")\nprint(f\"Task state: {export_classification.status()['state']}\")\nprint(\"\\nCheck Google Drive > EarthEngine folder for the file\")\nprint(\"Note: Export may take 5-15 minutes depending on area size\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export training samples to Google Drive (CSV)\n",
    "export_training = ee.batch.Export.table.toDrive(\n",
    "    collection=training_samples,\n",
    "    description='Palawan_Training_Samples',\n",
    "    folder='EarthEngine',\n",
    "    fileNamePrefix='palawan_training_samples',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "export_training.start()\n",
    "\n",
    "print(\"‚úì Training samples export task started\")\n",
    "print(f\"Task state: {export_training.status()['state']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrix locally (as CSV)\n",
    "df_confusion = pd.DataFrame(\n",
    "    matrix_array,\n",
    "    index=class_names,\n",
    "    columns=class_names\n",
    ")\n",
    "\n",
    "# Save to local file (will be available in Colab session)\n",
    "df_confusion.to_csv('palawan_confusion_matrix.csv')\n",
    "\n",
    "print(\"‚úì Confusion matrix saved locally\")\n",
    "print(\"File: palawan_confusion_matrix.csv\")\n",
    "print(\"\\nDownload from Files panel (left sidebar)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Area Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save area statistics locally (as CSV)\n",
    "df_area.to_csv('palawan_area_statistics.csv', index=False)\n",
    "\n",
    "print(\"‚úì Area statistics saved locally\")\n",
    "print(\"File: palawan_area_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Export Task Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of export tasks\n",
    "import time\n",
    "\n",
    "print(\"Export task status:\")\n",
    "print(f\"  Classification: {export_classification.status()['state']}\")\n",
    "print(f\"  Training samples: {export_training.status()['state']}\")\n",
    "\n",
    "print(\"\\nPossible states:\")\n",
    "print(\"  READY: Task is queued\")\n",
    "print(\"  RUNNING: Task is processing\")\n",
    "print(\"  COMPLETED: Task finished successfully\")\n",
    "print(\"  FAILED: Task encountered an error\")\n",
    "print(\"  CANCELLED: Task was cancelled\")\n",
    "\n",
    "print(\"\\nTo check status later, visit:\")\n",
    "print(\"https://code.earthengine.google.com/tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Common Export Issues:**\n",
    "\n",
    "1. **\"User memory limit exceeded\"**: Reduce scale (e.g., 30m instead of 10m) or reduce region size\n",
    "2. **\"Computation timed out\"**: Add `tileScale` parameter (e.g., `tileScale=4`)\n",
    "3. **\"Too many concurrent operations\"**: GEE limits concurrent tasks (wait for others to complete)\n",
    "4. **File not in Drive**: Check \"EarthEngine\" folder; exports may take 5-30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## L. Advanced Exercises (Optional, 15 minutes)\n",
    "\n",
    "For participants who finish early, here are advanced challenges:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 7: Add More Spectral Indices\n",
    "\n",
    "Calculate and add these additional indices to the feature stack:\n",
    "\n",
    "1. **SAVI** (Soil-Adjusted Vegetation Index): Reduces soil background effects\n",
    "2. **GNDVI** (Green NDVI): Sensitive to chlorophyll concentration\n",
    "3. **NBR** (Normalized Burn Ratio): Useful for detecting burned areas\n",
    "\n",
    "$$SAVI = \\frac{(NIR - Red) \\times (1 + L)}{(NIR + Red + L)}$$ where L = 0.5\n",
    "\n",
    "$$GNDVI = \\frac{NIR - Green}{NIR + Green}$$\n",
    "\n",
    "$$NBR = \\frac{NIR - SWIR2}{NIR + SWIR2}$$\n",
    "\n",
    "**Question**: Do these additional indices improve classification accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate SAVI, GNDVI, NBR\n",
    "# savi = ...\n",
    "# gndvi = ...\n",
    "# nbr = ...\n",
    "\n",
    "# TODO: Add to feature stack\n",
    "# feature_stack_extended = feature_stack.addBands([savi, gndvi, nbr])\n",
    "\n",
    "# TODO: Retrain classifier and compare accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 8: Multi-temporal Analysis\n",
    "\n",
    "Land cover has temporal patterns (phenology):\n",
    "- **Forests**: Relatively stable NDVI year-round\n",
    "- **Agriculture**: Seasonal NDVI variations (planting, growing, harvest)\n",
    "- **Water**: Stable, low NDVI\n",
    "\n",
    "Create composites for dry season (Jan-Apr) and wet season (Jun-Sep), then classify.\n",
    "\n",
    "**Question**: Does multi-temporal data improve discrimination between forest and agriculture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TODO: Create dry season composite\n# dry_season = s2_masked.filterDate('2025-01-01', '2025-04-30').median()\n\n# TODO: Create wet season composite\n# wet_season = s2_masked.filterDate('2025-06-01', '2025-09-30').median()\n\n# TODO: Calculate NDVI for each season\n# ndvi_dry = dry_season.normalizedDifference(['B8', 'B4']).rename('NDVI_dry')\n# ndvi_wet = wet_season.normalizedDifference(['B8', 'B4']).rename('NDVI_wet')\n\n# TODO: Create multi-temporal feature stack\n# feature_stack_temporal = dry_season.select(bands).addBands(wet_season.select(bands)).addBands([ndvi_dry, ndvi_wet])\n\n# TODO: Train and evaluate\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 9: Add Topographic Features\n",
    "\n",
    "Elevation and slope can improve classification:\n",
    "- **Forests**: Often in mountainous areas\n",
    "- **Agriculture**: Mainly in lowlands and valleys\n",
    "- **Water**: Low elevation, flat\n",
    "\n",
    "Add SRTM elevation and derived slope to features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load SRTM elevation data\n",
    "# srtm = ee.Image('USGS/SRTMGL1_003')\n",
    "# elevation = srtm.select('elevation').clip(palawan)\n",
    "\n",
    "# TODO: Calculate slope\n",
    "# slope = ee.Terrain.slope(elevation)\n",
    "\n",
    "# TODO: Add to feature stack\n",
    "# feature_stack_topo = feature_stack.addBands([elevation, slope])\n",
    "\n",
    "# TODO: Train and evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 10: Classify a Different Region\n",
    "\n",
    "Apply the same workflow to a different Philippine region:\n",
    "- **Metro Manila**: Urban-focused classification\n",
    "- **Ifugao (Rice Terraces)**: Agricultural focus\n",
    "- **Mindanao**: Different ecological zone\n",
    "\n",
    "**Question**: Are the same features important? Does the model generalize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define new study area\n",
    "# new_region = ...\n",
    "\n",
    "# TODO: Load Sentinel-2 data\n",
    "# ...\n",
    "\n",
    "# TODO: Create training samples\n",
    "# ...\n",
    "\n",
    "# TODO: Train and evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 11: Compare with CART (Single Decision Tree)\n",
    "\n",
    "Random Forest is an ensemble of trees. How does a single tree compare?\n",
    "\n",
    "Train a CART (Classification and Regression Tree) classifier and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train CART classifier\n",
    "# cart_classifier = ee.Classifier.smileCart()\n",
    "# trained_cart = cart_classifier.train(\n",
    "#     features=training_set,\n",
    "#     classProperty='landcover',\n",
    "#     inputProperties=feature_names\n",
    "# )\n",
    "\n",
    "# TODO: Classify and evaluate\n",
    "# ...\n",
    "\n",
    "# TODO: Compare confusion matrices and accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Reflection\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "In this hands-on lab, you:\n",
    "\n",
    "1. ‚úì **Set up Google Earth Engine** and authenticated successfully\n",
    "2. ‚úì **Acquired Sentinel-2 data** for Palawan, Philippines\n",
    "3. ‚úì **Preprocessed imagery** using cloud masking and compositing\n",
    "4. ‚úì **Calculated spectral indices** (NDVI, NDWI, NDBI, EVI)\n",
    "5. ‚úì **Created training datasets** with 5 land cover classes\n",
    "6. ‚úì **Trained a Random Forest classifier** with 100 trees\n",
    "7. ‚úì **Performed land cover classification** on the entire study area\n",
    "8. ‚úì **Assessed accuracy** using confusion matrices and statistical metrics\n",
    "9. ‚úì **Generated area statistics** for each land cover class\n",
    "10. ‚úì **Exported results** to Google Drive for further analysis\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "**Technical:**\n",
    "- Google Earth Engine enables cloud-based analysis of petabytes of satellite data\n",
    "- Random Forest is a powerful, interpretable algorithm for land cover classification\n",
    "- Feature engineering (spectral indices) improves discrimination\n",
    "- Training data quality is critical - garbage in, garbage out\n",
    "- Accuracy assessment requires independent validation data\n",
    "\n",
    "**Application to Philippine NRM:**\n",
    "- Land cover classification supports conservation planning (e.g., Palawan SEP)\n",
    "- Regular monitoring enables detection of deforestation, land conversion\n",
    "- Integration with PhilSA, NAMRIA, DENR datasets enhances operational value\n",
    "- Scalable workflows can be applied to other Philippine regions\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**To improve this classification:**\n",
    "1. **Collect more training data**: Field surveys with GPS, visual interpretation\n",
    "2. **Refine class definitions**: Separate primary/secondary forest, mangroves\n",
    "3. **Add temporal features**: Multi-season composites capture phenology\n",
    "4. **Incorporate ancillary data**: Elevation, slope, distance to roads/water\n",
    "5. **Post-processing**: Spatial filtering to remove isolated pixels\n",
    "\n",
    "**For operational deployment:**\n",
    "1. **Automate workflow**: Schedule regular updates (monthly, quarterly)\n",
    "2. **Change detection**: Compare classifications over time\n",
    "3. **Integrate with decision systems**: Feed results to monitoring dashboards\n",
    "4. **Validate with ground truth**: Coordinate with local agencies\n",
    "\n",
    "### Reflection Questions\n",
    "\n",
    "1. What surprised you about the classification results?\n",
    "2. Which land cover classes were easiest/hardest to classify? Why?\n",
    "3. How would you explain the classification to a non-technical stakeholder?\n",
    "4. What additional data would improve the classification?\n",
    "5. How could this workflow support your organization's mission?\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "**Google Earth Engine:**\n",
    "- [GEE Documentation](https://developers.google.com/earth-engine)\n",
    "- [GEE Code Editor](https://code.earthengine.google.com/)\n",
    "- [geemap Documentation](https://geemap.org/)\n",
    "\n",
    "**Sentinel-2:**\n",
    "- [Sentinel-2 User Handbook](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi)\n",
    "- [Copernicus Open Access Hub](https://scihub.copernicus.eu/)\n",
    "\n",
    "**Machine Learning for EO:**\n",
    "- Gislason et al. (2006): \"Random Forests for land cover classification\" - *Remote Sensing of Environment*\n",
    "- Maxwell et al. (2018): \"Implementation of machine-learning classification in remote sensing\" - *International Journal of Remote Sensing*\n",
    "\n",
    "**Philippine EO:**\n",
    "- [PhilSA Space+ Data Dashboard](https://data.philsa.gov.ph/)\n",
    "- [NAMRIA Geoportal](https://www.geoportal.gov.ph/)\n",
    "- [DOST-ASTI DATOS](https://datos.asti.dost.gov.ph/)\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "**Issue: \"Earth Engine authentication failed\"**\n",
    "- Solution: Run `ee.Authenticate()` and follow the prompts\n",
    "- Clear browser cache if persistent\n",
    "\n",
    "**Issue: \"Computation timed out\"**\n",
    "- Solution: Add `tileScale=4` to `sampleRegions()` or `reduceRegion()`\n",
    "- Reduce spatial resolution (e.g., `scale=30` instead of `scale=10`)\n",
    "\n",
    "**Issue: \"User memory limit exceeded\"**\n",
    "- Solution: Reduce study area size or increase `tileScale`\n",
    "- Export large computations instead of `.getInfo()`\n",
    "\n",
    "**Issue: \"No images in collection\"**\n",
    "- Solution: Relax cloud cover filter (e.g., `<30%` instead of `<20%`)\n",
    "- Expand date range\n",
    "\n",
    "**Issue: \"Classification has many misclassifications\"**\n",
    "- Solution: Add more training samples\n",
    "- Check that training polygons are pure (single land cover)\n",
    "- Add discriminative features\n",
    "\n",
    "**Issue: \"Export task failed\"**\n",
    "- Solution: Check task status at https://code.earthengine.google.com/tasks\n",
    "- Reduce export region or resolution\n",
    "- Check Google Drive storage quota\n",
    "\n",
    "---\n",
    "\n",
    "**End of Hands-on Lab**\n",
    "\n",
    "Thank you for participating in this session! Your feedback is valuable - please share any suggestions for improving this lab.\n",
    "\n",
    "**Contact**: [Training organizer email]\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}