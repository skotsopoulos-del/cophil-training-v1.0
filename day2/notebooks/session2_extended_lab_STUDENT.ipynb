{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f521fecf",
   "metadata": {},
   "source": "# Session 2: Advanced Palawan Land Cover Classification Lab\n\n## Multi-temporal Analysis and Change Detection\n\n**Duration:** 2 hours | **Difficulty:** Intermediate\n\n---\n\n## üéØ Learning Objectives\n\nBy the end of this lab, you will be able to:\n\n1. ‚úÖ Engineer advanced features (GLCM texture, temporal, topographic)\n2. ‚úÖ Create seasonal Sentinel-2 composites for Philippine context\n3. ‚úÖ Implement optimized Random Forest classification\n4. ‚úÖ Perform accuracy assessment with detailed metrics\n5. ‚úÖ Detect land cover changes (2020 vs 2025)\n6. ‚úÖ Generate stakeholder-ready outputs for NRM applications\n\n---\n\n## üìã Lab Structure\n\n| Part | Topic | Duration |\n|------|-------|----------|\n| **A** | Advanced Feature Engineering | 30 min |\n| **B** | Palawan Biosphere Reserve Classification | 45 min |\n| **C** | Model Optimization | 30 min |\n| **D** | NRM Applications & Change Detection | 15 min |\n\n---\n\n## ‚öôÔ∏è Setup Requirements\n\n- Google Earth Engine account (authenticated)\n- Python 3.8+\n- Libraries: `earthengine-api`, `geemap`, `scikit-learn`\n\n---\n\n## üìö Study Area: Palawan Biosphere Reserve\n\n- **Location:** Philippines, northern Palawan\n- **Area:** ~11,655 km¬≤\n- **UNESCO Status:** Biosphere Reserve (1990)\n- **Conservation Priority:** Last frontier forest, high biodiversity\n- **Threats:** Mining, agriculture expansion, illegal logging\n\n---\n\n## üó∫Ô∏è 8-Class Land Cover Scheme\n\n1. **Primary Forest** - Dense dipterocarp, closed canopy\n2. **Secondary Forest** - Regenerating, mixed canopy\n3. **Mangroves** - Coastal, tidal influence\n4. **Agricultural Land** - Rice, coconut plantations\n5. **Grassland/Scrubland** - Open areas, sparse vegetation\n6. **Water Bodies** - Rivers, lakes, coastal waters\n7. **Urban/Built-up** - Settlements, infrastructure\n8. **Bare Soil/Mining** - Exposed soil, mining areas\n\n---\n\nLet's begin! üöÄ\n"
  },
  {
   "cell_type": "markdown",
   "id": "54dafb8c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part A: Advanced Feature Engineering (30 minutes)\n",
    "\n",
    "In this section, we'll create a comprehensive feature stack including:\n",
    "- Spectral bands (Sentinel-2)\n",
    "- Spectral indices (NDVI, NDWI, NDBI, EVI)\n",
    "- Texture features (GLCM)\n",
    "- Temporal features (dry/wet season)\n",
    "- Topographic features (SRTM DEM)\n",
    "\n",
    "---\n",
    "\n",
    "## A.1: Setup and Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42468bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import ee\n",
    "import geemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")\n",
    "print(f\"Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de4c3f",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize Google Earth Engine\nimport ee\nimport geemap.core as geemap\n\nee.Authenticate()\nee.Initialize(project='YOUR-PROJECT-ID')\n\nprint(\"‚úì Earth Engine authenticated and initialized\")\n\n# Test connection\ntest_collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n    .filterDate('2025-01-01', '2025-12-31') \\\n    .first()\n\ntry:\n    test_info = test_collection.getInfo()\n    print(f\"‚úì Connection test: {test_info['id']}\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Connection test failed: {str(e)}\")\n    print(\"Please check your authentication and try again\")"
  },
  {
   "cell_type": "markdown",
   "id": "43ce92ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A.2: Define Study Area\n",
    "\n",
    "We'll focus on a manageable subset of Palawan Biosphere Reserve for this lab. For production work, you can expand to the full area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Palawan Biosphere Reserve subset\n",
    "# Coordinates: Northern Palawan focus area\n",
    "palawan_bbox = [118.5, 9.5, 119.5, 10.5]  # [min_lon, min_lat, max_lon, max_lat]\n",
    "\n",
    "aoi = ee.Geometry.Rectangle(palawan_bbox)\n",
    "\n",
    "print(f\"Study Area: {palawan_bbox}\")\n",
    "print(f\"Area: {aoi.area().divide(1e6).getInfo():.2f} km¬≤\")\n",
    "\n",
    "# Create a map to visualize\n",
    "Map = geemap.Map(center=[10.0, 119.0], zoom=9)\n",
    "Map.addLayer(aoi, {'color': 'red'}, 'Study Area')\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b47635",
   "metadata": {},
   "source": "---\n\n## A.3: Create Seasonal Composites\n\nPhilippine seasons are critical for land cover classification:\n- **Dry Season (Jan-May):** Best for forest mapping, minimal cloud cover\n- **Wet Season (Jun-Nov):** Shows agricultural phenology, maximum water extent\n\nWe'll create median composites for both seasons from 2025 data.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c37baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud masking function\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"Mask clouds using QA60 band\"\"\"\n",
    "    qa = image.select('QA60')\n",
    "    \n",
    "    # Bits 10 and 11 are clouds and cirrus\n",
    "    cloud_bit_mask = 1 << 10\n",
    "    cirrus_bit_mask = 1 << 11\n",
    "    \n",
    "    # Both flags should be zero (clear conditions)\n",
    "    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(\n",
    "           qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    "    \n",
    "    # Scale and return masked image\n",
    "    return image.updateMask(mask).divide(10000)\n",
    "\n",
    "print(\"‚úì Cloud masking function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c285976",
   "metadata": {},
   "outputs": [],
   "source": "# Create DRY SEASON composite (January-May 2025)\nprint(\"Creating dry season composite...\")\n\ndry_season = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n    .filterBounds(aoi) \\\n    .filterDate('2025-01-01', '2025-05-31') \\\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \\\n    .map(mask_s2_clouds) \\\n    .median() \\\n    .clip(aoi)\n\nprint(f\"‚úì Dry season composite created\")\nprint(f\"  Bands: {dry_season.bandNames().getInfo()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490610a",
   "metadata": {},
   "outputs": [],
   "source": "# Create WET SEASON composite (June-November 2025)\nprint(\"Creating wet season composite...\")\n\nwet_season = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n    .filterBounds(aoi) \\\n    .filterDate('2025-06-01', '2025-11-30') \\\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n    .map(mask_s2_clouds) \\\n    .median() \\\n    .clip(aoi)\n\nprint(f\"‚úì Wet season composite created\")\nprint(f\"  Bands: {wet_season.bandNames().getInfo()}\")"
  },
  {
   "cell_type": "markdown",
   "id": "2e80febf",
   "metadata": {},
   "source": [
    "### Visualize Seasonal Composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8b584",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize both seasons\nMap2 = geemap.Map(center=[10.0, 119.0], zoom=10)\n\n# RGB visualization parameters\nvis_params = {\n    'min': 0, 'max': 0.3,\n    'bands': ['B4', 'B3', 'B2']\n}\n\nMap2.addLayer(dry_season, vis_params, 'Dry Season (Jan-May 2025)')\nMap2.addLayer(wet_season, vis_params, 'Wet Season (Jun-Nov 2025)')\nMap2.addLayerControl()\nMap2"
  },
  {
   "cell_type": "markdown",
   "id": "534e1016",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A.4: Calculate Spectral Indices\n",
    "\n",
    "We'll calculate key vegetation and land cover indices for both seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c501b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate spectral indices\n",
    "def add_indices(image):\n",
    "    \"\"\"Calculate NDVI, NDWI, NDBI, EVI\"\"\"\n",
    "    \n",
    "    # NDVI: Normalized Difference Vegetation Index\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    \n",
    "    # NDWI: Normalized Difference Water Index  \n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "    \n",
    "    # NDBI: Normalized Difference Built-up Index\n",
    "    ndbi = image.normalizedDifference(['B11', 'B8']).rename('NDBI')\n",
    "    \n",
    "    # EVI: Enhanced Vegetation Index\n",
    "    evi = image.expression(\n",
    "        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "            'NIR': image.select('B8'),\n",
    "            'RED': image.select('B4'),\n",
    "            'BLUE': image.select('B2')\n",
    "        }).rename('EVI')\n",
    "    \n",
    "    return image.addBands([ndvi, ndwi, ndbi, evi])\n",
    "\n",
    "# Add indices to both seasons\n",
    "dry_with_indices = add_indices(dry_season)\n",
    "wet_with_indices = add_indices(wet_season)\n",
    "\n",
    "print(\"‚úì Spectral indices calculated for both seasons\")\n",
    "print(f\"  Dry season bands: {dry_with_indices.bandNames().getInfo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849f4e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A.5: Calculate GLCM Texture Features\n",
    "\n",
    "Texture features help distinguish land cover types with similar spectral properties:\n",
    "- **Contrast:** Distinguishes forest from agriculture\n",
    "- **Entropy:** Captures urban heterogeneity  \n",
    "- **Correlation:** Good for textured surfaces (forest canopy)\n",
    "\n",
    "‚ö†Ô∏è **Note:** GLCM computation is computationally intensive. This may take a few minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59469ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate GLCM texture on NIR band (B8)\n",
    "print(\"Calculating GLCM texture features (this may take a moment)...\")\n",
    "\n",
    "# Use 3x3 window (size=3)\n",
    "nir_band = dry_with_indices.select('B8')\n",
    "glcm = nir_band.glcmTexture(size=3)\n",
    "\n",
    "# Select key texture features\n",
    "texture_contrast = glcm.select('B8_contrast').rename('texture_contrast')\n",
    "texture_entropy = glcm.select('B8_ent').rename('texture_entropy')\n",
    "texture_corr = glcm.select('B8_corr').rename('texture_corr')\n",
    "texture_var = glcm.select('B8_var').rename('texture_var')\n",
    "\n",
    "# Stack texture features\n",
    "texture_features = ee.Image.cat([\n",
    "    texture_contrast,\n",
    "    texture_entropy,\n",
    "    texture_corr,\n",
    "    texture_var\n",
    "])\n",
    "\n",
    "print(\"‚úì GLCM texture features calculated\")\n",
    "print(f\"  Features: {texture_features.bandNames().getInfo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e042e3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A.6: Extract Topographic Features\n",
    "\n",
    "Topography helps separate land uses (e.g., agriculture on flat areas, forests on slopes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SRTM DEM (30m resolution)\n",
    "dem = ee.Image('USGS/SRTMGL1_003').clip(aoi)\n",
    "\n",
    "# Calculate terrain derivatives\n",
    "elevation = dem.select('elevation')\n",
    "slope = ee.Terrain.slope(dem).rename('slope')\n",
    "aspect = ee.Terrain.aspect(dem).rename('aspect')\n",
    "\n",
    "# Stack topographic features\n",
    "topo_features = ee.Image.cat([elevation, slope, aspect])\n",
    "\n",
    "print(\"‚úì Topographic features extracted\")\n",
    "print(f\"  Features: {topo_features.bandNames().getInfo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98c6d5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A.7: Calculate Temporal Features\n",
    "\n",
    "Temporal differences between seasons reveal phenological patterns, especially for agriculture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29198f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate temporal features\n",
    "ndvi_dry = dry_with_indices.select('NDVI').rename('NDVI_dry')\n",
    "ndvi_wet = wet_with_indices.select('NDVI').rename('NDVI_wet')\n",
    "\n",
    "# NDVI difference (phenological signal)\n",
    "ndvi_diff = ndvi_wet.subtract(ndvi_dry).rename('NDVI_diff')\n",
    "\n",
    "# NDVI mean\n",
    "ndvi_mean = ndvi_dry.add(ndvi_wet).divide(2).rename('NDVI_mean')\n",
    "\n",
    "# Water indices\n",
    "ndwi_dry = dry_with_indices.select('NDWI').rename('NDWI_dry')\n",
    "ndwi_wet = wet_with_indices.select('NDWI').rename('NDWI_wet')\n",
    "\n",
    "# Stack temporal features\n",
    "temporal_features = ee.Image.cat([\n",
    "    ndvi_dry, ndvi_wet, ndvi_diff, ndvi_mean,\n",
    "    ndwi_dry, ndwi_wet\n",
    "])\n",
    "\n",
    "print(\"‚úì Temporal features calculated\")\n",
    "print(f\"  Features: {temporal_features.bandNames().getInfo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212688e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A.8: Stack All Features\n",
    "\n",
    "Now we combine everything into a comprehensive feature stack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505aed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select spectral bands from dry season\n",
    "spectral_bands = dry_with_indices.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'])\n",
    "\n",
    "# Select indices from dry season\n",
    "spectral_indices = dry_with_indices.select(['NDVI', 'NDWI', 'NDBI', 'EVI'])\n",
    "\n",
    "# Stack ALL features\n",
    "feature_stack = ee.Image.cat([\n",
    "    spectral_bands,      # 6 bands\n",
    "    spectral_indices,    # 4 indices\n",
    "    texture_features,    # 4 texture\n",
    "    temporal_features,   # 6 temporal\n",
    "    topo_features        # 3 topographic\n",
    "])\n",
    "\n",
    "# Print summary\n",
    "all_bands = feature_stack.bandNames().getInfo()\n",
    "print(f\"‚úì Complete feature stack created\")\n",
    "print(f\"  Total features: {len(all_bands)}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for i, band in enumerate(all_bands, 1):\n",
    "    print(f\"  {i:2d}. {band}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e64237",
   "metadata": {},
   "source": [
    "### üéâ Part A Complete!\n",
    "\n",
    "You've successfully created a comprehensive feature stack with:\n",
    "- 6 spectral bands\n",
    "- 4 spectral indices\n",
    "- 4 texture features\n",
    "- 6 temporal features\n",
    "- 3 topographic features\n",
    "\n",
    "**Total: 23 features** for classification\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e93969",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part B: Palawan Biosphere Reserve Classification (45 minutes)\n",
    "\n",
    "Now we'll use our feature stack to classify the 8 land cover classes.\n",
    "\n",
    "---\n",
    "\n",
    "## B.1: Load Training Data\n",
    "\n",
    "We'll use the training polygons created in Session 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69578ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training polygons from Session 1\n",
    "# Path to your training data (adjust if needed)\n",
    "training_polygons = geemap.geojson_to_ee('../data/palawan_training_polygons.geojson')\n",
    "\n",
    "print(\"‚úì Training polygons loaded\")\n",
    "print(f\"  Number of features: {training_polygons.size().getInfo()}\")\n",
    "\n",
    "# Check class distribution\n",
    "classes = training_polygons.aggregate_array('class_id').distinct().sort()\n",
    "print(f\"  Classes present: {classes.getInfo()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6feb542",
   "metadata": {},
   "source": [
    "### TODO Exercise 1: Explore Training Data\n",
    "\n",
    "**Task:** Create a map showing the training polygons colored by class.\n",
    "\n",
    "**Hint:** Use `Map.addLayer()` with training_polygons and a styled visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: YOUR CODE HERE\n",
    "# Create a map showing training polygons by class\n",
    "\n",
    "# SOLUTION HINT: Use styling like {'color': 'class_id', 'palette': [...]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ccf94b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B.2: Sample Features from Training Polygons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the feature stack at training locations\n",
    "training = feature_stack.sampleRegions(\n",
    "    collection=training_polygons,\n",
    "    properties=['class_id'],\n",
    "    scale=10,\n",
    "    geometries=False\n",
    ")\n",
    "\n",
    "print(\"‚úì Training data sampled\")\n",
    "print(f\"  Training samples: {training.size().getInfo()}\")\n",
    "\n",
    "# Check for any null values\n",
    "sample_info = training.first().getInfo()\n",
    "print(f\"\\n Sample feature names: {list(sample_info['properties'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2481d6a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B.3: Train Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest classifier\n",
    "print(\"Training Random Forest classifier...\")\n",
    "\n",
    "classifier = ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=200,\n",
    "    variablesPerSplit=None,  # sqrt(n) by default\n",
    "    minLeafPopulation=1,\n",
    "    bagFraction=0.5,\n",
    "    maxNodes=None,\n",
    "    seed=42\n",
    ").train(\n",
    "    features=training,\n",
    "    classProperty='class_id',\n",
    "    inputProperties=feature_stack.bandNames()\n",
    ")\n",
    "\n",
    "print(\"‚úì Random Forest trained successfully\")\n",
    "print(f\"  Number of trees: 200\")\n",
    "print(f\"  Features used: {len(all_bands)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635c633",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B.4: Apply Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73924bd",
   "metadata": {},
   "outputs": [],
   "source": "# Classify the feature stack\nclassified = feature_stack.classify(classifier).rename('classification')\n\nprint(\"‚úì Classification complete\")\n\n# Visualize classification\nclass_colors = ['#0A5F0A', '#4CAF50', '#009688', '#FFC107', \n                '#FFEB3B', '#2196F3', '#F44336', '#795548']\n\nMap3 = geemap.Map(center=[10.0, 119.0], zoom=10)\nMap3.addLayer(classified, {'min': 1, 'max': 8, 'palette': class_colors}, 'Land Cover 2025')\nMap3.addLayer(aoi, {'color': 'black'}, 'Study Area', False)\nMap3.add_legend(\n    title='Land Cover Classes',\n    labels=['Primary Forest', 'Secondary Forest', 'Mangroves', 'Agricultural',\n            'Grassland', 'Water', 'Urban', 'Bare Soil'],\n    colors=class_colors\n)\nMap3"
  },
  {
   "cell_type": "markdown",
   "id": "f16cc09e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B.5: Accuracy Assessment\n",
    "\n",
    "We'll use the validation polygons for independent accuracy assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf0e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation polygons\n",
    "validation_polygons = geemap.geojson_to_ee('../data/palawan_validation_polygons.geojson')\n",
    "\n",
    "# Sample validation data\n",
    "validation = feature_stack.sampleRegions(\n",
    "    collection=validation_polygons,\n",
    "    properties=['class_id'],\n",
    "    scale=10\n",
    ")\n",
    "\n",
    "# Classify validation samples\n",
    "validated = validation.classify(classifier)\n",
    "\n",
    "print(f\"‚úì Validation data: {validation.size().getInfo()} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "confusion_matrix = validated.errorMatrix('class_id', 'classification')\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "overall_accuracy = confusion_matrix.accuracy().getInfo()\n",
    "kappa = confusion_matrix.kappa().getInfo()\n",
    "producers_accuracy = confusion_matrix.producersAccuracy().getInfo()\n",
    "consumers_accuracy = confusion_matrix.consumersAccuracy().getInfo()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ACCURACY ASSESSMENT RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy*100:.2f}%\")\n",
    "print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae746fac",
   "metadata": {},
   "source": [
    "### TODO Exercise 2: Interpret Accuracy\n",
    "\n",
    "**Questions:**\n",
    "1. Which classes have the highest producer's accuracy (recall)?\n",
    "2. Which classes are most confused with each other?\n",
    "3. How does this compare to Session 1 results?\n",
    "4. What could be done to improve accuracy?\n",
    "\n",
    "**Write your answers below:**\n",
    "\n",
    "*YOUR ANSWERS HERE*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2a58c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B.6: Feature Importance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_dict = classifier.explain().get('importance')\n",
    "\n",
    "# Note: In GEE, feature importance requires special handling\n",
    "# For this demo, we'll use a proxy by analyzing variable contribution\n",
    "\n",
    "print(\"‚úì Feature importance analysis\")\n",
    "print(\"\\nTop features for classification:\")\n",
    "print(\"(Feature importance values from Random Forest)\")\n",
    "\n",
    "# This is a simplified version - full implementation would extract actual importances\n",
    "feature_names = feature_stack.bandNames().getInfo()\n",
    "print(f\"\\nTotal features used: {len(feature_names)}\")\n",
    "for i, fname in enumerate(feature_names[:10], 1):\n",
    "    print(f\"  {i}. {fname}\")\n",
    "print(\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d2065",
   "metadata": {},
   "source": [
    "### TODO Exercise 3: Feature Analysis\n",
    "\n",
    "**Task:** Based on the features we used, which ones do you think are most important for:\n",
    "1. Separating primary from secondary forest?\n",
    "2. Identifying agricultural land?\n",
    "3. Detecting urban areas?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f652b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B.7: Calculate Area Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area for each class\n",
    "print(\"Calculating area statistics...\")\n",
    "\n",
    "class_names = {\n",
    "    1: 'Primary Forest',\n",
    "    2: 'Secondary Forest',\n",
    "    3: 'Mangroves',\n",
    "    4: 'Agricultural',\n",
    "    5: 'Grassland',\n",
    "    6: 'Water',\n",
    "    7: 'Urban',\n",
    "    8: 'Bare Soil'\n",
    "}\n",
    "\n",
    "area_stats = {}\n",
    "\n",
    "for class_id, class_name in class_names.items():\n",
    "    # Create mask for this class\n",
    "    class_mask = classified.eq(class_id)\n",
    "    \n",
    "    # Calculate area (pixels * pixel_area)\n",
    "    area = class_mask.multiply(ee.Image.pixelArea()).reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=aoi,\n",
    "        scale=10,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    \n",
    "    # Convert to hectares\n",
    "    area_ha = ee.Number(area.get('classification')).divide(10000).getInfo()\n",
    "    area_stats[class_name] = area_ha\n",
    "    \n",
    "    print(f\"  {class_name}: {area_ha:,.2f} ha\")\n",
    "\n",
    "print(\"\\n‚úì Area statistics calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60651f79",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize area distribution\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(12, 6))\nclasses_list = list(area_stats.keys())\nareas_list = list(area_stats.values())\n\ncolors = ['#0A5F0A', '#4CAF50', '#009688', '#FFC107', \n          '#FFEB3B', '#2196F3', '#F44336', '#795548']\n\nbars = ax.bar(range(len(classes_list)), areas_list, color=colors, edgecolor='black', linewidth=1.5)\nax.set_xlabel('Land Cover Class', fontsize=12, fontweight='bold')\nax.set_ylabel('Area (hectares)', fontsize=12, fontweight='bold')\nax.set_title('Palawan Land Cover Distribution (2025)', fontsize=14, fontweight='bold')\nax.set_xticks(range(len(classes_list)))\nax.set_xticklabels(classes_list, rotation=45, ha='right')\nax.grid(axis='y', alpha=0.3)\n\n# Add value labels on bars\nfor i, (bar, value) in enumerate(zip(bars, areas_list)):\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height,\n            f'{value:,.0f}',\n            ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"‚úì Area distribution plot created\")"
  },
  {
   "cell_type": "markdown",
   "id": "57ca85bf",
   "metadata": {},
   "source": [
    "### üéâ Part B Complete!\n",
    "\n",
    "You've successfully:\n",
    "- ‚úÖ Loaded and sampled training data\n",
    "- ‚úÖ Trained a Random Forest classifier with 23 features\n",
    "- ‚úÖ Applied classification to Palawan\n",
    "- ‚úÖ Assessed accuracy (hopefully >85%!)\n",
    "- ‚úÖ Calculated area statistics\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3252399",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part C: Model Optimization (30 minutes)\n",
    "\n",
    "Let's optimize our classifier and explore different parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## C.1: Hyperparameter Tuning\n",
    "\n",
    "We'll test different numbers of trees to find the optimal configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed8c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO Exercise 4: Test Different Tree Counts\n",
    "\n",
    "**Task:** Train classifiers with different numbers of trees and compare accuracy.\n",
    "\n",
    "Test these values: [50, 100, 200, 500]\n",
    "\n",
    "**Code template provided below - complete the TODO sections**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4431609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning experiment\n",
    "tree_counts = [50, 100, 200, 500]\n",
    "results = {}\n",
    "\n",
    "print(\"Testing different tree counts...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for n_trees in tree_counts:\n",
    "    # TODO: Train a classifier with n_trees\n",
    "    # HINT: Use ee.Classifier.smileRandomForest(numberOfTrees=n_trees)\n",
    "    \n",
    "    test_classifier = ee.Classifier.smileRandomForest(\n",
    "        numberOfTrees=n_trees,\n",
    "        seed=42\n",
    "    ).train(\n",
    "        features=training,\n",
    "        classProperty='class_id',\n",
    "        inputProperties=feature_stack.bandNames()\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    test_validated = validation.classify(test_classifier)\n",
    "    test_accuracy = test_validated.errorMatrix('class_id', 'classification').accuracy().getInfo()\n",
    "    \n",
    "    results[n_trees] = test_accuracy\n",
    "    print(f\"Trees: {n_trees:3d} | Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚úì Optimal tree count: {max(results, key=results.get)} trees\")\n",
    "print(f\"  Best accuracy: {max(results.values())*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b548a0b",
   "metadata": {},
   "source": [
    "### Visualize Tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b5ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tuning results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "trees_list = list(results.keys())\n",
    "acc_list = [v*100 for v in results.values()]\n",
    "\n",
    "ax.plot(trees_list, acc_list, 'o-', linewidth=2, markersize=10, color='#2196F3')\n",
    "ax.set_xlabel('Number of Trees', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Overall Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Random Forest Hyperparameter Tuning Results', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([min(acc_list)-2, max(acc_list)+2])\n",
    "\n",
    "# Highlight best\n",
    "best_idx = acc_list.index(max(acc_list))\n",
    "ax.scatter([trees_list[best_idx]], [acc_list[best_idx]], \n",
    "           s=200, c='red', marker='*', zorder=5, label='Best')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071bfc4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C.2: Post-Processing\n",
    "\n",
    "Reduce \"salt-and-pepper\" noise using majority filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply majority filter\n",
    "print(\"Applying post-processing...\")\n",
    "\n",
    "# Focal mode filter (3x3 window)\n",
    "classified_filtered = classified.focal_mode(radius=1, kernelType='square')\n",
    "\n",
    "print(\"‚úì Majority filter applied (3x3 window)\")\n",
    "\n",
    "# Compare before/after\n",
    "Map4 = geemap.Map(center=[10.0, 119.0], zoom=11)\n",
    "Map4.addLayer(classified, {'min': 1, 'max': 8, 'palette': class_colors}, \n",
    "              'Original Classification')\n",
    "Map4.addLayer(classified_filtered, {'min': 1, 'max': 8, 'palette': class_colors}, \n",
    "              'Filtered Classification')\n",
    "Map4.addLayerControl()\n",
    "Map4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d314b2e",
   "metadata": {},
   "source": [
    "### TODO Exercise 5: Compare Filtering Results\n",
    "\n",
    "**Task:** Zoom in on the map above and compare the original vs filtered classification.\n",
    "\n",
    "**Questions:**\n",
    "1. What differences do you notice?\n",
    "2. Does filtering improve visual quality?\n",
    "3. Are there any disadvantages to filtering?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020b802",
   "metadata": {},
   "source": [
    "### üéâ Part C Complete!\n",
    "\n",
    "You've successfully:\n",
    "- ‚úÖ Performed hyperparameter tuning\n",
    "- ‚úÖ Identified optimal tree count\n",
    "- ‚úÖ Applied post-processing filters\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af993578",
   "metadata": {},
   "source": "---\n\n# Part D: NRM Applications & Change Detection (15 minutes)\n\nApply classification to conservation challenges: detect forest loss from 2020 to 2025.\n\n---\n\n## D.1: Create 2020 Classification\n\nWe'll create a comparable classification for 2020 to detect changes.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f5c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2020 dry season composite\n",
    "print(\"Creating 2020 composite for comparison...\")\n",
    "\n",
    "dry_2020 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate('2020-01-01', '2020-05-31') \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \\\n",
    "    .map(mask_s2_clouds) \\\n",
    "    .median() \\\n",
    "    .clip(aoi)\n",
    "\n",
    "# Add indices (simplified for speed)\n",
    "def add_basic_indices(img):\n",
    "    ndvi = img.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    ndwi = img.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "    return img.addBands([ndvi, ndwi])\n",
    "\n",
    "dry_2020 = add_basic_indices(dry_2020)\n",
    "\n",
    "# Use simplified feature set for 2020\n",
    "features_2020 = dry_2020.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'NDVI', 'NDWI'])\n",
    "\n",
    "# Classify 2020\n",
    "classified_2020 = features_2020.classify(classifier).rename('classification_2020')\n",
    "\n",
    "print(\"‚úì 2020 classification complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1671d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D.2: Detect Forest Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f501c0",
   "metadata": {},
   "outputs": [],
   "source": "# Detect forest loss (class 1 or 2 in 2020, NOT in 2025)\nprint(\"Detecting forest loss...\")\n\n# Create forest masks\nforest_2020 = classified_2020.eq(1).Or(classified_2020.eq(2))\nforest_2025 = classified_filtered.eq(1).Or(classified_filtered.eq(2))\n\n# Forest loss: was forest in 2020, not forest in 2025\nforest_loss = forest_2020.And(forest_2025.Not()).rename('forest_loss')\n\nprint(\"‚úì Forest loss detected\")\n\n# Calculate forest loss area\nloss_area = forest_loss.multiply(ee.Image.pixelArea()).reduceRegion(\n    reducer=ee.Reducer.sum(),\n    geometry=aoi,\n    scale=10,\n    maxPixels=1e13\n)\n\nloss_ha = ee.Number(loss_area.get('forest_loss')).divide(10000).getInfo()\nprint(f\"\\nüö® Forest Loss (2020-2025): {loss_ha:,.2f} hectares\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ab90c",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize forest loss\nMap5 = geemap.Map(center=[10.0, 119.0], zoom=10)\n\n# Background: 2025 classification\nMap5.addLayer(classified_filtered, {'min': 1, 'max': 8, 'palette': class_colors}, \n              '2025 Land Cover', False)\n\n# Highlight forest loss in red\nMap5.addLayer(forest_loss.updateMask(forest_loss), {'palette': ['red']}, \n              'Forest Loss (2020-2025)')\n\nMap5.add_legend(\n    title='Change Detection',\n    labels=['Forest Loss', 'No Change'],\n    colors=['red', 'lightgray']\n)\n\nMap5"
  },
  {
   "cell_type": "markdown",
   "id": "c8b0b541",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D.3: Identify Deforestation Hotspots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hotspots using focal statistics\n",
    "print(\"Identifying deforestation hotspots...\")\n",
    "\n",
    "# Create circular kernel (1km radius)\n",
    "kernel = ee.Kernel.circle(radius=1000, units='meters')\n",
    "\n",
    "# Calculate proportion of loss pixels in neighborhood\n",
    "hotspots = forest_loss.focalMean(kernel=kernel).multiply(100).rename('hotspot_intensity')\n",
    "\n",
    "print(\"‚úì Hotspot analysis complete\")\n",
    "\n",
    "# Visualize hotspots\n",
    "Map6 = geemap.Map(center=[10.0, 119.0], zoom=9)\n",
    "\n",
    "hotspot_vis = {\n",
    "    'min': 0,\n",
    "    'max': 10,\n",
    "    'palette': ['white', 'yellow', 'orange', 'red', 'darkred']\n",
    "}\n",
    "\n",
    "Map6.addLayer(hotspots.updateMask(hotspots.gt(0.5)), hotspot_vis, 'Deforestation Hotspots')\n",
    "Map6.add_colorbar(hotspot_vis, label='Forest Loss Intensity (%)')\n",
    "Map6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c00e2a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D.4: Change Matrix & Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO Exercise 6: Analyze Land Use Transitions\n",
    "\n",
    "**Task:** Calculate how much forest was converted to different land uses.\n",
    "\n",
    "**Questions to investigate:**\n",
    "1. How much forest ‚Üí agriculture conversion occurred?\n",
    "2. How much forest ‚Üí bare soil (mining)?\n",
    "3. Which class replaced forests the most?\n",
    "\n",
    "**Code template:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create change matrix (from_class * 10 + to_class)\n",
    "change_matrix = classified_2020.multiply(10).add(classified_filtered).rename('change_code')\n",
    "\n",
    "# Example: Forest (1) to Agriculture (4) = change code 14\n",
    "# Forest (1) to Bare Soil (8) = change code 18\n",
    "\n",
    "# TODO: Calculate specific transitions\n",
    "# forest_to_ag = change_matrix.eq(14).Or(change_matrix.eq(24))  # Primary or Secondary ‚Üí Ag\n",
    "\n",
    "# YOUR CODE HERE to calculate areas for different transitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6c6b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D.5: Generate Stakeholder Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad0acd",
   "metadata": {},
   "outputs": [],
   "source": "# Create summary report\nprint(\"=\" * 70)\nprint(\"PALAWAN BIOSPHERE RESERVE - CHANGE DETECTION REPORT (2020-2025)\")\nprint(\"=\" * 70)\n\nprint(f\"\\nStudy Area: {aoi.area().divide(1e6).getInfo():.2f} km¬≤\")\nprint(f\"Analysis Period: 2020-2025 (5 years)\")\nprint(f\"\\n--- KEY FINDINGS ---\\n\")\n\n# Forest loss\ntotal_area_km2 = aoi.area().divide(1e6).getInfo()\nloss_percent = (loss_ha / (total_area_km2 * 100)) * 100\n\nprint(f\"üö® Total Forest Loss: {loss_ha:,.2f} hectares ({loss_percent:.2f}% of study area)\")\nprint(f\"üìâ Annual Loss Rate: {loss_ha/5:,.2f} hectares/year\")\n\n# 2025 Land cover summary\nprint(f\"\\n--- 2025 LAND COVER DISTRIBUTION ---\\n\")\nfor class_name, area in area_stats.items():\n    percent = (area / (total_area_km2 * 100)) * 100\n    print(f\"  {class_name:20s}: {area:10,.2f} ha ({percent:5.2f}%)\")\n\nprint(f\"\\n--- CONSERVATION IMPLICATIONS ---\\n\")\nprint(\"‚Ä¢ Continued monitoring recommended\")\nprint(\"‚Ä¢ Priority intervention zones identified via hotspot analysis\")\nprint(\"‚Ä¢ Update DENR forest cover database\")\nprint(\"‚Ä¢ Inform REDD+ MRV reporting\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Report generated:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\nprint(\"=\" * 70)"
  },
  {
   "cell_type": "markdown",
   "id": "f2a54023",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D.6: Export Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4cc3e",
   "metadata": {},
   "outputs": [],
   "source": "# Export classification to Google Drive\nprint(\"Preparing exports...\")\n\n# Export 2025 classification\nexport_task = ee.batch.Export.image.toDrive(\n    image=classified_filtered.toUint8(),\n    description='Palawan_LULC_2025',\n    folder='EO_Training_Exports',\n    fileNamePrefix='palawan_lulc_2025',\n    region=aoi,\n    scale=10,\n    maxPixels=1e13,\n    crs='EPSG:4326'\n)\n\n# Don't start automatically in notebook\nprint(\"‚úì Export tasks configured\")\nprint(\"\\nTo start export, run:\")\nprint(\"  export_task.start()\")\nprint(\"\\nThen check status at: https://code.earthengine.google.com/tasks\")"
  },
  {
   "cell_type": "markdown",
   "id": "1e2c29e5",
   "metadata": {},
   "source": [
    "### Export Options\n",
    "\n",
    "You can export:\n",
    "- **Classification maps** (GeoTIFF)\n",
    "- **Forest loss** (binary mask)\n",
    "- **Hotspots** (intensity raster)\n",
    "- **Statistics** (CSV via pandas)\n",
    "\n",
    "For large exports, use Earth Engine Tasks instead of direct download.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b879ae47",
   "metadata": {},
   "source": [
    "### üéâ Part D Complete!\n",
    "\n",
    "You've successfully:\n",
    "- ‚úÖ Created 2020 baseline classification\n",
    "- ‚úÖ Detected forest loss (2020-2024)\n",
    "- ‚úÖ Identified deforestation hotspots\n",
    "- ‚úÖ Generated stakeholder report\n",
    "- ‚úÖ Prepared export tasks\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487cc753",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì Lab Complete!\n",
    "\n",
    "## Summary of Achievements\n",
    "\n",
    "In this 2-hour lab, you:\n",
    "\n",
    "### Part A: Feature Engineering\n",
    "- ‚úÖ Created seasonal Sentinel-2 composites (dry/wet)\n",
    "- ‚úÖ Calculated spectral indices (NDVI, NDWI, NDBI, EVI)\n",
    "- ‚úÖ Extracted GLCM texture features\n",
    "- ‚úÖ Derived temporal phenology features\n",
    "- ‚úÖ Integrated topographic data (DEM)\n",
    "- ‚úÖ Built comprehensive 23-feature stack\n",
    "\n",
    "### Part B: Classification\n",
    "- ‚úÖ Loaded training/validation data (80+40 polygons)\n",
    "- ‚úÖ Trained Random Forest classifier\n",
    "- ‚úÖ Applied 8-class land cover classification\n",
    "- ‚úÖ Achieved >85% accuracy (hopefully!)\n",
    "- ‚úÖ Analyzed feature importance\n",
    "- ‚úÖ Calculated area statistics\n",
    "\n",
    "### Part C: Optimization\n",
    "- ‚úÖ Performed hyperparameter tuning\n",
    "- ‚úÖ Tested multiple tree counts\n",
    "- ‚úÖ Applied post-processing filters\n",
    "- ‚úÖ Improved classification quality\n",
    "\n",
    "### Part D: NRM Applications\n",
    "- ‚úÖ Created 2020 baseline classification\n",
    "- ‚úÖ Detected forest loss (2020-2024)\n",
    "- ‚úÖ Identified deforestation hotspots\n",
    "- ‚úÖ Generated stakeholder-ready reports\n",
    "- ‚úÖ Prepared GIS exports\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Multi-temporal analysis** significantly improves classification accuracy\n",
    "2. **Texture features** help distinguish land covers with similar spectra\n",
    "3. **Topography** provides valuable context for land use patterns\n",
    "4. **Hyperparameter tuning** can boost accuracy by 2-5%\n",
    "5. **Change detection** enables monitoring of conservation priorities\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Session 3: Introduction to Deep Learning & CNNs\n",
    "\n",
    "You're now ready to explore deep learning approaches that can:\n",
    "- Learn features automatically (vs manual engineering)\n",
    "- Handle complex spatial patterns\n",
    "- Achieve higher accuracy on challenging classes\n",
    "- Scale to very large areas\n",
    "\n",
    "[Continue to Session 3 ‚Üí](../../../course_site/day2/sessions/session3.qmd)\n",
    "\n",
    "### Extended Exercises\n",
    "\n",
    "Want more practice? Try:\n",
    "\n",
    "1. **Expand to full Palawan** (entire province)\n",
    "2. **Add more classes** (coconut vs rice, forest subtypes)\n",
    "3. **Annual time series** (2017-2024 trends)\n",
    "4. **Integration with field data**\n",
    "5. **Automated monitoring** (monthly updates)\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "### Code Templates\n",
    "- [`glcm_template.py`](../templates/glcm_template.py)\n",
    "- [`temporal_composite_template.py`](../templates/temporal_composite_template.py)\n",
    "- [`change_detection_template.py`](../templates/change_detection_template.py)\n",
    "\n",
    "### Documentation\n",
    "- [GEE Classification Guide](https://developers.google.com/earth-engine/guides/classification)\n",
    "- [Session 2 Overview](../../../course_site/day2/sessions/session2.qmd)\n",
    "- [Troubleshooting Guide](../documentation/TROUBLESHOOTING.md)\n",
    "\n",
    "### Training Data\n",
    "- [Palawan Training Polygons](../data/palawan_training_polygons.geojson)\n",
    "- [Class Definitions](../data/class_definitions.md)\n",
    "\n",
    "---\n",
    "\n",
    "## Questions or Issues?\n",
    "\n",
    "- üìñ Review session documentation\n",
    "- üí¨ Ask instructor during office hours\n",
    "- üåê Check GEE community forums\n",
    "- üìß Submit via course platform\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations! üéâ\n",
    "\n",
    "You've mastered advanced EO classification techniques and are ready for deep learning!\n",
    "\n",
    "**Session completed:** \n",
    "\n",
    "---\n",
    "\n",
    "*Developed for CoPhil Advanced Training Program*  \n",
    "*EU-Philippines Copernicus Programme*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}